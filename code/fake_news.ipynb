{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U01PK8zLfl40"
      },
      "outputs": [],
      "source": [
        "pip install pandas scikit-learn nltk bnlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bnlp_toolkit"
      ],
      "metadata": {
        "id": "ujSnCl96gA1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from bnlp import BasicTokenizer\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel(\"dataset.xlsx\")  # Replace with your file path\n",
        "\n",
        "data['combined_text'] = data['category'] + ' ' + data['headline'] + ' ' + data['content']\n",
        "\n",
        "# Preprocessing using bnlp\n",
        "bnlp_tokenizer = BasicTokenizer()\n",
        "data['combined_text'] = data['combined_text'].astype(str).apply(bnlp_tokenizer.tokenize)\n",
        "\n",
        "# Convert content back to strings\n",
        "data['combined_text'] = data['combined_text'].apply(lambda tokens: \" \".join(tokens))\n",
        "\n",
        "# Preprocessing\n",
        "X = data['combined_text'].astype(str).values\n",
        "y = data['label'].values\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize a tokenizer\n",
        "max_words = 10000\n",
        "tokenizer = tf.keras.layers.TextVectorization(max_tokens=max_words, output_mode='int', output_sequence_length=200)\n",
        "tokenizer.adapt(X_train)\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "X_train_padded = tokenizer(X_train).numpy()\n",
        "X_test_padded = tokenizer(X_test).numpy()\n",
        "\n",
        "# Build LSTM models\n",
        "def build_lstm_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(input_dim=max_words, output_dim=100, input_length=200),\n",
        "        tf.keras.layers.LSTM(128, return_sequences=True),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.LSTM(256),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create three LSTM models\n",
        "num_models = 5\n",
        "models = [build_lstm_model() for _ in range(num_models)]\n",
        "\n",
        "# Train each model\n",
        "for i, model in enumerate(models):\n",
        "    print(f\"Training Model {i+1}\")\n",
        "    model.fit(X_train_padded, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Make predictions with each model\n",
        "predictions = np.array([model.predict(X_test_padded) for model in models])\n",
        "\n",
        "# Ensemble predictions using majority vote\n",
        "ensemble_predictions = np.round(np.mean(predictions, axis=0)).flatten()\n",
        "\n",
        "# Evaluate the ensemble\n",
        "print(classification_report(y_test, ensemble_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oApkZKnfgFze",
        "outputId": "9a835ead-07a9-4a8a-f23c-234230749acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "punkt not found. downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model 1\n",
            "Epoch 1/100\n",
            "237/237 [==============================] - 54s 181ms/step - loss: 0.7772 - accuracy: 0.5508 - val_loss: 1.0343 - val_accuracy: 0.5208\n",
            "Epoch 2/100\n",
            "237/237 [==============================] - 19s 80ms/step - loss: 0.6239 - accuracy: 0.6327 - val_loss: 1.0315 - val_accuracy: 0.5208\n",
            "Epoch 3/100\n",
            "237/237 [==============================] - 14s 59ms/step - loss: 0.4425 - accuracy: 0.7936 - val_loss: 1.6353 - val_accuracy: 0.5377\n",
            "Epoch 4/100\n",
            "237/237 [==============================] - 9s 38ms/step - loss: 0.2727 - accuracy: 0.8873 - val_loss: 1.5944 - val_accuracy: 0.5894\n",
            "Epoch 5/100\n",
            "237/237 [==============================] - 8s 33ms/step - loss: 0.1934 - accuracy: 0.9295 - val_loss: 15.0855 - val_accuracy: 0.4792\n",
            "Epoch 6/100\n",
            "237/237 [==============================] - 9s 36ms/step - loss: 0.1444 - accuracy: 0.9525 - val_loss: 2.0394 - val_accuracy: 0.5409\n",
            "Epoch 7/100\n",
            "237/237 [==============================] - 8s 33ms/step - loss: 0.1178 - accuracy: 0.9628 - val_loss: 5.1805 - val_accuracy: 0.5040\n",
            "Epoch 8/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.1048 - accuracy: 0.9629 - val_loss: 0.6002 - val_accuracy: 0.6960\n",
            "Epoch 9/100\n",
            "237/237 [==============================] - 7s 31ms/step - loss: 0.0894 - accuracy: 0.9691 - val_loss: 3.5656 - val_accuracy: 0.5578\n",
            "Epoch 10/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0735 - accuracy: 0.9724 - val_loss: 3.9777 - val_accuracy: 0.5989\n",
            "Epoch 11/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0865 - accuracy: 0.9711 - val_loss: 1.5273 - val_accuracy: 0.6934\n",
            "Epoch 12/100\n",
            "237/237 [==============================] - 7s 31ms/step - loss: 0.0812 - accuracy: 0.9703 - val_loss: 2.2544 - val_accuracy: 0.6681\n",
            "Epoch 13/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.3279 - accuracy: 0.8598 - val_loss: 2.6774 - val_accuracy: 0.5208\n",
            "Epoch 14/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.1746 - accuracy: 0.9308 - val_loss: 1.3548 - val_accuracy: 0.6433\n",
            "Epoch 15/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.1136 - accuracy: 0.9578 - val_loss: 1.1304 - val_accuracy: 0.7003\n",
            "Epoch 16/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0933 - accuracy: 0.9624 - val_loss: 0.9602 - val_accuracy: 0.7609\n",
            "Epoch 17/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0754 - accuracy: 0.9707 - val_loss: 1.2276 - val_accuracy: 0.7398\n",
            "Epoch 18/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0626 - accuracy: 0.9744 - val_loss: 1.1753 - val_accuracy: 0.7646\n",
            "Epoch 19/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0655 - accuracy: 0.9758 - val_loss: 0.9955 - val_accuracy: 0.7499\n",
            "Epoch 20/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0527 - accuracy: 0.9791 - val_loss: 0.9228 - val_accuracy: 0.7578\n",
            "Epoch 21/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0483 - accuracy: 0.9787 - val_loss: 1.7622 - val_accuracy: 0.7066\n",
            "Epoch 22/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0554 - accuracy: 0.9766 - val_loss: 1.0713 - val_accuracy: 0.7609\n",
            "Epoch 23/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0455 - accuracy: 0.9791 - val_loss: 1.3136 - val_accuracy: 0.7388\n",
            "Epoch 24/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0445 - accuracy: 0.9822 - val_loss: 1.3232 - val_accuracy: 0.7383\n",
            "Epoch 25/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0470 - accuracy: 0.9794 - val_loss: 1.2048 - val_accuracy: 0.7398\n",
            "Epoch 26/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0482 - accuracy: 0.9782 - val_loss: 1.1697 - val_accuracy: 0.7441\n",
            "Epoch 27/100\n",
            "237/237 [==============================] - 6s 23ms/step - loss: 0.0443 - accuracy: 0.9790 - val_loss: 1.7033 - val_accuracy: 0.7303\n",
            "Epoch 28/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0412 - accuracy: 0.9798 - val_loss: 1.4788 - val_accuracy: 0.7187\n",
            "Epoch 29/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0383 - accuracy: 0.9799 - val_loss: 2.7914 - val_accuracy: 0.7119\n",
            "Epoch 30/100\n",
            "237/237 [==============================] - 7s 31ms/step - loss: 0.0372 - accuracy: 0.9813 - val_loss: 1.4554 - val_accuracy: 0.7456\n",
            "Epoch 31/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0426 - accuracy: 0.9810 - val_loss: 1.1966 - val_accuracy: 0.7609\n",
            "Epoch 32/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0335 - accuracy: 0.9813 - val_loss: 1.6371 - val_accuracy: 0.7583\n",
            "Epoch 33/100\n",
            "237/237 [==============================] - 6s 23ms/step - loss: 0.0379 - accuracy: 0.9818 - val_loss: 1.7814 - val_accuracy: 0.7108\n",
            "Epoch 34/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0436 - accuracy: 0.9806 - val_loss: 1.9096 - val_accuracy: 0.7409\n",
            "Epoch 35/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0412 - accuracy: 0.9784 - val_loss: 5.1804 - val_accuracy: 0.5910\n",
            "Epoch 36/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0416 - accuracy: 0.9797 - val_loss: 2.3856 - val_accuracy: 0.7214\n",
            "Epoch 37/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0381 - accuracy: 0.9820 - val_loss: 1.6371 - val_accuracy: 0.7351\n",
            "Epoch 38/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0414 - accuracy: 0.9817 - val_loss: 1.8053 - val_accuracy: 0.7061\n",
            "Epoch 39/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0344 - accuracy: 0.9817 - val_loss: 1.9842 - val_accuracy: 0.7319\n",
            "Epoch 40/100\n",
            "237/237 [==============================] - 7s 31ms/step - loss: 0.0334 - accuracy: 0.9827 - val_loss: 2.0694 - val_accuracy: 0.7335\n",
            "Epoch 41/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0311 - accuracy: 0.9810 - val_loss: 1.7757 - val_accuracy: 0.7330\n",
            "Epoch 42/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0304 - accuracy: 0.9835 - val_loss: 2.5251 - val_accuracy: 0.7594\n",
            "Epoch 43/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0379 - accuracy: 0.9823 - val_loss: 2.2181 - val_accuracy: 0.7493\n",
            "Epoch 44/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0337 - accuracy: 0.9836 - val_loss: 2.1389 - val_accuracy: 0.7187\n",
            "Epoch 45/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0302 - accuracy: 0.9844 - val_loss: 2.0168 - val_accuracy: 0.7309\n",
            "Epoch 46/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0375 - accuracy: 0.9807 - val_loss: 1.8682 - val_accuracy: 0.7493\n",
            "Epoch 47/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0373 - accuracy: 0.9818 - val_loss: 1.2984 - val_accuracy: 0.7578\n",
            "Epoch 48/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0300 - accuracy: 0.9838 - val_loss: 1.9633 - val_accuracy: 0.7330\n",
            "Epoch 49/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0285 - accuracy: 0.9830 - val_loss: 3.7346 - val_accuracy: 0.6612\n",
            "Epoch 50/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0315 - accuracy: 0.9840 - val_loss: 2.5566 - val_accuracy: 0.7309\n",
            "Epoch 51/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0256 - accuracy: 0.9843 - val_loss: 2.3564 - val_accuracy: 0.7346\n",
            "Epoch 52/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0406 - accuracy: 0.9809 - val_loss: 1.3478 - val_accuracy: 0.7683\n",
            "Epoch 53/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0287 - accuracy: 0.9840 - val_loss: 2.2788 - val_accuracy: 0.6454\n",
            "Epoch 54/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0271 - accuracy: 0.9844 - val_loss: 1.6502 - val_accuracy: 0.7536\n",
            "Epoch 55/100\n",
            "237/237 [==============================] - 5s 23ms/step - loss: 0.0309 - accuracy: 0.9838 - val_loss: 2.0931 - val_accuracy: 0.7472\n",
            "Epoch 56/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0341 - accuracy: 0.9823 - val_loss: 2.1854 - val_accuracy: 0.7356\n",
            "Epoch 57/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0366 - accuracy: 0.9789 - val_loss: 3.0661 - val_accuracy: 0.6617\n",
            "Epoch 58/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0340 - accuracy: 0.9834 - val_loss: 1.6029 - val_accuracy: 0.7451\n",
            "Epoch 59/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0306 - accuracy: 0.9835 - val_loss: 1.5767 - val_accuracy: 0.7240\n",
            "Epoch 60/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.1012 - accuracy: 0.9626 - val_loss: 7.6042 - val_accuracy: 0.5208\n",
            "Epoch 61/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0773 - accuracy: 0.9692 - val_loss: 2.0537 - val_accuracy: 0.6596\n",
            "Epoch 62/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0369 - accuracy: 0.9810 - val_loss: 1.6039 - val_accuracy: 0.7077\n",
            "Epoch 63/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0362 - accuracy: 0.9798 - val_loss: 1.5376 - val_accuracy: 0.7631\n",
            "Epoch 64/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0244 - accuracy: 0.9856 - val_loss: 2.3518 - val_accuracy: 0.7377\n",
            "Epoch 65/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0257 - accuracy: 0.9835 - val_loss: 1.7382 - val_accuracy: 0.7567\n",
            "Epoch 66/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0231 - accuracy: 0.9852 - val_loss: 2.0360 - val_accuracy: 0.7525\n",
            "Epoch 67/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0217 - accuracy: 0.9847 - val_loss: 2.5265 - val_accuracy: 0.7493\n",
            "Epoch 68/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0278 - accuracy: 0.9843 - val_loss: 2.3744 - val_accuracy: 0.7420\n",
            "Epoch 69/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0296 - accuracy: 0.9834 - val_loss: 1.7661 - val_accuracy: 0.7515\n",
            "Epoch 70/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0275 - accuracy: 0.9840 - val_loss: 1.9648 - val_accuracy: 0.7636\n",
            "Epoch 71/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0251 - accuracy: 0.9853 - val_loss: 2.6652 - val_accuracy: 0.7483\n",
            "Epoch 72/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0285 - accuracy: 0.9831 - val_loss: 1.8266 - val_accuracy: 0.7224\n",
            "Epoch 73/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0260 - accuracy: 0.9850 - val_loss: 2.2491 - val_accuracy: 0.7747\n",
            "Epoch 74/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0240 - accuracy: 0.9853 - val_loss: 1.5867 - val_accuracy: 0.7456\n",
            "Epoch 75/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0271 - accuracy: 0.9840 - val_loss: 1.8375 - val_accuracy: 0.7393\n",
            "Epoch 76/100\n",
            "237/237 [==============================] - 6s 23ms/step - loss: 0.0341 - accuracy: 0.9827 - val_loss: 3.0162 - val_accuracy: 0.7013\n",
            "Epoch 77/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0276 - accuracy: 0.9836 - val_loss: 2.1220 - val_accuracy: 0.7599\n",
            "Epoch 78/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0248 - accuracy: 0.9856 - val_loss: 3.3805 - val_accuracy: 0.7430\n",
            "Epoch 79/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0261 - accuracy: 0.9836 - val_loss: 3.1906 - val_accuracy: 0.7193\n",
            "Epoch 80/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0298 - accuracy: 0.9846 - val_loss: 2.5245 - val_accuracy: 0.7583\n",
            "Epoch 81/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0249 - accuracy: 0.9842 - val_loss: 2.4464 - val_accuracy: 0.7472\n",
            "Epoch 82/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0220 - accuracy: 0.9867 - val_loss: 3.3153 - val_accuracy: 0.6865\n",
            "Epoch 83/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0288 - accuracy: 0.9834 - val_loss: 6.2353 - val_accuracy: 0.5562\n",
            "Epoch 84/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0300 - accuracy: 0.9820 - val_loss: 2.5468 - val_accuracy: 0.7768\n",
            "Epoch 85/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0290 - accuracy: 0.9847 - val_loss: 1.8974 - val_accuracy: 0.7351\n",
            "Epoch 86/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0399 - accuracy: 0.9815 - val_loss: 3.6399 - val_accuracy: 0.6923\n",
            "Epoch 87/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0242 - accuracy: 0.9843 - val_loss: 2.1306 - val_accuracy: 0.7367\n",
            "Epoch 88/100\n",
            "237/237 [==============================] - 5s 23ms/step - loss: 0.0239 - accuracy: 0.9852 - val_loss: 2.2929 - val_accuracy: 0.6828\n",
            "Epoch 89/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0318 - accuracy: 0.9839 - val_loss: 2.3263 - val_accuracy: 0.7161\n",
            "Epoch 90/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0253 - accuracy: 0.9832 - val_loss: 2.0778 - val_accuracy: 0.7029\n",
            "Epoch 91/100\n",
            "237/237 [==============================] - 6s 23ms/step - loss: 0.0268 - accuracy: 0.9868 - val_loss: 3.5383 - val_accuracy: 0.6887\n",
            "Epoch 92/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0241 - accuracy: 0.9835 - val_loss: 2.5364 - val_accuracy: 0.7493\n",
            "Epoch 93/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0225 - accuracy: 0.9855 - val_loss: 1.8705 - val_accuracy: 0.7646\n",
            "Epoch 94/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0295 - accuracy: 0.9835 - val_loss: 1.5601 - val_accuracy: 0.7541\n",
            "Epoch 95/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0397 - accuracy: 0.9815 - val_loss: 1.9765 - val_accuracy: 0.7478\n",
            "Epoch 96/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0307 - accuracy: 0.9826 - val_loss: 1.9949 - val_accuracy: 0.7462\n",
            "Epoch 97/100\n",
            "237/237 [==============================] - 5s 23ms/step - loss: 0.0302 - accuracy: 0.9832 - val_loss: 1.8887 - val_accuracy: 0.7092\n",
            "Epoch 98/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0229 - accuracy: 0.9853 - val_loss: 1.9602 - val_accuracy: 0.7488\n",
            "Epoch 99/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0203 - accuracy: 0.9860 - val_loss: 2.2664 - val_accuracy: 0.7625\n",
            "Epoch 100/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0194 - accuracy: 0.9871 - val_loss: 2.1350 - val_accuracy: 0.7625\n",
            "Training Model 2\n",
            "Epoch 1/100\n",
            "237/237 [==============================] - 39s 144ms/step - loss: 0.7896 - accuracy: 0.5429 - val_loss: 0.7863 - val_accuracy: 0.5113\n",
            "Epoch 2/100\n",
            "237/237 [==============================] - 17s 70ms/step - loss: 0.6148 - accuracy: 0.6651 - val_loss: 1.0067 - val_accuracy: 0.5219\n",
            "Epoch 3/100\n",
            "237/237 [==============================] - 9s 39ms/step - loss: 0.4420 - accuracy: 0.7897 - val_loss: 0.4978 - val_accuracy: 0.7404\n",
            "Epoch 4/100\n",
            "237/237 [==============================] - 9s 37ms/step - loss: 0.2556 - accuracy: 0.8985 - val_loss: 0.6000 - val_accuracy: 0.7483\n",
            "Epoch 5/100\n",
            "237/237 [==============================] - 8s 33ms/step - loss: 0.1731 - accuracy: 0.9366 - val_loss: 0.5872 - val_accuracy: 0.7467\n",
            "Epoch 6/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.1243 - accuracy: 0.9591 - val_loss: 0.8229 - val_accuracy: 0.7441\n",
            "Epoch 7/100\n",
            "237/237 [==============================] - 8s 35ms/step - loss: 0.0915 - accuracy: 0.9682 - val_loss: 0.9361 - val_accuracy: 0.7504\n",
            "Epoch 8/100\n",
            "237/237 [==============================] - 7s 31ms/step - loss: 0.0739 - accuracy: 0.9715 - val_loss: 1.3113 - val_accuracy: 0.7441\n",
            "Epoch 9/100\n",
            "237/237 [==============================] - 7s 30ms/step - loss: 0.0714 - accuracy: 0.9703 - val_loss: 1.0688 - val_accuracy: 0.7504\n",
            "Epoch 10/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0775 - accuracy: 0.9708 - val_loss: 0.9308 - val_accuracy: 0.7541\n",
            "Epoch 11/100\n",
            "237/237 [==============================] - 7s 31ms/step - loss: 0.0761 - accuracy: 0.9691 - val_loss: 1.5018 - val_accuracy: 0.7135\n",
            "Epoch 12/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0645 - accuracy: 0.9740 - val_loss: 1.2216 - val_accuracy: 0.7551\n",
            "Epoch 13/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0806 - accuracy: 0.9670 - val_loss: 1.3025 - val_accuracy: 0.7430\n",
            "Epoch 14/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0585 - accuracy: 0.9765 - val_loss: 1.0870 - val_accuracy: 0.7393\n",
            "Epoch 15/100\n",
            "237/237 [==============================] - 7s 27ms/step - loss: 0.0471 - accuracy: 0.9798 - val_loss: 1.2302 - val_accuracy: 0.7499\n",
            "Epoch 16/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0466 - accuracy: 0.9791 - val_loss: 1.0064 - val_accuracy: 0.7615\n",
            "Epoch 17/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0448 - accuracy: 0.9807 - val_loss: 1.7406 - val_accuracy: 0.7187\n",
            "Epoch 18/100\n",
            "237/237 [==============================] - 6s 23ms/step - loss: 0.0361 - accuracy: 0.9820 - val_loss: 1.6562 - val_accuracy: 0.7488\n",
            "Epoch 19/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0575 - accuracy: 0.9739 - val_loss: 1.2209 - val_accuracy: 0.7641\n",
            "Epoch 20/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0472 - accuracy: 0.9781 - val_loss: 1.0202 - val_accuracy: 0.7689\n",
            "Epoch 21/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0392 - accuracy: 0.9818 - val_loss: 1.2832 - val_accuracy: 0.7704\n",
            "Epoch 22/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0455 - accuracy: 0.9789 - val_loss: 0.7396 - val_accuracy: 0.7441\n",
            "Epoch 23/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0480 - accuracy: 0.9784 - val_loss: 1.0945 - val_accuracy: 0.7435\n",
            "Epoch 24/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0405 - accuracy: 0.9824 - val_loss: 1.2689 - val_accuracy: 0.7662\n",
            "Epoch 25/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0517 - accuracy: 0.9768 - val_loss: 1.4544 - val_accuracy: 0.7404\n",
            "Epoch 26/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0386 - accuracy: 0.9798 - val_loss: 1.2443 - val_accuracy: 0.7325\n",
            "Epoch 27/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0411 - accuracy: 0.9803 - val_loss: 1.1485 - val_accuracy: 0.7646\n",
            "Epoch 28/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0336 - accuracy: 0.9819 - val_loss: 1.6129 - val_accuracy: 0.7462\n",
            "Epoch 29/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0323 - accuracy: 0.9824 - val_loss: 2.3013 - val_accuracy: 0.7351\n",
            "Epoch 30/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0401 - accuracy: 0.9805 - val_loss: 1.6614 - val_accuracy: 0.7478\n",
            "Epoch 31/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0364 - accuracy: 0.9810 - val_loss: 2.3799 - val_accuracy: 0.6850\n",
            "Epoch 32/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0327 - accuracy: 0.9827 - val_loss: 2.3881 - val_accuracy: 0.6934\n",
            "Epoch 33/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0347 - accuracy: 0.9823 - val_loss: 1.5901 - val_accuracy: 0.7631\n",
            "Epoch 34/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0338 - accuracy: 0.9807 - val_loss: 1.9604 - val_accuracy: 0.7398\n",
            "Epoch 35/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0291 - accuracy: 0.9839 - val_loss: 1.4933 - val_accuracy: 0.7631\n",
            "Epoch 36/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0316 - accuracy: 0.9844 - val_loss: 1.9716 - val_accuracy: 0.7314\n",
            "Epoch 37/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0398 - accuracy: 0.9809 - val_loss: 1.4051 - val_accuracy: 0.7567\n",
            "Epoch 38/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0360 - accuracy: 0.9813 - val_loss: 2.1432 - val_accuracy: 0.6955\n",
            "Epoch 39/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0392 - accuracy: 0.9809 - val_loss: 1.4935 - val_accuracy: 0.7567\n",
            "Epoch 40/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0376 - accuracy: 0.9809 - val_loss: 1.3303 - val_accuracy: 0.7562\n",
            "Epoch 41/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0311 - accuracy: 0.9819 - val_loss: 1.5455 - val_accuracy: 0.7388\n",
            "Epoch 42/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0302 - accuracy: 0.9847 - val_loss: 1.4588 - val_accuracy: 0.7620\n",
            "Epoch 43/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0324 - accuracy: 0.9832 - val_loss: 2.1319 - val_accuracy: 0.7509\n",
            "Epoch 44/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0249 - accuracy: 0.9851 - val_loss: 1.4995 - val_accuracy: 0.7678\n",
            "Epoch 45/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0305 - accuracy: 0.9838 - val_loss: 1.8546 - val_accuracy: 0.7198\n",
            "Epoch 46/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0293 - accuracy: 0.9830 - val_loss: 2.0476 - val_accuracy: 0.7261\n",
            "Epoch 47/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0281 - accuracy: 0.9846 - val_loss: 1.6622 - val_accuracy: 0.7726\n",
            "Epoch 48/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0295 - accuracy: 0.9820 - val_loss: 2.1472 - val_accuracy: 0.7483\n",
            "Epoch 49/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0274 - accuracy: 0.9842 - val_loss: 1.4922 - val_accuracy: 0.7388\n",
            "Epoch 50/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0326 - accuracy: 0.9839 - val_loss: 1.4289 - val_accuracy: 0.7615\n",
            "Epoch 51/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0319 - accuracy: 0.9820 - val_loss: 2.0758 - val_accuracy: 0.7029\n",
            "Epoch 52/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0355 - accuracy: 0.9831 - val_loss: 2.2534 - val_accuracy: 0.7493\n",
            "Epoch 53/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0328 - accuracy: 0.9819 - val_loss: 1.8352 - val_accuracy: 0.7525\n",
            "Epoch 54/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0259 - accuracy: 0.9842 - val_loss: 2.1675 - val_accuracy: 0.7578\n",
            "Epoch 55/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0628 - accuracy: 0.9733 - val_loss: 1.2608 - val_accuracy: 0.7193\n",
            "Epoch 56/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0487 - accuracy: 0.9781 - val_loss: 1.6135 - val_accuracy: 0.7441\n",
            "Epoch 57/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0330 - accuracy: 0.9828 - val_loss: 1.6103 - val_accuracy: 0.7546\n",
            "Epoch 58/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0221 - accuracy: 0.9851 - val_loss: 2.2986 - val_accuracy: 0.7367\n",
            "Epoch 59/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0342 - accuracy: 0.9847 - val_loss: 1.4785 - val_accuracy: 0.7583\n",
            "Epoch 60/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0227 - accuracy: 0.9857 - val_loss: 1.9098 - val_accuracy: 0.7425\n",
            "Epoch 61/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0272 - accuracy: 0.9844 - val_loss: 1.7963 - val_accuracy: 0.7462\n",
            "Epoch 62/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0214 - accuracy: 0.9843 - val_loss: 1.9108 - val_accuracy: 0.7509\n",
            "Epoch 63/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0204 - accuracy: 0.9869 - val_loss: 2.1667 - val_accuracy: 0.7546\n",
            "Epoch 64/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0305 - accuracy: 0.9830 - val_loss: 1.7977 - val_accuracy: 0.7456\n",
            "Epoch 65/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0304 - accuracy: 0.9828 - val_loss: 2.0137 - val_accuracy: 0.7288\n",
            "Epoch 66/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0243 - accuracy: 0.9861 - val_loss: 2.1123 - val_accuracy: 0.7551\n",
            "Epoch 67/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0227 - accuracy: 0.9863 - val_loss: 1.9538 - val_accuracy: 0.7573\n",
            "Epoch 68/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0216 - accuracy: 0.9848 - val_loss: 2.2744 - val_accuracy: 0.7594\n",
            "Epoch 69/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0246 - accuracy: 0.9850 - val_loss: 2.3786 - val_accuracy: 0.7557\n",
            "Epoch 70/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0254 - accuracy: 0.9826 - val_loss: 1.8926 - val_accuracy: 0.7404\n",
            "Epoch 71/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0256 - accuracy: 0.9840 - val_loss: 1.9440 - val_accuracy: 0.7604\n",
            "Epoch 72/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0327 - accuracy: 0.9824 - val_loss: 2.0101 - val_accuracy: 0.7646\n",
            "Epoch 73/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0266 - accuracy: 0.9846 - val_loss: 1.7012 - val_accuracy: 0.7530\n",
            "Epoch 74/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0272 - accuracy: 0.9843 - val_loss: 1.5983 - val_accuracy: 0.7726\n",
            "Epoch 75/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0263 - accuracy: 0.9857 - val_loss: 2.1559 - val_accuracy: 0.7657\n",
            "Epoch 76/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0243 - accuracy: 0.9844 - val_loss: 2.0009 - val_accuracy: 0.7689\n",
            "Epoch 77/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0264 - accuracy: 0.9848 - val_loss: 1.8747 - val_accuracy: 0.7657\n",
            "Epoch 78/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0273 - accuracy: 0.9834 - val_loss: 2.1012 - val_accuracy: 0.7657\n",
            "Epoch 79/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0228 - accuracy: 0.9855 - val_loss: 2.2255 - val_accuracy: 0.7668\n",
            "Epoch 80/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0210 - accuracy: 0.9861 - val_loss: 2.3168 - val_accuracy: 0.7683\n",
            "Epoch 81/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0205 - accuracy: 0.9864 - val_loss: 2.2066 - val_accuracy: 0.7620\n",
            "Epoch 82/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0194 - accuracy: 0.9851 - val_loss: 2.6267 - val_accuracy: 0.7662\n",
            "Epoch 83/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0252 - accuracy: 0.9852 - val_loss: 2.0926 - val_accuracy: 0.7430\n",
            "Epoch 84/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0380 - accuracy: 0.9822 - val_loss: 1.6784 - val_accuracy: 0.7573\n",
            "Epoch 85/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0256 - accuracy: 0.9852 - val_loss: 1.7462 - val_accuracy: 0.7551\n",
            "Epoch 86/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0277 - accuracy: 0.9855 - val_loss: 1.9822 - val_accuracy: 0.7641\n",
            "Epoch 87/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0236 - accuracy: 0.9838 - val_loss: 2.6628 - val_accuracy: 0.7441\n",
            "Epoch 88/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0218 - accuracy: 0.9863 - val_loss: 2.2491 - val_accuracy: 0.7578\n",
            "Epoch 89/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0213 - accuracy: 0.9860 - val_loss: 2.1587 - val_accuracy: 0.7509\n",
            "Epoch 90/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0233 - accuracy: 0.9868 - val_loss: 1.8958 - val_accuracy: 0.7689\n",
            "Epoch 91/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0190 - accuracy: 0.9868 - val_loss: 2.1711 - val_accuracy: 0.7731\n",
            "Epoch 92/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0200 - accuracy: 0.9861 - val_loss: 2.2192 - val_accuracy: 0.7573\n",
            "Epoch 93/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0224 - accuracy: 0.9852 - val_loss: 2.2995 - val_accuracy: 0.7515\n",
            "Epoch 94/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0324 - accuracy: 0.9834 - val_loss: 2.3587 - val_accuracy: 0.7499\n",
            "Epoch 95/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0327 - accuracy: 0.9839 - val_loss: 2.1185 - val_accuracy: 0.7620\n",
            "Epoch 96/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0385 - accuracy: 0.9820 - val_loss: 2.0780 - val_accuracy: 0.7367\n",
            "Epoch 97/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0294 - accuracy: 0.9864 - val_loss: 1.9840 - val_accuracy: 0.7731\n",
            "Epoch 98/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0221 - accuracy: 0.9876 - val_loss: 1.7637 - val_accuracy: 0.7673\n",
            "Epoch 99/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0200 - accuracy: 0.9872 - val_loss: 2.1922 - val_accuracy: 0.7683\n",
            "Epoch 100/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0214 - accuracy: 0.9847 - val_loss: 1.9377 - val_accuracy: 0.7620\n",
            "Training Model 3\n",
            "Epoch 1/100\n",
            "237/237 [==============================] - 39s 140ms/step - loss: 0.7817 - accuracy: 0.5318 - val_loss: 0.6917 - val_accuracy: 0.5208\n",
            "Epoch 2/100\n",
            "237/237 [==============================] - 15s 63ms/step - loss: 0.5655 - accuracy: 0.6992 - val_loss: 2.3283 - val_accuracy: 0.5208\n",
            "Epoch 3/100\n",
            "237/237 [==============================] - 11s 46ms/step - loss: 0.3680 - accuracy: 0.8342 - val_loss: 1.5057 - val_accuracy: 0.4802\n",
            "Epoch 4/100\n",
            "237/237 [==============================] - 9s 38ms/step - loss: 0.2452 - accuracy: 0.9063 - val_loss: 0.5556 - val_accuracy: 0.7599\n",
            "Epoch 5/100\n",
            "237/237 [==============================] - 9s 37ms/step - loss: 0.1811 - accuracy: 0.9314 - val_loss: 6.2976 - val_accuracy: 0.4823\n",
            "Epoch 6/100\n",
            "237/237 [==============================] - 8s 35ms/step - loss: 0.1340 - accuracy: 0.9513 - val_loss: 1.5898 - val_accuracy: 0.6639\n",
            "Epoch 7/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.1119 - accuracy: 0.9642 - val_loss: 2.0410 - val_accuracy: 0.6253\n",
            "Epoch 8/100\n",
            "237/237 [==============================] - 8s 33ms/step - loss: 0.1046 - accuracy: 0.9616 - val_loss: 4.1600 - val_accuracy: 0.5414\n",
            "Epoch 9/100\n",
            "237/237 [==============================] - 8s 32ms/step - loss: 0.0868 - accuracy: 0.9690 - val_loss: 2.1366 - val_accuracy: 0.6617\n",
            "Epoch 10/100\n",
            "237/237 [==============================] - 8s 32ms/step - loss: 0.0814 - accuracy: 0.9694 - val_loss: 1.8453 - val_accuracy: 0.7098\n",
            "Epoch 11/100\n",
            "237/237 [==============================] - 7s 30ms/step - loss: 0.0815 - accuracy: 0.9711 - val_loss: 1.3692 - val_accuracy: 0.6770\n",
            "Epoch 12/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0705 - accuracy: 0.9741 - val_loss: 0.7473 - val_accuracy: 0.7515\n",
            "Epoch 13/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0682 - accuracy: 0.9723 - val_loss: 1.0546 - val_accuracy: 0.7335\n",
            "Epoch 14/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0634 - accuracy: 0.9757 - val_loss: 4.6928 - val_accuracy: 0.6011\n",
            "Epoch 15/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0683 - accuracy: 0.9727 - val_loss: 4.2894 - val_accuracy: 0.5251\n",
            "Epoch 16/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0603 - accuracy: 0.9756 - val_loss: 6.2374 - val_accuracy: 0.5208\n",
            "Epoch 17/100\n",
            "237/237 [==============================] - 7s 30ms/step - loss: 0.0586 - accuracy: 0.9761 - val_loss: 2.4429 - val_accuracy: 0.6174\n",
            "Epoch 18/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0568 - accuracy: 0.9760 - val_loss: 1.4080 - val_accuracy: 0.7420\n",
            "Epoch 19/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0567 - accuracy: 0.9774 - val_loss: 1.1588 - val_accuracy: 0.7541\n",
            "Epoch 20/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0451 - accuracy: 0.9806 - val_loss: 2.0832 - val_accuracy: 0.7340\n",
            "Epoch 21/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0468 - accuracy: 0.9799 - val_loss: 2.1409 - val_accuracy: 0.7245\n",
            "Epoch 22/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0523 - accuracy: 0.9761 - val_loss: 3.3547 - val_accuracy: 0.6359\n",
            "Epoch 23/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0409 - accuracy: 0.9805 - val_loss: 1.5744 - val_accuracy: 0.7620\n",
            "Epoch 24/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0416 - accuracy: 0.9809 - val_loss: 1.6264 - val_accuracy: 0.7251\n",
            "Epoch 25/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0376 - accuracy: 0.9806 - val_loss: 4.4080 - val_accuracy: 0.5794\n",
            "Epoch 26/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0438 - accuracy: 0.9810 - val_loss: 3.0980 - val_accuracy: 0.6332\n",
            "Epoch 27/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0474 - accuracy: 0.9802 - val_loss: 1.8184 - val_accuracy: 0.7113\n",
            "Epoch 28/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0412 - accuracy: 0.9822 - val_loss: 0.9991 - val_accuracy: 0.7119\n",
            "Epoch 29/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0427 - accuracy: 0.9798 - val_loss: 2.2670 - val_accuracy: 0.7346\n",
            "Epoch 30/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0434 - accuracy: 0.9805 - val_loss: 1.7832 - val_accuracy: 0.7420\n",
            "Epoch 31/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0384 - accuracy: 0.9794 - val_loss: 2.0854 - val_accuracy: 0.7166\n",
            "Epoch 32/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0302 - accuracy: 0.9831 - val_loss: 1.8372 - val_accuracy: 0.7325\n",
            "Epoch 33/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0330 - accuracy: 0.9819 - val_loss: 2.1228 - val_accuracy: 0.7214\n",
            "Epoch 34/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0312 - accuracy: 0.9839 - val_loss: 3.9998 - val_accuracy: 0.6908\n",
            "Epoch 35/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0329 - accuracy: 0.9814 - val_loss: 1.9175 - val_accuracy: 0.7383\n",
            "Epoch 36/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0391 - accuracy: 0.9806 - val_loss: 3.7466 - val_accuracy: 0.6602\n",
            "Epoch 37/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0403 - accuracy: 0.9791 - val_loss: 1.2058 - val_accuracy: 0.7356\n",
            "Epoch 38/100\n",
            "237/237 [==============================] - 7s 27ms/step - loss: 0.0354 - accuracy: 0.9813 - val_loss: 1.3403 - val_accuracy: 0.7351\n",
            "Epoch 39/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0282 - accuracy: 0.9834 - val_loss: 1.5606 - val_accuracy: 0.7546\n",
            "Epoch 40/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0352 - accuracy: 0.9807 - val_loss: 1.5297 - val_accuracy: 0.7536\n",
            "Epoch 41/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0345 - accuracy: 0.9831 - val_loss: 2.0132 - val_accuracy: 0.7224\n",
            "Epoch 42/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0281 - accuracy: 0.9830 - val_loss: 1.8303 - val_accuracy: 0.7641\n",
            "Epoch 43/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0375 - accuracy: 0.9805 - val_loss: 1.8990 - val_accuracy: 0.7557\n",
            "Epoch 44/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0415 - accuracy: 0.9795 - val_loss: 2.0739 - val_accuracy: 0.7346\n",
            "Epoch 45/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0314 - accuracy: 0.9827 - val_loss: 1.3340 - val_accuracy: 0.7383\n",
            "Epoch 46/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0406 - accuracy: 0.9814 - val_loss: 1.7288 - val_accuracy: 0.7340\n",
            "Epoch 47/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0550 - accuracy: 0.9786 - val_loss: 1.4654 - val_accuracy: 0.7441\n",
            "Epoch 48/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0302 - accuracy: 0.9831 - val_loss: 1.7047 - val_accuracy: 0.7462\n",
            "Epoch 49/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0242 - accuracy: 0.9852 - val_loss: 2.0605 - val_accuracy: 0.7441\n",
            "Epoch 50/100\n",
            "237/237 [==============================] - 7s 31ms/step - loss: 0.0243 - accuracy: 0.9839 - val_loss: 1.7410 - val_accuracy: 0.7567\n",
            "Epoch 51/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0384 - accuracy: 0.9828 - val_loss: 2.0212 - val_accuracy: 0.7261\n",
            "Epoch 52/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0289 - accuracy: 0.9840 - val_loss: 1.5342 - val_accuracy: 0.7573\n",
            "Epoch 53/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0326 - accuracy: 0.9824 - val_loss: 1.2144 - val_accuracy: 0.7515\n",
            "Epoch 54/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0258 - accuracy: 0.9856 - val_loss: 1.9734 - val_accuracy: 0.7367\n",
            "Epoch 55/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0256 - accuracy: 0.9839 - val_loss: 2.2630 - val_accuracy: 0.7404\n",
            "Epoch 56/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0350 - accuracy: 0.9819 - val_loss: 2.2432 - val_accuracy: 0.7573\n",
            "Epoch 57/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0252 - accuracy: 0.9848 - val_loss: 1.7234 - val_accuracy: 0.7446\n",
            "Epoch 58/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0288 - accuracy: 0.9856 - val_loss: 1.8033 - val_accuracy: 0.7446\n",
            "Epoch 59/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0298 - accuracy: 0.9832 - val_loss: 1.9394 - val_accuracy: 0.7367\n",
            "Epoch 60/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0225 - accuracy: 0.9860 - val_loss: 1.9475 - val_accuracy: 0.7515\n",
            "Epoch 61/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0221 - accuracy: 0.9863 - val_loss: 1.2685 - val_accuracy: 0.7467\n",
            "Epoch 62/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0327 - accuracy: 0.9811 - val_loss: 3.1274 - val_accuracy: 0.7161\n",
            "Epoch 63/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0358 - accuracy: 0.9823 - val_loss: 1.6640 - val_accuracy: 0.7551\n",
            "Epoch 64/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0247 - accuracy: 0.9856 - val_loss: 1.3069 - val_accuracy: 0.7573\n",
            "Epoch 65/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0239 - accuracy: 0.9855 - val_loss: 2.1130 - val_accuracy: 0.7478\n",
            "Epoch 66/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0300 - accuracy: 0.9842 - val_loss: 1.7932 - val_accuracy: 0.7224\n",
            "Epoch 67/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0295 - accuracy: 0.9851 - val_loss: 1.7100 - val_accuracy: 0.7441\n",
            "Epoch 68/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0310 - accuracy: 0.9840 - val_loss: 1.9228 - val_accuracy: 0.7388\n",
            "Epoch 69/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0283 - accuracy: 0.9863 - val_loss: 1.6838 - val_accuracy: 0.7451\n",
            "Epoch 70/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0224 - accuracy: 0.9853 - val_loss: 1.6932 - val_accuracy: 0.7451\n",
            "Epoch 71/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0249 - accuracy: 0.9853 - val_loss: 1.0640 - val_accuracy: 0.7757\n",
            "Epoch 72/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0281 - accuracy: 0.9846 - val_loss: 2.9295 - val_accuracy: 0.7398\n",
            "Epoch 73/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0232 - accuracy: 0.9856 - val_loss: 1.9141 - val_accuracy: 0.7478\n",
            "Epoch 74/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0260 - accuracy: 0.9840 - val_loss: 2.0298 - val_accuracy: 0.7594\n",
            "Epoch 75/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0300 - accuracy: 0.9828 - val_loss: 1.5988 - val_accuracy: 0.7588\n",
            "Epoch 76/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0293 - accuracy: 0.9836 - val_loss: 1.8719 - val_accuracy: 0.7583\n",
            "Epoch 77/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0197 - accuracy: 0.9864 - val_loss: 1.9458 - val_accuracy: 0.7609\n",
            "Epoch 78/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0221 - accuracy: 0.9872 - val_loss: 3.0355 - val_accuracy: 0.7261\n",
            "Epoch 79/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0295 - accuracy: 0.9868 - val_loss: 1.8749 - val_accuracy: 0.7694\n",
            "Epoch 80/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0251 - accuracy: 0.9830 - val_loss: 1.9823 - val_accuracy: 0.7451\n",
            "Epoch 81/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0264 - accuracy: 0.9840 - val_loss: 2.2979 - val_accuracy: 0.7472\n",
            "Epoch 82/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0258 - accuracy: 0.9840 - val_loss: 2.3641 - val_accuracy: 0.7567\n",
            "Epoch 83/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0241 - accuracy: 0.9861 - val_loss: 1.8392 - val_accuracy: 0.7541\n",
            "Epoch 84/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0298 - accuracy: 0.9848 - val_loss: 1.6684 - val_accuracy: 0.7652\n",
            "Epoch 85/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0251 - accuracy: 0.9850 - val_loss: 1.8034 - val_accuracy: 0.7388\n",
            "Epoch 86/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0198 - accuracy: 0.9856 - val_loss: 2.1326 - val_accuracy: 0.7467\n",
            "Epoch 87/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0254 - accuracy: 0.9847 - val_loss: 2.1010 - val_accuracy: 0.7525\n",
            "Epoch 88/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0199 - accuracy: 0.9865 - val_loss: 2.3406 - val_accuracy: 0.7573\n",
            "Epoch 89/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0266 - accuracy: 0.9840 - val_loss: 1.6633 - val_accuracy: 0.7604\n",
            "Epoch 90/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0199 - accuracy: 0.9869 - val_loss: 2.5411 - val_accuracy: 0.7499\n",
            "Epoch 91/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0288 - accuracy: 0.9847 - val_loss: 1.7386 - val_accuracy: 0.7303\n",
            "Epoch 92/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0241 - accuracy: 0.9864 - val_loss: 1.4525 - val_accuracy: 0.7499\n",
            "Epoch 93/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0201 - accuracy: 0.9859 - val_loss: 2.0606 - val_accuracy: 0.7594\n",
            "Epoch 94/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0204 - accuracy: 0.9852 - val_loss: 2.4399 - val_accuracy: 0.7372\n",
            "Epoch 95/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0280 - accuracy: 0.9835 - val_loss: 3.1818 - val_accuracy: 0.7335\n",
            "Epoch 96/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0341 - accuracy: 0.9838 - val_loss: 1.5279 - val_accuracy: 0.7409\n",
            "Epoch 97/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0235 - accuracy: 0.9863 - val_loss: 1.9604 - val_accuracy: 0.7615\n",
            "Epoch 98/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0196 - accuracy: 0.9861 - val_loss: 2.4316 - val_accuracy: 0.7562\n",
            "Epoch 99/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0194 - accuracy: 0.9875 - val_loss: 2.3370 - val_accuracy: 0.7646\n",
            "Epoch 100/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0268 - accuracy: 0.9869 - val_loss: 2.0224 - val_accuracy: 0.7652\n",
            "Training Model 4\n",
            "Epoch 1/100\n",
            "237/237 [==============================] - 38s 136ms/step - loss: 0.7748 - accuracy: 0.5288 - val_loss: 0.8145 - val_accuracy: 0.4792\n",
            "Epoch 2/100\n",
            "237/237 [==============================] - 17s 73ms/step - loss: 0.5645 - accuracy: 0.6919 - val_loss: 1.8648 - val_accuracy: 0.5625\n",
            "Epoch 3/100\n",
            "237/237 [==============================] - 12s 49ms/step - loss: 0.3680 - accuracy: 0.8289 - val_loss: 2.3368 - val_accuracy: 0.5219\n",
            "Epoch 4/100\n",
            "237/237 [==============================] - 10s 41ms/step - loss: 0.2434 - accuracy: 0.9010 - val_loss: 6.8014 - val_accuracy: 0.5208\n",
            "Epoch 5/100\n",
            "237/237 [==============================] - 8s 32ms/step - loss: 0.1670 - accuracy: 0.9380 - val_loss: 5.3843 - val_accuracy: 0.5958\n",
            "Epoch 6/100\n",
            "237/237 [==============================] - 9s 38ms/step - loss: 0.1397 - accuracy: 0.9530 - val_loss: 35.0262 - val_accuracy: 0.5208\n",
            "Epoch 7/100\n",
            "237/237 [==============================] - 8s 34ms/step - loss: 0.1189 - accuracy: 0.9580 - val_loss: 1.1829 - val_accuracy: 0.7594\n",
            "Epoch 8/100\n",
            "237/237 [==============================] - 7s 30ms/step - loss: 0.0935 - accuracy: 0.9667 - val_loss: 1.5496 - val_accuracy: 0.7061\n",
            "Epoch 9/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0997 - accuracy: 0.9626 - val_loss: 2.8001 - val_accuracy: 0.5113\n",
            "Epoch 10/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0736 - accuracy: 0.9740 - val_loss: 4.5267 - val_accuracy: 0.5040\n",
            "Epoch 11/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0754 - accuracy: 0.9719 - val_loss: 0.7177 - val_accuracy: 0.7583\n",
            "Epoch 12/100\n",
            "237/237 [==============================] - 7s 30ms/step - loss: 0.0705 - accuracy: 0.9737 - val_loss: 0.6226 - val_accuracy: 0.7609\n",
            "Epoch 13/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0628 - accuracy: 0.9761 - val_loss: 1.9123 - val_accuracy: 0.7562\n",
            "Epoch 14/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0659 - accuracy: 0.9766 - val_loss: 1.1950 - val_accuracy: 0.7472\n",
            "Epoch 15/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0681 - accuracy: 0.9743 - val_loss: 17.5707 - val_accuracy: 0.5346\n",
            "Epoch 16/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0619 - accuracy: 0.9721 - val_loss: 2.9400 - val_accuracy: 0.5784\n",
            "Epoch 17/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0567 - accuracy: 0.9772 - val_loss: 38.9440 - val_accuracy: 0.5245\n",
            "Epoch 18/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0540 - accuracy: 0.9757 - val_loss: 0.8197 - val_accuracy: 0.6681\n",
            "Epoch 19/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0521 - accuracy: 0.9764 - val_loss: 7.8905 - val_accuracy: 0.5868\n",
            "Epoch 20/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0572 - accuracy: 0.9785 - val_loss: 1.3516 - val_accuracy: 0.7683\n",
            "Epoch 21/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0558 - accuracy: 0.9752 - val_loss: 3.6204 - val_accuracy: 0.6617\n",
            "Epoch 22/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0372 - accuracy: 0.9814 - val_loss: 3.0044 - val_accuracy: 0.6987\n",
            "Epoch 23/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0411 - accuracy: 0.9790 - val_loss: 3.4949 - val_accuracy: 0.7303\n",
            "Epoch 24/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0443 - accuracy: 0.9799 - val_loss: 0.6339 - val_accuracy: 0.7504\n",
            "Epoch 25/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0461 - accuracy: 0.9760 - val_loss: 0.8738 - val_accuracy: 0.7361\n",
            "Epoch 26/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0397 - accuracy: 0.9807 - val_loss: 2.1634 - val_accuracy: 0.7314\n",
            "Epoch 27/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0321 - accuracy: 0.9834 - val_loss: 2.3646 - val_accuracy: 0.7377\n",
            "Epoch 28/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0448 - accuracy: 0.9787 - val_loss: 6.3329 - val_accuracy: 0.6359\n",
            "Epoch 29/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0466 - accuracy: 0.9795 - val_loss: 3.0539 - val_accuracy: 0.6929\n",
            "Epoch 30/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0369 - accuracy: 0.9815 - val_loss: 2.1470 - val_accuracy: 0.7177\n",
            "Epoch 31/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0329 - accuracy: 0.9819 - val_loss: 0.8601 - val_accuracy: 0.6934\n",
            "Epoch 32/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0384 - accuracy: 0.9819 - val_loss: 3.2937 - val_accuracy: 0.7546\n",
            "Epoch 33/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0437 - accuracy: 0.9798 - val_loss: 0.6087 - val_accuracy: 0.6839\n",
            "Epoch 34/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0324 - accuracy: 0.9822 - val_loss: 1.9531 - val_accuracy: 0.7456\n",
            "Epoch 35/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0291 - accuracy: 0.9831 - val_loss: 1.3453 - val_accuracy: 0.7198\n",
            "Epoch 36/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0331 - accuracy: 0.9814 - val_loss: 1.8558 - val_accuracy: 0.7372\n",
            "Epoch 37/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0303 - accuracy: 0.9819 - val_loss: 1.8444 - val_accuracy: 0.7546\n",
            "Epoch 38/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0373 - accuracy: 0.9806 - val_loss: 3.4142 - val_accuracy: 0.6839\n",
            "Epoch 39/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0298 - accuracy: 0.9831 - val_loss: 1.0910 - val_accuracy: 0.7615\n",
            "Epoch 40/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0325 - accuracy: 0.9819 - val_loss: 0.7753 - val_accuracy: 0.7662\n",
            "Epoch 41/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0310 - accuracy: 0.9819 - val_loss: 1.8373 - val_accuracy: 0.7520\n",
            "Epoch 42/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0264 - accuracy: 0.9840 - val_loss: 0.9889 - val_accuracy: 0.7504\n",
            "Epoch 43/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0414 - accuracy: 0.9826 - val_loss: 2.8995 - val_accuracy: 0.6997\n",
            "Epoch 44/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0279 - accuracy: 0.9843 - val_loss: 2.5049 - val_accuracy: 0.7235\n",
            "Epoch 45/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0411 - accuracy: 0.9803 - val_loss: 1.6125 - val_accuracy: 0.7145\n",
            "Epoch 46/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0312 - accuracy: 0.9839 - val_loss: 2.1762 - val_accuracy: 0.7504\n",
            "Epoch 47/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0275 - accuracy: 0.9831 - val_loss: 2.5873 - val_accuracy: 0.7520\n",
            "Epoch 48/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0303 - accuracy: 0.9820 - val_loss: 1.4508 - val_accuracy: 0.7351\n",
            "Epoch 49/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0288 - accuracy: 0.9828 - val_loss: 2.6298 - val_accuracy: 0.7594\n",
            "Epoch 50/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0335 - accuracy: 0.9822 - val_loss: 1.8577 - val_accuracy: 0.7599\n",
            "Epoch 51/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0329 - accuracy: 0.9839 - val_loss: 4.4818 - val_accuracy: 0.6850\n",
            "Epoch 52/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0342 - accuracy: 0.9832 - val_loss: 3.9538 - val_accuracy: 0.6834\n",
            "Epoch 53/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0322 - accuracy: 0.9826 - val_loss: 1.3059 - val_accuracy: 0.7567\n",
            "Epoch 54/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0278 - accuracy: 0.9855 - val_loss: 1.5693 - val_accuracy: 0.7668\n",
            "Epoch 55/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0254 - accuracy: 0.9840 - val_loss: 2.0576 - val_accuracy: 0.7726\n",
            "Epoch 56/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0229 - accuracy: 0.9851 - val_loss: 2.2306 - val_accuracy: 0.7726\n",
            "Epoch 57/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0245 - accuracy: 0.9852 - val_loss: 3.1799 - val_accuracy: 0.7340\n",
            "Epoch 58/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0282 - accuracy: 0.9835 - val_loss: 2.4287 - val_accuracy: 0.7430\n",
            "Epoch 59/100\n",
            "237/237 [==============================] - 7s 27ms/step - loss: 0.0329 - accuracy: 0.9838 - val_loss: 1.4361 - val_accuracy: 0.7351\n",
            "Epoch 60/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0400 - accuracy: 0.9806 - val_loss: 1.3563 - val_accuracy: 0.7509\n",
            "Epoch 61/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0309 - accuracy: 0.9828 - val_loss: 1.6217 - val_accuracy: 0.7520\n",
            "Epoch 62/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0248 - accuracy: 0.9856 - val_loss: 2.1919 - val_accuracy: 0.7641\n",
            "Epoch 63/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0283 - accuracy: 0.9834 - val_loss: 1.6376 - val_accuracy: 0.7509\n",
            "Epoch 64/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0273 - accuracy: 0.9834 - val_loss: 1.6074 - val_accuracy: 0.7631\n",
            "Epoch 65/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0265 - accuracy: 0.9831 - val_loss: 2.8525 - val_accuracy: 0.7710\n",
            "Epoch 66/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0279 - accuracy: 0.9850 - val_loss: 2.8036 - val_accuracy: 0.6417\n",
            "Epoch 67/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0262 - accuracy: 0.9830 - val_loss: 2.3313 - val_accuracy: 0.7594\n",
            "Epoch 68/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0266 - accuracy: 0.9846 - val_loss: 1.2318 - val_accuracy: 0.7414\n",
            "Epoch 69/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0267 - accuracy: 0.9838 - val_loss: 1.9896 - val_accuracy: 0.7520\n",
            "Epoch 70/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0265 - accuracy: 0.9844 - val_loss: 3.3010 - val_accuracy: 0.7509\n",
            "Epoch 71/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0287 - accuracy: 0.9844 - val_loss: 1.1817 - val_accuracy: 0.7773\n",
            "Epoch 72/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0272 - accuracy: 0.9842 - val_loss: 2.3301 - val_accuracy: 0.7704\n",
            "Epoch 73/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0266 - accuracy: 0.9847 - val_loss: 2.6155 - val_accuracy: 0.7319\n",
            "Epoch 74/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0384 - accuracy: 0.9802 - val_loss: 1.3356 - val_accuracy: 0.7150\n",
            "Epoch 75/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0252 - accuracy: 0.9868 - val_loss: 2.3922 - val_accuracy: 0.7166\n",
            "Epoch 76/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0261 - accuracy: 0.9850 - val_loss: 1.6246 - val_accuracy: 0.7747\n",
            "Epoch 77/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0224 - accuracy: 0.9847 - val_loss: 2.0098 - val_accuracy: 0.7520\n",
            "Epoch 78/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0246 - accuracy: 0.9830 - val_loss: 2.3181 - val_accuracy: 0.7662\n",
            "Epoch 79/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0226 - accuracy: 0.9850 - val_loss: 2.3734 - val_accuracy: 0.7657\n",
            "Epoch 80/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0258 - accuracy: 0.9856 - val_loss: 2.2153 - val_accuracy: 0.7720\n",
            "Epoch 81/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0263 - accuracy: 0.9846 - val_loss: 2.3842 - val_accuracy: 0.7224\n",
            "Epoch 82/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0278 - accuracy: 0.9844 - val_loss: 2.2916 - val_accuracy: 0.7346\n",
            "Epoch 83/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0205 - accuracy: 0.9857 - val_loss: 2.2775 - val_accuracy: 0.7710\n",
            "Epoch 84/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0211 - accuracy: 0.9856 - val_loss: 2.0320 - val_accuracy: 0.7636\n",
            "Epoch 85/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0322 - accuracy: 0.9832 - val_loss: 1.2404 - val_accuracy: 0.7731\n",
            "Epoch 86/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0251 - accuracy: 0.9855 - val_loss: 1.5399 - val_accuracy: 0.7446\n",
            "Epoch 87/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0236 - accuracy: 0.9869 - val_loss: 1.5394 - val_accuracy: 0.7668\n",
            "Epoch 88/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0259 - accuracy: 0.9857 - val_loss: 1.5672 - val_accuracy: 0.7541\n",
            "Epoch 89/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0302 - accuracy: 0.9843 - val_loss: 2.0236 - val_accuracy: 0.7583\n",
            "Epoch 90/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0265 - accuracy: 0.9835 - val_loss: 1.8893 - val_accuracy: 0.7678\n",
            "Epoch 91/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0268 - accuracy: 0.9836 - val_loss: 2.0973 - val_accuracy: 0.7689\n",
            "Epoch 92/100\n",
            "237/237 [==============================] - 7s 30ms/step - loss: 0.0204 - accuracy: 0.9856 - val_loss: 1.7990 - val_accuracy: 0.7810\n",
            "Epoch 93/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0202 - accuracy: 0.9850 - val_loss: 2.0993 - val_accuracy: 0.7710\n",
            "Epoch 94/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0272 - accuracy: 0.9839 - val_loss: 2.2548 - val_accuracy: 0.7393\n",
            "Epoch 95/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0245 - accuracy: 0.9848 - val_loss: 2.1374 - val_accuracy: 0.7736\n",
            "Epoch 96/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0213 - accuracy: 0.9853 - val_loss: 2.0612 - val_accuracy: 0.7736\n",
            "Epoch 97/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0266 - accuracy: 0.9876 - val_loss: 0.9017 - val_accuracy: 0.7720\n",
            "Epoch 98/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0271 - accuracy: 0.9839 - val_loss: 2.3976 - val_accuracy: 0.7683\n",
            "Epoch 99/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0203 - accuracy: 0.9850 - val_loss: 2.7238 - val_accuracy: 0.7810\n",
            "Epoch 100/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0290 - accuracy: 0.9838 - val_loss: 4.7250 - val_accuracy: 0.7736\n",
            "Training Model 5\n",
            "Epoch 1/100\n",
            "237/237 [==============================] - 38s 135ms/step - loss: 0.7660 - accuracy: 0.5422 - val_loss: 0.6939 - val_accuracy: 0.5208\n",
            "Epoch 2/100\n",
            "237/237 [==============================] - 15s 64ms/step - loss: 0.5581 - accuracy: 0.7008 - val_loss: 1.1425 - val_accuracy: 0.4792\n",
            "Epoch 3/100\n",
            "237/237 [==============================] - 12s 51ms/step - loss: 0.3568 - accuracy: 0.8457 - val_loss: 0.6391 - val_accuracy: 0.7388\n",
            "Epoch 4/100\n",
            "237/237 [==============================] - 9s 39ms/step - loss: 0.2085 - accuracy: 0.9170 - val_loss: 13.5401 - val_accuracy: 0.5208\n",
            "Epoch 5/100\n",
            "237/237 [==============================] - 8s 34ms/step - loss: 0.1588 - accuracy: 0.9393 - val_loss: 1.6315 - val_accuracy: 0.6544\n",
            "Epoch 6/100\n",
            "237/237 [==============================] - 8s 35ms/step - loss: 0.1237 - accuracy: 0.9546 - val_loss: 0.5132 - val_accuracy: 0.7636\n",
            "Epoch 7/100\n",
            "237/237 [==============================] - 7s 30ms/step - loss: 0.1026 - accuracy: 0.9609 - val_loss: 1.8286 - val_accuracy: 0.6533\n",
            "Epoch 8/100\n",
            "237/237 [==============================] - 8s 35ms/step - loss: 0.1048 - accuracy: 0.9609 - val_loss: 5.8781 - val_accuracy: 0.5230\n",
            "Epoch 9/100\n",
            "237/237 [==============================] - 7s 31ms/step - loss: 0.0887 - accuracy: 0.9638 - val_loss: 4.8994 - val_accuracy: 0.5103\n",
            "Epoch 10/100\n",
            "237/237 [==============================] - 7s 27ms/step - loss: 0.0755 - accuracy: 0.9715 - val_loss: 9.6175 - val_accuracy: 0.4818\n",
            "Epoch 11/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0673 - accuracy: 0.9751 - val_loss: 1.3266 - val_accuracy: 0.6317\n",
            "Epoch 12/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0673 - accuracy: 0.9729 - val_loss: 1.9751 - val_accuracy: 0.7668\n",
            "Epoch 13/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0545 - accuracy: 0.9773 - val_loss: 1.0577 - val_accuracy: 0.7325\n",
            "Epoch 14/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0648 - accuracy: 0.9728 - val_loss: 1.2780 - val_accuracy: 0.7203\n",
            "Epoch 15/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0614 - accuracy: 0.9735 - val_loss: 4.5215 - val_accuracy: 0.6628\n",
            "Epoch 16/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0549 - accuracy: 0.9785 - val_loss: 4.5456 - val_accuracy: 0.5910\n",
            "Epoch 17/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0606 - accuracy: 0.9743 - val_loss: 0.5232 - val_accuracy: 0.7325\n",
            "Epoch 18/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0497 - accuracy: 0.9785 - val_loss: 1.0890 - val_accuracy: 0.7573\n",
            "Epoch 19/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0534 - accuracy: 0.9764 - val_loss: 2.7857 - val_accuracy: 0.5224\n",
            "Epoch 20/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0524 - accuracy: 0.9749 - val_loss: 2.1769 - val_accuracy: 0.6517\n",
            "Epoch 21/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0412 - accuracy: 0.9790 - val_loss: 4.8345 - val_accuracy: 0.6507\n",
            "Epoch 22/100\n",
            "237/237 [==============================] - 7s 29ms/step - loss: 0.0418 - accuracy: 0.9791 - val_loss: 1.8952 - val_accuracy: 0.7108\n",
            "Epoch 23/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0386 - accuracy: 0.9828 - val_loss: 0.6569 - val_accuracy: 0.7757\n",
            "Epoch 24/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0370 - accuracy: 0.9806 - val_loss: 2.4388 - val_accuracy: 0.7129\n",
            "Epoch 25/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0338 - accuracy: 0.9822 - val_loss: 8.9094 - val_accuracy: 0.5156\n",
            "Epoch 26/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0448 - accuracy: 0.9785 - val_loss: 2.1124 - val_accuracy: 0.6966\n",
            "Epoch 27/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0460 - accuracy: 0.9773 - val_loss: 3.1452 - val_accuracy: 0.6522\n",
            "Epoch 28/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0358 - accuracy: 0.9813 - val_loss: 2.7092 - val_accuracy: 0.6686\n",
            "Epoch 29/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0339 - accuracy: 0.9819 - val_loss: 1.8476 - val_accuracy: 0.7562\n",
            "Epoch 30/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0365 - accuracy: 0.9813 - val_loss: 3.4585 - val_accuracy: 0.7018\n",
            "Epoch 31/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0353 - accuracy: 0.9814 - val_loss: 1.3276 - val_accuracy: 0.7736\n",
            "Epoch 32/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0334 - accuracy: 0.9822 - val_loss: 2.2769 - val_accuracy: 0.7108\n",
            "Epoch 33/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0318 - accuracy: 0.9838 - val_loss: 1.6367 - val_accuracy: 0.7414\n",
            "Epoch 34/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0372 - accuracy: 0.9798 - val_loss: 5.4256 - val_accuracy: 0.6406\n",
            "Epoch 35/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0273 - accuracy: 0.9839 - val_loss: 2.7251 - val_accuracy: 0.7372\n",
            "Epoch 36/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0446 - accuracy: 0.9786 - val_loss: 1.2539 - val_accuracy: 0.7689\n",
            "Epoch 37/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0330 - accuracy: 0.9809 - val_loss: 2.9619 - val_accuracy: 0.7446\n",
            "Epoch 38/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0304 - accuracy: 0.9835 - val_loss: 1.5911 - val_accuracy: 0.7757\n",
            "Epoch 39/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0300 - accuracy: 0.9826 - val_loss: 1.9932 - val_accuracy: 0.7689\n",
            "Epoch 40/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0325 - accuracy: 0.9826 - val_loss: 1.4319 - val_accuracy: 0.7726\n",
            "Epoch 41/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0327 - accuracy: 0.9822 - val_loss: 1.1783 - val_accuracy: 0.7351\n",
            "Epoch 42/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0352 - accuracy: 0.9815 - val_loss: 1.3272 - val_accuracy: 0.7678\n",
            "Epoch 43/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0244 - accuracy: 0.9848 - val_loss: 3.5056 - val_accuracy: 0.7298\n",
            "Epoch 44/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0313 - accuracy: 0.9831 - val_loss: 1.4805 - val_accuracy: 0.7541\n",
            "Epoch 45/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0398 - accuracy: 0.9815 - val_loss: 3.5887 - val_accuracy: 0.6327\n",
            "Epoch 46/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0352 - accuracy: 0.9819 - val_loss: 1.5179 - val_accuracy: 0.7646\n",
            "Epoch 47/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0254 - accuracy: 0.9861 - val_loss: 2.0108 - val_accuracy: 0.7541\n",
            "Epoch 48/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0314 - accuracy: 0.9835 - val_loss: 1.7393 - val_accuracy: 0.7309\n",
            "Epoch 49/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0298 - accuracy: 0.9836 - val_loss: 1.9924 - val_accuracy: 0.7420\n",
            "Epoch 50/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0251 - accuracy: 0.9848 - val_loss: 1.5927 - val_accuracy: 0.7525\n",
            "Epoch 51/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0388 - accuracy: 0.9822 - val_loss: 1.6460 - val_accuracy: 0.7652\n",
            "Epoch 52/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0292 - accuracy: 0.9838 - val_loss: 1.7321 - val_accuracy: 0.7720\n",
            "Epoch 53/100\n",
            "237/237 [==============================] - 7s 28ms/step - loss: 0.0294 - accuracy: 0.9836 - val_loss: 1.2368 - val_accuracy: 0.7420\n",
            "Epoch 54/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0254 - accuracy: 0.9846 - val_loss: 1.3151 - val_accuracy: 0.7768\n",
            "Epoch 55/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0253 - accuracy: 0.9839 - val_loss: 3.8779 - val_accuracy: 0.7303\n",
            "Epoch 56/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0219 - accuracy: 0.9856 - val_loss: 2.6367 - val_accuracy: 0.7578\n",
            "Epoch 57/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0268 - accuracy: 0.9834 - val_loss: 1.7997 - val_accuracy: 0.7720\n",
            "Epoch 58/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0236 - accuracy: 0.9859 - val_loss: 1.4543 - val_accuracy: 0.7794\n",
            "Epoch 59/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0360 - accuracy: 0.9813 - val_loss: 2.1175 - val_accuracy: 0.7509\n",
            "Epoch 60/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0340 - accuracy: 0.9831 - val_loss: 1.2420 - val_accuracy: 0.7662\n",
            "Epoch 61/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0268 - accuracy: 0.9846 - val_loss: 1.7481 - val_accuracy: 0.7451\n",
            "Epoch 62/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0252 - accuracy: 0.9852 - val_loss: 2.0176 - val_accuracy: 0.7340\n",
            "Epoch 63/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0285 - accuracy: 0.9847 - val_loss: 1.6685 - val_accuracy: 0.7161\n",
            "Epoch 64/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0310 - accuracy: 0.9828 - val_loss: 2.3615 - val_accuracy: 0.7683\n",
            "Epoch 65/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0292 - accuracy: 0.9844 - val_loss: 1.6727 - val_accuracy: 0.7509\n",
            "Epoch 66/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0245 - accuracy: 0.9840 - val_loss: 2.5715 - val_accuracy: 0.7620\n",
            "Epoch 67/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0294 - accuracy: 0.9847 - val_loss: 1.3453 - val_accuracy: 0.7646\n",
            "Epoch 68/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0217 - accuracy: 0.9863 - val_loss: 2.1301 - val_accuracy: 0.7799\n",
            "Epoch 69/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0252 - accuracy: 0.9859 - val_loss: 1.7090 - val_accuracy: 0.7784\n",
            "Epoch 70/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0231 - accuracy: 0.9851 - val_loss: 1.8078 - val_accuracy: 0.7741\n",
            "Epoch 71/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0327 - accuracy: 0.9820 - val_loss: 1.9079 - val_accuracy: 0.7398\n",
            "Epoch 72/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0286 - accuracy: 0.9848 - val_loss: 1.6195 - val_accuracy: 0.7821\n",
            "Epoch 73/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0287 - accuracy: 0.9839 - val_loss: 1.6358 - val_accuracy: 0.7451\n",
            "Epoch 74/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0269 - accuracy: 0.9848 - val_loss: 2.0909 - val_accuracy: 0.7683\n",
            "Epoch 75/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0242 - accuracy: 0.9852 - val_loss: 1.2855 - val_accuracy: 0.7773\n",
            "Epoch 76/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0223 - accuracy: 0.9857 - val_loss: 2.0361 - val_accuracy: 0.7842\n",
            "Epoch 77/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0245 - accuracy: 0.9850 - val_loss: 2.0095 - val_accuracy: 0.7551\n",
            "Epoch 78/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0264 - accuracy: 0.9857 - val_loss: 2.4271 - val_accuracy: 0.7815\n",
            "Epoch 79/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0274 - accuracy: 0.9851 - val_loss: 1.2776 - val_accuracy: 0.7625\n",
            "Epoch 80/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0259 - accuracy: 0.9856 - val_loss: 2.2458 - val_accuracy: 0.7430\n",
            "Epoch 81/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0265 - accuracy: 0.9856 - val_loss: 3.1649 - val_accuracy: 0.7013\n",
            "Epoch 82/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0240 - accuracy: 0.9865 - val_loss: 2.2483 - val_accuracy: 0.7815\n",
            "Epoch 83/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0341 - accuracy: 0.9810 - val_loss: 1.9158 - val_accuracy: 0.7636\n",
            "Epoch 84/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0250 - accuracy: 0.9836 - val_loss: 1.5938 - val_accuracy: 0.7873\n",
            "Epoch 85/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0215 - accuracy: 0.9851 - val_loss: 1.6535 - val_accuracy: 0.7741\n",
            "Epoch 86/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0195 - accuracy: 0.9859 - val_loss: 2.0313 - val_accuracy: 0.7736\n",
            "Epoch 87/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0216 - accuracy: 0.9850 - val_loss: 1.9499 - val_accuracy: 0.7752\n",
            "Epoch 88/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0226 - accuracy: 0.9867 - val_loss: 2.6195 - val_accuracy: 0.7551\n",
            "Epoch 89/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0213 - accuracy: 0.9867 - val_loss: 2.1354 - val_accuracy: 0.7747\n",
            "Epoch 90/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0251 - accuracy: 0.9848 - val_loss: 2.0283 - val_accuracy: 0.7646\n",
            "Epoch 91/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0312 - accuracy: 0.9827 - val_loss: 2.0640 - val_accuracy: 0.7504\n",
            "Epoch 92/100\n",
            "237/237 [==============================] - 7s 27ms/step - loss: 0.0284 - accuracy: 0.9823 - val_loss: 2.2681 - val_accuracy: 0.7414\n",
            "Epoch 93/100\n",
            "237/237 [==============================] - 6s 24ms/step - loss: 0.0281 - accuracy: 0.9840 - val_loss: 1.9973 - val_accuracy: 0.7747\n",
            "Epoch 94/100\n",
            "237/237 [==============================] - 6s 26ms/step - loss: 0.0254 - accuracy: 0.9861 - val_loss: 2.8356 - val_accuracy: 0.7462\n",
            "Epoch 95/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0296 - accuracy: 0.9831 - val_loss: 1.7007 - val_accuracy: 0.7799\n",
            "Epoch 96/100\n",
            "237/237 [==============================] - 6s 27ms/step - loss: 0.0212 - accuracy: 0.9855 - val_loss: 2.4314 - val_accuracy: 0.7736\n",
            "Epoch 97/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0245 - accuracy: 0.9875 - val_loss: 2.3315 - val_accuracy: 0.7794\n",
            "Epoch 98/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0275 - accuracy: 0.9844 - val_loss: 2.0568 - val_accuracy: 0.7678\n",
            "Epoch 99/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0218 - accuracy: 0.9861 - val_loss: 1.6643 - val_accuracy: 0.7794\n",
            "Epoch 100/100\n",
            "237/237 [==============================] - 6s 25ms/step - loss: 0.0205 - accuracy: 0.9863 - val_loss: 1.8331 - val_accuracy: 0.7900\n",
            "74/74 [==============================] - 1s 11ms/step\n",
            "74/74 [==============================] - 2s 8ms/step\n",
            "74/74 [==============================] - 1s 8ms/step\n",
            "74/74 [==============================] - 1s 8ms/step\n",
            "74/74 [==============================] - 1s 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.79      0.80      1188\n",
            "           1       0.79      0.81      0.80      1180\n",
            "\n",
            "    accuracy                           0.80      2368\n",
            "   macro avg       0.80      0.80      0.80      2368\n",
            "weighted avg       0.80      0.80      0.80      2368\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(f\"Test Accuracy: {accuracy[1] * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPqE1-YdujKz",
        "outputId": "c468005b-09ec-4241-ba6f-4daeaf111eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 1s 16ms/step - loss: 1.7861 - accuracy: 0.7867\n",
            "Test Accuracy: 78.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "# Calculate ROC-AUC scores for each model\n",
        "roc_auc_scores = [roc_auc_score(y_test, prediction) for prediction in predictions]\n",
        "\n",
        "# Calculate average ROC-AUC score\n",
        "avg_roc_auc = np.mean(roc_auc_scores)\n",
        "\n",
        "# Compute the ROC curve and ROC-AUC for the ensemble predictions\n",
        "fpr, tpr, _ = roc_curve(y_test, ensemble_predictions)\n",
        "roc_auc = roc_auc_score(y_test, ensemble_predictions)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Ensemble ROC-AUC (Avg = {avg_roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "dIEiPkRIunCM",
        "outputId": "f5c315dd-44d7-4418-d7db-bd3c42658c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHHCAYAAABTMjf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACNEElEQVR4nOzdd1hT1xsH8G8SIOw9VZShILjBiXtTJ2oViwOte7auXx111bq31rqq4qyjolIXrdZd6sAtCAqiqIAgG5nJ+f0RCUSGCSZcIO/neXg8Obn35k1iyMuZPMYYAyGEEEKIGuJzHQAhhBBCCFcoESKEEEKI2qJEiBBCCCFqixIhQgghhKgtSoQIIYQQorYoESKEEEKI2qJEiBBCCCFqixIhQgghhKgtSoQIIYQQorYoESJESezs7DBixAiuw1A7HTp0QIcOHbgO47MWLVoEHo+HhIQErkOpcHg8HhYtWqSUa0VFRYHH48HPz08p1yNVHyVCpFLw8/MDj8eT/mhoaKB69eoYMWIE3rx5w3V4FVpGRgaWLFmChg0bQldXF0ZGRmjbti327duHyrLDTkhICBYtWoSoqCiuQylCJBJhz5496NChA0xNTSEUCmFnZ4eRI0fizp07XIenFIcOHcKGDRu4DkNGRYyJVE4aXAdAiCJ++ukn2NvbIysrC//99x/8/Pxw/fp1PH78GNra2pzGFhYWBj6/Yv1tERcXh86dOyM0NBSDBw/G5MmTkZWVhePHj8PX1xdnz57FwYMHIRAIuA61VCEhIVi8eDE6dOgAOzs7mfv++usvboICkJmZif79++P8+fNo164d5s6dC1NTU0RFReHo0aPYu3cvXr16hRo1anAWozIcOnQIjx8/xvfff6+S62dmZkJDQ7Gvo5JiqlWrFjIzM6GpqanECElVRokQqVS++uorNG3aFAAwevRomJubY+XKlQgICMCgQYM4jU0oFJb7Y2ZlZUFLS6vEBMzX1xehoaE4ceIE+vTpI62fOnUqZs2ahTVr1qBJkyb44YcfyitkAJJWKj09PaVcS0tLSynXKYtZs2bh/PnzWL9+fZEv5IULF2L9+vXlGg9jDFlZWdDR0SnXxy0LsViMnJwcaGtrK/WPGB6Px/kfRaSSYYRUAnv27GEA2O3bt2XqT58+zQCwZcuWydSHhoayAQMGMBMTEyYUCpm7uzs7depUkesmJSWx77//ntWqVYtpaWmx6tWrs2HDhrH4+HjpMVlZWWzBggXM0dGRaWlpsRo1arBZs2axrKwsmWvVqlWL+fr6MsYYu337NgPA/Pz8ijzm+fPnGQD2559/Sutev37NRo4cySwtLZmWlhZzdXVlu3btkjnv0qVLDAD7/fff2bx581i1atUYj8djSUlJxb5mQUFBDAD79ttvi70/NzeX1alTh5mYmLAPHz4wxhh78eIFA8BWr17N1q1bx2rWrMm0tbVZu3bt2KNHj4pcQ57XOf+9u3z5MpswYQKzsLBgxsbGjDHGoqKi2IQJE5iTkxPT1tZmpqam7Ouvv2YvXrwocv6nP5cuXWKMMda+fXvWvn37Iq/TkSNH2M8//8yqV6/OhEIh69SpE3v27FmR5/DLL78we3t7pq2tzZo1a8auXr1a5JrFiY6OZhoaGqxr166lHpdv4cKFDAB79uwZ8/X1ZUZGRszQ0JCNGDGCZWRkyBy7e/du1rFjR2ZhYcG0tLSYi4sL+/XXX4tcs1atWqxnz57s/PnzzN3dnQmFQrZ+/XqFrsEYY2fPnmXt2rVj+vr6zMDAgDVt2pQdPHiQMSZ5fT997WvVqiU9V97PBwA2adIkduDAAebq6so0NDTYiRMnpPctXLhQemxqair77rvvpJ9LCwsL1qVLFxYcHPzZmPL/D+/Zs0fm8UNDQ9nAgQOZubk509bWZk5OTmzu3LmlvWVETVCLEKnU8seMmJiYSOuePHmC1q1bo3r16pg9ezb09PRw9OhReHl54fjx4+jXrx8AID09HW3btkVoaCi+/fZbuLm5ISEhAQEBAXj9+jXMzc0hFovRp08fXL9+HWPHjoWLiwsePXqE9evXIzw8HCdPniw2rqZNm8LBwQFHjx6Fr6+vzH1HjhyBiYkJunfvDkDSfdWyZUvweDxMnjwZFhYWOHfuHEaNGoXU1NQiLQ1LliyBlpYWZs6ciezs7BJbRP78808AwPDhw4u9X0NDAz4+Pli8eDFu3LiBLl26SO/bt28f0tLSMGnSJGRlZWHjxo3o1KkTHj16BCsrK4Ve53wTJ06EhYUFFixYgIyMDADA7du38e+//2Lw4MGoUaMGoqKisHXrVnTo0AEhISHQ1dVFu3btMHXqVGzatAlz586Fi4sLAEj/LcmKFSvA5/Mxc+ZMpKSkYNWqVRgyZAhu3rwpPWbr1q2YPHky2rZti2nTpiEqKgpeXl4wMTH5bHfWuXPnkJeXh2HDhpV63KcGDRoEe3t7LF++HHfv3sVvv/0GS0tLrFy5UiauevXqoU+fPtDQ0MCff/6JiRMnQiwWY9KkSTLXCwsLwzfffINx48ZhzJgxcHZ2Vugafn5++Pbbb1GvXj3MmTMHxsbGuHfvHs6fPw8fHx/MmzcPKSkpeP36tbSFS19fHwAU/nz8888/OHr0KCZPngxzc/Mi3Zz5xo8fjz/++AOTJ0+Gq6sr3r9/j+vXryM0NBRubm6lxlSchw8fom3bttDU1MTYsWNhZ2eHiIgI/Pnnn1i6dKl8bxypurjOxAiRR36rwIULF1h8fDyLjo5mf/zxB7OwsGBCoZBFR0dLj+3cuTNr0KCBzF+kYrGYeXh4sDp16kjrFixYwAAwf3//Io8nFosZY4zt37+f8fl8du3aNZn7t23bxgCwGzduSOsKtwgxxticOXOYpqYmS0xMlNZlZ2czY2NjmVaaUaNGMRsbG5aQkCDzGIMHD2ZGRkbS1pr8lg4HBwdpXWm8vLwYgBJbjBhjzN/fnwFgmzZtYowV/DWto6PDXr9+LT3u5s2bDACbNm2atE7e1zn/vWvTpg3Ly8uTefzinkd+S9a+ffukdceOHZNpBSqspBYhFxcXlp2dLa3fuHEjAyBt2crOzmZmZmasWbNmLDc3V3qcn58fA/DZFqFp06YxAOzevXulHpcvv0Xo0xa6fv36MTMzM5m64l6X7t27MwcHB5m6WrVqMQDs/PnzRY6X5xrJycnMwMCAtWjRgmVmZsocm/8ZYIyxnj17yrQC5VPk8wGA8fl89uTJkyLXwSctQkZGRmzSpElFjiuspJiKaxFq164dMzAwYC9fvizxORL1VbFGdhLyGV26dIGFhQVsbW3x9ddfQ09PDwEBAdK/3hMTE/HPP/9g0KBBSEtLQ0JCAhISEvD+/Xt0794dz549k84yO378OBo1alSk5QKQjDMAgGPHjsHFxQV169aVXishIQGdOnUCAFy6dKnEWL29vZGbmwt/f39p3V9//YXk5GR4e3sDkIzpOH78OHr37g3GmMxjdO/eHSkpKbh7967MdX19feUaA5KWlgYAMDAwKPGY/PtSU1Nl6r28vFC9enXp7ebNm6NFixY4e/YsAMVe53xjxowpMii78PPIzc3F+/fvUbt2bRgbGxd53ooaOXKkTGtZ27ZtAQCRkZEAgDt37uD9+/cYM2aMzEDdIUOGyLQwliT/NSvt9S3O+PHjZW63bdsW79+/l3kPCr8uKSkpSEhIQPv27REZGYmUlBSZ8+3t7aWti4XJc42///4baWlpmD17dpFxNfmfgdIo+vlo3749XF1dP3tdY2Nj3Lx5E2/fvv3ssZ8THx+Pq1ev4ttvv0XNmjVl7pPnOZKqj7rGSKWyZcsWODk5ISUlBbt378bVq1dlBik/f/4cjDHMnz8f8+fPL/Ya7969Q/Xq1REREYEBAwaU+njPnj1DaGgoLCwsSrxWSRo1aoS6deviyJEjGDVqFABJt5i5ubn0iyI+Ph7JycnYsWMHduzYIddj2Nvblxpzvvwv6LS0NBgbGxd7TEnJUp06dYoc6+TkhKNHjwJQ7HUuLe7MzEwsX74ce/bswZs3b2Sm83/6ha+oT7/08pObpKQkAMDLly8BALVr15Y5TkNDo8Qum8IMDQ0BFLyGyogr/5o3btzAwoULERQUhA8fPsgcn5KSAiMjI+ntkv4/yHONiIgIAED9+vUVeg75FP18yPt/d9WqVfD19YWtrS3c3d3Ro0cPDB8+HA4ODgrHmJ/4lvU5kqqPEiFSqTRv3lw6a8zLywtt2rSBj48PwsLCoK+vD7FYDACYOXNmsX8lA0W/+EojFovRoEEDrFu3rtj7bW1tSz3f29sbS5cuRUJCAgwMDBAQEIBvvvlG2gKRH+/QoUOLjCXK17BhQ5nb8s4IcnFxwcmTJ/Hw4UO0a9eu2GMePnwIAHL9lV5YWV7n4uKeMmUK9uzZg++//x6tWrWCkZEReDweBg8eLH2MsippSQCmpLWT6tatCwB49OgRGjduLPd5n4srIiICnTt3Rt26dbFu3TrY2tpCS0sLZ8+exfr164u8LsW9ropeo6wU/XzI+3930KBBaNu2LU6cOIG//voLq1evxsqVK+Hv74+vvvrqi+MmpDBKhEilJRAIsHz5cnTs2BG//PILZs+eLf2LUVNTU2bwb3EcHR3x+PHjzx7z4MEDdO7cuUzN6N7e3li8eDGOHz8OKysrpKamYvDgwdL7LSwsYGBgAJFI9Nl4FdWrVy8sX74c+/btKzYREolEOHToEExMTNC6dWuZ+549e1bk+PDwcGlLiSKvc2n++OMP+Pr6Yu3atdK6rKwsJCcnyxynii6MWrVqAZC0bnXs2FFan5eXh6ioqCIJ6Ke++uorCAQCHDhwQOEB06X5888/kZ2djYCAAJnWo9K6Yct6DUdHRwDA48ePS/0DoaTX/0s/H6WxsbHBxIkTMXHiRLx79w5ubm5YunSpNBGS9/Hy/69+7rNO1BeNESKVWocOHdC8eXNs2LABWVlZsLS0RIcOHbB9+3bExMQUOT4+Pl5aHjBgAB48eIATJ04UOS7/r/NBgwbhzZs32LlzZ5FjMjMzpbOfSuLi4oIGDRrgyJEjOHLkCGxsbGSSEoFAgAEDBuD48ePF/qIuHK+iPDw80KVLF+zZswenT58ucv+8efMQHh6O//3vf0X+Uj958qTMGJ9bt27h5s2b0i8hRV7n0ggEgiItNJs3b4ZIJJKpy19z6NME6Us0bdoUZmZm2LlzJ/Ly8qT1Bw8elHaflcbW1hZjxozBX3/9hc2bNxe5XywWY+3atXj9+rVCceW3GH3aTbhnzx6lX6Nbt24wMDDA8uXLkZWVJXNf4XP19PSK7ar80s9HcUQiUZHHsrS0RLVq1ZCdnf3ZmD5lYWGBdu3aYffu3Xj16pXMfcpqHSSVG7UIkUpv1qxZGDhwIPz8/DB+/Hhs2bIFbdq0QYMGDTBmzBg4ODggLi4OQUFBeP36NR48eCA9748//sDAgQPx7bffwt3dHYmJiQgICMC2bdvQqFEjDBs2DEePHsX48eNx6dIltG7dGiKRCE+fPsXRo0cRGBgo7aoribe3NxYsWABtbW2MGjWqyOKHK1aswKVLl9CiRQuMGTMGrq6uSExMxN27d3HhwgUkJiaW+bXZt28fOnfujL59+8LHxwdt27ZFdnY2/P39cfnyZXh7e2PWrFlFzqtduzbatGmDCRMmIDs7Gxs2bICZmRn+97//SY+R93UuTa9evbB//34YGRnB1dUVQUFBuHDhAszMzGSOa9y4MQQCAVauXImUlBQIhUJ06tQJlpaWZX5ttLS0sGjRIkyZMgWdOnXCoEGDEBUVBT8/Pzg6OsrV4rB27VpERERg6tSp8Pf3R69evWBiYoJXr17h2LFjePr0qUwLoDy6desGLS0t9O7dG+PGjUN6ejp27twJS0vLYpPOL7mGoaEh1q9fj9GjR6NZs2bw8fGBiYkJHjx4gA8fPmDv3r0AAHd3dxw5cgTTp09Hs2bNoK+vj969eyvl8/GptLQ01KhRA19//TUaNWoEfX19XLhwAbdv35ZpOSwppuJs2rQJbdq0gZubG8aOHQt7e3tERUXhzJkzuH//vkLxkSqIk7lqhCiopAUVGWNMJBIxR0dH5ujoKJ2eHRERwYYPH86sra2ZpqYmq169OuvVqxf7448/ZM59//49mzx5Mqtevbp0MThfX1+Zqew5OTls5cqVrF69ekwoFDITExPm7u7OFi9ezFJSUqTHfTp9Pt+zZ8+ki75dv3692OcXFxfHJk2axGxtbZmmpiaztrZmnTt3Zjt27JAekz8t/NixYwq9dmlpaWzRokWsXr16TEdHhxkYGLDWrVszPz+/ItOHCy+ouHbtWmZra8uEQiFr27Yte/DgQZFry/M6l/beJSUlsZEjRzJzc3Omr6/Punfvzp4+fVrsa7lz507m4ODABAKBXAsqfvo6lbTQ3qZNm1itWrWYUChkzZs3Zzdu3GDu7u7M09NTjleXsby8PPbbb7+xtm3bMiMjI6apqclq1arFRo4cKTO1Pn/6fOHFOgu/PoUXkQwICGANGzZk2trazM7Ojq1cuZLt3r27yHH5CyoWR95r5B/r4eHBdHR0mKGhIWvevDn7/fffpfenp6czHx8fZmxsXGRBRXk/H/i4oGJxUGj6fHZ2Nps1axZr1KgRMzAwYHp6eqxRo0ZFFoMsKaaS3ufHjx+zfv36MWNjY6atrc2cnZ3Z/Pnzi42HqBceY9Q2SAiRiIqKgr29PVavXo2ZM2dyHQ4nxGIxLCws0L9//2K7fAghVQuNESKEqK2srKwi40T27duHxMREdOjQgZugCCHlisYIEULU1n///Ydp06Zh4MCBMDMzw927d7Fr1y7Ur18fAwcO5Do8Qkg5oESIEKK27OzsYGtri02bNiExMRGmpqYYPnw4VqxYwemu9oSQ8kNjhAghhBCitmiMECGEEELUFiVChBBCCFFbajdGSCwW4+3btzAwMKCdhwkhhJBKgjGGtLQ0VKtWrcjCtF9C7RKht2/ffnajTEIIIYRUTNHR0ahRo4bSrqd2iZCBgQEAyQtpaGjIcTSEEEIIkUdqaipsbW2l3+PKonaJUH53mKGhISVChBBCSCWj7GEtNFiaEEIIIWqLEiFCCCGEqC1KhAghhBCitigRIoQQQojaokSIEEIIIWqLEiFCCCGEqC1KhAghhBCitigRIoQQQojaokSIEEIIIWqLEiFCCCGEqC1OE6GrV6+id+/eqFatGng8Hk6ePPnZcy5fvgw3NzcIhULUrl0bfn5+Ko+TEEIIIVUTp4lQRkYGGjVqhC1btsh1/IsXL9CzZ0907NgR9+/fx/fff4/Ro0cjMDBQxZESQgghpCridNPVr776Cl999ZXcx2/btg329vZYu3YtAMDFxQXXr1/H+vXr0b17d1WFSQghhJAqqlLtPh8UFIQuXbrI1HXv3h3ff/89NwERQgghRHVy0oD3IRC/e4Qn1+6r5CEqVSIUGxsLKysrmTorKyukpqYiMzMTOjo6Rc7Jzs5Gdna29HZqaqrK4ySEEEKIAnIzgcSnwPvHQMKTj/8+BlJfIiZVHyOPeOFKhLVKHrpSJUJlsXz5cixevJjrMAghhBAiygWSn0mSnPyf90+A5OcAExc5/NRjZ4w+1gcJGXoAslQSUqVKhKytrREXFydTFxcXB0NDw2JbgwBgzpw5mD59uvR2amoqbG1tVRonIYQQotbEIiDlxcdEp1ArT2IYIM6V6xLx2ZYY8vtAZGRLUhVLM028e6/8UCtVItSqVSucPXtWpu7vv/9Gq1atSjxHKBRCKBSqOjRCCCFE/TAGpEVLWnUKt/IkhgJ5mfJdQ0MbMHUFzOsDZvUk/5rXh4WBLTZY3sOYMX/Cy6su1q1rDweHJUp/CpwmQunp6Xj+/Ln09osXL3D//n2YmpqiZs2amDNnDt68eYN9+/YBAMaPH49ffvkF//vf//Dtt9/in3/+wdGjR3HmzBmungIhhBBS9TEGfHhXqIUnv5XnCZAj59hbvgZgWrcg2TGrD5jXA4wcAL4AIpEYeXliCIUFqcmoUU1ga2uIbt0ckZaWppKnxmkidOfOHXTs2FF6O78Ly9fXF35+foiJicGrV6+k99vb2+PMmTOYNm0aNm7ciBo1auC3336jqfOEEEKIsmQlFYzdKdzKkyVvvxQPMKn9MdEp1MpjUgcQaBV7RnR0CoYPP4n69S2weXOPgivxeOjevbYSnlQp0TLGmEofoYJJTU2FkZERUlJSYGhoyHU4hBBCCDdy0oH3IUXH8aS/lf8ahrVkkx2z+pJWH83ix+0W5+jRJxg37jSSkyWDoc+c8UGPHnWKHKeq7+9KNUaIEEIIIQrKy/o4Nf2TFp7UKPmvoWdd0MKTn/iYuQLCsickqanZmDr1HPbufSCts7U1hIFB8a1GqkKJECGEEFIViHIl09Cl09I/tvIkPyt2anqxtE0A8wYyg5ZhVg/QMVNqqEFB0Rg69AQiI5Okdd7e9bB1a0+YmMjfmqQMlAgRQgghlQkTF5qaXqiVJ/Gp3FPToakvGaj8aSuPnjXA46ks9Lw8MZYuvYolS65CJJKMzDEw0MKWLT0wdGhD8FT42CWhRIgQQgipiBgD0t8UbeF5HwLkfZDvGgKhpAvrk6npMLAFeOW77/r79x/Qu/fvCAp6La3z8LDFgQP9YG9vUq6xFEaJECGEEMK1/Knpn7byKDI13cSpaAuPsSPAF6g2djkZG2tDQ0OSfAkEPCxY0B5z57aV1nGFEiFCCCGkvGQlyyY6+a08mfFyXoAnSW7MP52a7lTi1PSKQiDgY//+fujf/yi2bOmBli1rcB0SAEqECCGEEOXLzSiYml64lSf9jfzXMKhZdByPaV1AU1d1cSvRlStR0NHRRPPm1aV1tWoZ486dMZyMBSoJJUKEEEJIWeVlF52a/v6xZDCzvHStirbwmLkCQiPVxa1COTkiLFx4CStX3oC9vQnu3x8HA4OCra4qUhIEUCJECCGEfJ44D0h6XrC9RH7ik/QMYCL5riE0lkxNL9zKY1YP0DVXaejlKSwsAT4+/rh7NwYAEBmZhK1b7+B//2vNcWQlo0SIEEIIycfEQEpU0RaexKeAKEe+a2jqFV2Hx7w+oGej0qnpXGKMYefOu/j++/PIzMwDAGhq8rF0aSfMmOHBcXSlo0SIEEKI+mFMspWEdAPR/FaeJ4pNTTd1KTqOx7BmuU9N51J8fAbGjPkTp06FSeucnc1w6NAAuLnZcBiZfCgRIoQQUrV9iC86Lf39YyA7Rb7zeQLJrCzz4qamq/fXaGDgc4wYcQqxsenSuvHj3bF2bXfo6mpyGJn81PsdJIQQUnVkpxRsHFo48fnwTs4L8ABjh4+tO4VaeUycAA3h509XM3Fx6fDyOoKsLElXmLm5Lnbv7oPevZ05jkwxlAgRQgipXHIzgPehRVt50l9//tx8BrZFx/GYuUjG9xC5WFnpY8WKzvj++0B07+4IPz8vWFvrcx2WwigRIoQQUjHlZQNJ4YUWHvyY+CRHAmDyXUPX8mOiU7iVp16lnZrOJbGYQSQSQ1OzYKXqKVNaoEYNQ/Tr5wI+v3IOBKdEiBBCCLfEeUByRNEWnqRwxaamF27hkU5Nt1Bp6OoiJiYNI0acQuPGVli5squ0ns/nYcAAVw4j+3KUCBFCCCkfTAykvpSM4ym8vURiKCDKlu8aGrqfzNL6WNavVmWnpnPt1KmnGDUqAO/fZ+LvvyPQvXttdOpkz3VYSkOJECGEEOViDMiIKbq9xPsnkvE98hBoSaamf9rKY1hLraamcykjIwczZvyF7duDpXVWVpVvDNDnUCJECCGk7D4kFEp0CiU+WUnync8TACZ1io7jMamt9lPTuRQc/BY+Pv4ID38vrevb1xm//dYH5uaVY68zedH/MkIIIZ+XnfrJOjz5U9Pj5L+GkYPsSsvm9QETZ5qaXoGIRGKsWfMvfvzxEvLyxAAAXV1NbNjQHaNHu1W4fcKUgRIhQgghBXI/SMbsJHzSypMWLf819KsXauH52Mpj6gJoVb1ulaokIeEDBg48hsuXo6R17u42OHRoAJyczLgLTMUoESKEEHUkyimYml64hSc5AnJPTdcxl2wi+ul6PNrGqoycqIiRkRDp6ZL91Hg8YPbsNli0qAO0tASfObNyo0SIEEKqMrFIktzkz9DKb+VJCpdMW5eH0Kgg2SncyqNrqdrYSbnS1BTg4MH+8PI6jK1be6J9ezuuQyoXlAgRQkhVwBiQ9qqghSe/lScxFMjLku8aGjqFEp5CrTz61WlqehUUFBQNXV1NNGpkLa1zcjLD48cTK+3iiGVBiRAhhFQmjAEZsZ9MS//Y2pOb/vnzAYCvKdlO4tNWHiM7mpquBvLyxFi69CqWLLkKJycz3LkzVmaDVHVKggBKhAghpOLKfF/8TK2sRPnO5/EB4zqy43fM6wPGtQFB5dgZnChXZGQShg71R1CQZF+20NAE/Prrbcyc6cFxZNyhRIgQQriWk1Zo/E6hVp6MWPmvYWT/yaDl+oCpM6Chrbq4SaXBGMP+/Q8xefJZpKVJBkQLBDwsXNge33/fkuPouEWJECGElJfcTCDxacGU9PzEJ/Wl/NfQr1ZowHL+rumuNDWdlCgpKRPjx5/B0aNPpHWOjiY4cKA/WraswWFkFQMlQoQQomyi3E92TX8i+Tc5QrLfljy0zQCLBp+M46kHaJuoNnZSpVy+HIVhw07g9etUad3IkY2xcaMnDAxoIUuAEiFCCCk7sQhIiSxIdArvmi7Ole8aWoZF1+Exry+Zmk4ztcgXiIlJQ/fuB5CTIwIAmJhoY/v2Xhg4sB7HkVUslAgRQsjnMCZZWfnTQcuJIQpOTXeVTXbM6gMGNSjhISphY2OAhQvbY968f9Cxox327euHGjUMuQ6rwqFEiBBC8jEm2Tvr0xae908kA5rlwdeUDFL+dByPkT3Ar9or9BJuMcYgFjMIBAVLIPzwQ2vY2hpiyJCGajctXl6UCBFC1FNmYglT099//lzg49T02kUXHzSuQ1PTSbmLj8/AmDF/okkTayxc2EFaLxDwMWxYI+4CqwQoESKEVG05acD7kKKtPBkx8l/D0E4yUNmsUAuPaV1AU0dlYRMir8DA5xgx4hRiY9Nx+nQ4unVzRKtWtlyHVWlQIkQIqRrysiRT0z9t4UmNkv8aejZFBy2buQJaBioLm5CyysrKw5w5F7Bhw01pnYmJjnSdICIfSoQIIZWLKBdIfvYx4SnUypP8XIGp6aafbCD6MfHRMVVt7IQoyaNHcRgyxB+PHr2T1nXv7gg/Py9YW9OaUoqgRIgQUjExMZDyophNRJ/KPzVdU79oC495fUDXimZqkUpJLGbYvPkmfvjhArKzJdPihUIBVq3qismTm9OA6DKgRIgQwi3GgLTXsgsPJjyWjOvJy5TvGhragKmr7Dge8/qAgS0lPKTKeP/+A4YM8UdgYIS0rkEDSxw6NAD161tyGFnlRokQIaR8MAZ8eCc7U0s6NT318+cDAF8DMHEu2spj5EBT00mVp6enhTdvCpZxmDatJZYt6wxtbfoq/xL06hFClC8rqVDrTqFWnswEOS/AA0xqF2wrkd/KY1IHEGipNHRCKiptbQ0cOtQfffsexrZtvdCtmyPXIVUJlAgRQsouN+Pj1PRPWnjS38h/DYOaBS08MlPTdVUXNyGVQHDwW+jpaaFuXXNpXYMGVggPnwINDX4pZxJFUCJECPm8vCwgMazQOjwfW3lSXsh/DT3roi08Zq6AkJb8J6QwkUiMNWv+xY8/XkL9+pb4779REAoLvq4pCVIuSoQIIQXEeUDSs6LjeJKfA0wk3zW0TWQHLEunppupNnZCqoDo6BQMG3YCV668BADcvx+LX3+9jWnTWnEcWdVFiRAh6oiJgZSoj11ZhVp4Ep8CIjkXY9PUL9S6U6iVR8+aZmoRUgZHjz7BuHGnkZws2ciXxwNmz26DSZOacxxZ1UaJECFVGWOS8TqFV1qWTk3/IN81BEJJF1bhdXjM6gGGNSX7bRFCvkhqajamTj2HvXsfSOtsbQ2xf38/tG9vx11gaoISIUKqig/xhRKdQq082Snync/XAEycCnVrfWzlMXakqemEqEhQUDSGDj2ByMgkaZ23dz1s3doTJia0l115oESIkMomK1nSuvPpOJ7MeDkvwJMkN4VbeMzrS5IgmppOSLl58yYVHTrsRU6OZPydgYEWtmzpgaFDG4JH3cvlhhIhQiqq3AzgfWjRTUTTX8t/DQPbT/bUqgeYutDUdEIqgOrVDTFzZissW3YdHh62OHCgH+ztTbgOS+1QIkQI1/KygaSwouN4Ul4AYPJdQ9eq6H5aZq6A0EiloRNC5MeY5PNcuLVn0aIOqFnTCKNGudG0eI5QIkRIeRHnAckRRcfxJIXLPzVdaFwo0ckfx1MP0LVQaeiEkC+TlJSJ8ePPoFmzapg500Nar6kpwLhxTTmMjFAiRIiyMTGQ+rJol1ZiqAJT0/UKWncKt/Lo2dDUdEIqmcuXozBs2Am8fp2KEydC0bmzPZo0seE6LPIRJUKElBVjQPrbT6alf5yanpsh3zUEQsl2Ep+O4zGsRVPTCankcnJEWLDgElatuoGPvWLQ19dCbGw6t4ERGZQIESKPDwkF20sUTnyyk+U7nyeQzMr6tIXH2FEybZ0QUqWEhSXAx8cfd+/GSOs6drTDvn39UKMGbStTkdBvYEIKy075uP7Ok0LjeB4DH97JeQEeYOxQqFur0NR0DaFKQyeEcI8xhh07gjFtWiAyM/MAAJqafCxd2gkzZniAz6eu7YqGEiGinnI/SMbsfDqOJy1a/mvo15Bdadm8PmDmIhnfQwhRO4mJmRg58hQCAsKkdc7OZjh0aADc3GhMUEVFiRCp2kQ5H3dN/2QcT3Ik5J+abvlJsvNxarq2sSojJ4RUMkKhAE+fJkhvT5jQFGvWdIOuriaHUZHPoUSIVA1ikWRqen5XVv72Eknhkmnr8hAaye6ablZPMnBZ11K1sRNCqgQ9PS0cPNgfffsexrZtPdG7tzPXIRE5UCJEKhcmBlJfFR20nBgKiLLlu4aGbsH6O4XX5NGvRlPTCSFye/QoDnp6WnBwKFgNumnTaoiMnAqhkL5eKwt6p0jFxBiQESs7YPn9E0lLT66cU08FWpKp6WafjOMxsqOp6YSQMhOLGTZvvokffriAJk1scO3aSJlVoSkJqlzo3SIVx7v7wMOdQMIjSfKTlfTZUwB8nJpep+g4HpPaNDWdEKJUMTFpGDHiFP76KwIA8N9/r7F1621MmdKC48hIWXH+LbFlyxasXr0asbGxaNSoETZv3ozmzZuXePyGDRuwdetWvHr1Cubm5vj666+xfPlyaGtrl2PUROnysoHjnsCHuNKPM3L4pEurHmDqDGjQ+08IUa1Tp55i1KgAvH+fKa2bNq0lxoxx5zAq8qU4TYSOHDmC6dOnY9u2bWjRogU2bNiA7t27IywsDJaWRQeoHjp0CLNnz8bu3bvh4eGB8PBwjBgxAjweD+vWrePgGRCleXFWNgnSry67n5Z5fcmu6Vr63MVICFFLGRk5mDHjL2zfHiyts7HRh5+fF7p1c+QwMqIMPJa/HS4HWrRogWbNmuGXX34BAIjFYtja2mLKlCmYPXt2keMnT56M0NBQXLx4UVo3Y8YM3Lx5E9evX5frMVNTU2FkZISUlBQYGtLqnhVGwADgmb+k7PUn4NiL23gIIQRAcPBb+Pj4Izz8vbTOy6sudu7sDXNzXQ4jUz+q+v7mbMRoTk4OgoOD0aVLl4Jg+Hx06dIFQUFBxZ7j4eGB4OBg3Lp1CwAQGRmJs2fPokePHiU+TnZ2NlJTU2V+SAWTlQREnpaUda0Ae09u4yGEEADR0Snw8NgtTYJ0dTWxc2dv+PsPoiSoCuEsEUpISIBIJIKVlZVMvZWVFWJjY4s9x8fHBz/99BPatGkDTU1NODo6okOHDpg7d26Jj7N8+XIYGRlJf2xtbZX6PIgShB0t2JXdxYcGOBNCKgRbWyNMnNgUAODuboN798Zh9Gg38GiZjSqlUs0hvnz5MpYtW4Zff/0Vd+/ehb+/P86cOYMlS5aUeM6cOXOQkpIi/YmOVmALBVI+Qg8UlF2GcRcHIUTtfTpaZPnyLli3rhv+/XcUnJzMOIqKqBJnf3qbm5tDIBAgLk52llBcXBysra2LPWf+/PkYNmwYRo8eDQBo0KABMjIyMHbsWMybNw98ftG8TigUQiikzS4rrJQXwJuP47vMXAHLxpyGQwhRT6mp2Zg69RyaN6+OiRObSeu1tTUwbVorDiMjqsZZi5CWlhbc3d1lBj6LxWJcvHgRrVoV/5/uw4cPRZIdgUAAoGgWTyqJkE9ag6jJmRBSzoKCotG48Tbs3fsAM2b8hdDQeK5DIuWI08EY06dPh6+vL5o2bYrmzZtjw4YNyMjIwMiRIwEAw4cPR/Xq1bF8+XIAQO/evbFu3To0adIELVq0wPPnzzF//nz07t1bmhCRSoQxIHR/wW2XIdzFQghRO3l5Yvz881X8/PNViESSP6Y1NfmIiEiCi4sFx9GR8sJpIuTt7Y34+HgsWLAAsbGxaNy4Mc6fPy8dQP3q1SuZFqAff/wRPB4PP/74I968eQMLCwv07t0bS5cu5eopkC8RextIeiYp23YADGkgOyGkfERGJmHoUH8EBb2W1nl42OLAgX6wtzcp5UxS1XC6jhAXaB2hCuTiFOC+ZA0pdNsFNPiW23gIIVUeYwz79j3A5MnnkJ4uma0qEPCwYEF7zJ3bVmbPMFKxqOr7m+YpE26IcoGww5KyhjbgNIDbeAghVV5ychbGjTuNo0efSOscHExw8GB/tGxZg8PICJcoESLciAoEMhMkZYc+gNCI23gIIVUejwfcvFnQFTZiRGNs2uQJAwOaWazOqA2QcCOk0CBpV1o7iBCiekZG2ti/vx/MzXVx9OjX2LOnLyVBhFqECAeyU4CIU5Kyjjlg153beAghVVJYWAL09LRQo0bBeJK2bWshKuo76OlpcRgZqUioRYiUv/DjgChbUnYeDAg0uY2HEFKlMMawffsdNGmyHcOHn4BYLDsniJIgUhglQqT8hVK3GCFENeLjM+DldQTjx59BZmYeLl2Kwo4dwVyHRSow6hoj5Sv1FRB9WVI2cQKsm5V2NCGEyC0w8DlGjDiF2Nh0ad348e4YPrwRh1GRio4SIVK+Qg8VlF2G0pYahJAvlpWVhzlzLmDDhpvSOnNzXeze3Qe9eztzGBmpDCgRIuXn0y01XIdyFwshpEp49CgOQ4b449Gjd9K67t0d4efnBWtrfQ4jI5UFJUKk/Ly7B7wPkZSrtwGM7LmNhxBSqb18mYxmzXYiO1sEABAKBVi1qismT24OPp9am4l8aLA0KT+hhXeap9YgQsiXqVXLWDr+p0EDS9y5MxZTp7agJIgohFqESPkQ5xWMDxJoAc6DuI2HEFIlrF/fHbVqGWHGDA9oa9NXGlEctQiR8vHyAvAhTlJ26AVo0+7OhBD5ZWTkYPz40/Dzuy9Tr6enhXnz2lESRMqM/ueQ8kHdYoSQMgoOfoshQ/wRFvYeBw8+Qtu2NeHoaMp1WKSKoBYhono56cCzE5Kytglg34PbeAghlYJIJMbKldfRsuUuhIW9BwCIxQyPH7/7zJmEyI9ahIjqPfMH8j5Iys7egAZtckgIKV10dAqGDTuBK1deSuvc3W1w6NAAODmZcRgZqWooESKqR91ihBAFHD36BOPGnUZychYAybqrs2e3waJFHaClJeA4OlLVUCJEVCv9LfDqoqRs5ABU8+A2HkJIhZWWlo0pU85h794H0jpbW0Ps398P7dvbcRcYqdIoESKqFXoIYGJJmbbUIISUIjtbhL/+ipDe9vauh61be8LERIfDqEhVR4OliWoV7hajLTUIIaUwN9fF3r1eMDQUYt8+L/z++wBKgojKUYsQUZ34R0D8xyZumxaASR1u4yGEVCiRkUnQ09OElVXBnmBduzri5cvvYWyszWFkRJ1QixBRnZBCG6y6DOMuDkJIhcIYw96999Go0TZ8+20AGGMy91MSRMoTJUJENcQi4OnHLTX4GpJp84QQtZeUlInBg49jxIhTSE/Pwdmzz7Bnz32uwyJqjLrGiGpEXwbS30jKdl8BuuZcRkMIqQAuX47CsGEn8Pp1qrRuxIjGGDjQlcOoiLqjRIioRmihbjFX6hYjRJ3l5IiwYMElrFp1A/m9YCYm2ti+vRcGDqzHbXBE7VEiRJQv9wMQflxS1jKUbLJKCFFLT58mYMgQf9y9GyOt69jRDvv29UONGoYcRkaIBCVCRPmenwJy0yVlp4GAJk1/JUQdRUYmwc1tOzIz8wAAmpp8LF3aCTNmeIDPpzXFSMVAg6WJ8lG3GCEEgIODCfr3dwEAODub4b//RmPWrNaUBJEKhVqEiHJlxAFRf0nKBjWBGm25jYcQwqktW3qgVi0jzJvXDrq6mlyHQ0gRX9QilJWVpaw4SFURdhhgIknZZQjAo0ZHQtRBVlYepk07j2PHnsjUGxlpY+nSzpQEkQpL4W8psViMJUuWoHr16tDX10dkZCQAYP78+di1a5fSAySVTOFFFGlLDULUwqNHcWjefCc2bLiJsWNPIzo6heuQCJGbwonQzz//DD8/P6xatQpaWlrS+vr16+O3335TanCkknkfCsQFS8qWboAZrQ1CSFUmFjNs3PgfmjXbiUeP3gEAMjNzcefOW44jI0R+CidC+/btw44dOzBkyBAIBAJpfaNGjfD06VOlBkcqGZkNVmmQNCFVWUxMGnr0OIjvvw9EdrakO7xBA0vcuTMW/fq5cBwdIfJTeLD0mzdvULt27SL1YrEYubm5SgmKVEJMDIR8TIR4AqDuN9zGQwhRmVOnnmL06D+RkPBBWjdtWkssW9YZ2to0B4dULgr/j3V1dcW1a9dQq1Ytmfo//vgDTZo0UVpgpJJ5cx1IeyUp1+oK6FlxGw8hROkyMnIwY8Zf2L49WFpnY6MPPz8vdOvmyGFkhJSdwonQggUL4Ovrizdv3kAsFsPf3x9hYWHYt28fTp8+rYoYSWUQQmsHEVLVpaZm4/jxUOltL6+62LmzN8zNdTmMipAvo/AYob59++LPP//EhQsXoKenhwULFiA0NBR//vknunbtqooYSUWXlwWEH5OUNfWB2l6chkMIUQ0bGwP89ltv6OpqYufO3vD3H0RJEKn0eIzlb4GnHlJTU2FkZISUlBQYGtI+N0oR/gfw50BJ2XU48NVebuMhhChFdHQK9PS0YGoqu03Ou3cZsLTU4ygqoq5U9f2tcIuQg4MD3r9/X6Q+OTkZDg4OSgmKVDLULUZIlXP06BM0bLgN48adxqd/L1MSRKoShROhqKgoiESiIvXZ2dl48+aNUoIilciHBODFWUlZvxpg25HbeAghXyQ1NRsjRpyEt/cfSE7Owh9/hODQoUdch0WIysg9WDogIEBaDgwMhJGRkfS2SCTCxYsXYWdnp9TgSCUQfhQQS3aWRl0fgC8o/XhCSIUVFBSNIUP88eJFsrTO27seevSow11QhKiY3ImQl5cXAIDH48HX11fmPk1NTdjZ2WHt2rVKDY5UAtQtRkill5cnxtKlV7FkyVWIRJJuMAMDLWzZ0gNDhzYEj0e7xZOqS+5ESCwWAwDs7e1x+/ZtmJubqywoUkkkPQNi/pOULRpKfgghlUpkZBKGDvVHUNBraZ2Hhy0OHOgHe3sTDiMjpHwovI7QixcvVBEHqYxCDxaUXWiDVUIqm+fPE+Hmth1paTkAAIGAhwUL2mPu3LbQ0FB4CCkhlVKZ1kLPyMjAlStX8OrVK+Tk5MjcN3XqVKUERio4xgrtLcaTjA8ihFQqjo4m6NzZASdPPoWDgwkOHuyPli1rcB0WIeVK4UTo3r176NGjBz58+ICMjAyYmpoiISEBurq6sLS0pERIXbwNApIjJOWanQGD6tzGQwhRGI/Hw86dvVGrlhGWLOkIAwMh1yERUu4UbvucNm0aevfujaSkJOjo6OC///7Dy5cv4e7ujjVr1qgiRlIRyew0T91ihFR0OTkizJ59AWfOhMvUm5vrYsMGT0qCiNpSOBG6f/8+ZsyYAT6fD4FAgOzsbNja2mLVqlWYO3euKmIkFY0oBwg7Iilr6AB1+nMbDyGkVGFhCWjVahdWrryBb78NQFxcOtchEVJhKJwIaWpqgs+XnGZpaYlXryQ7jhsZGSE6Olq50ZGKKfIskJUoKdfuB2gZcBsPIaRYjDFs334HTZpsx927MQCApKRM3LhBv6sJyafwGKEmTZrg9u3bqFOnDtq3b48FCxYgISEB+/fvR/369VURI6loqFuMkAovPj4Do0f/iYCAMGmds7MZDh0aADc3Gw4jI6RiUbhFaNmyZbCxkXyIli5dChMTE0yYMAHx8fHYvn270gMkFUxWEhD5p6SsawXU6sptPISQIgIDn6Nhw20ySdCECU1x9+44SoII+YTCLUJNmzaVli0tLXH+/HmlBkQquPBjkjFCAFD3G4BfphUYCCEqkJWVhzlzLmDDhpvSOnNzXeze3Qe9eztzGBkhFZfSVsy6e/cuevXqpazLkYoqhLrFCKmo3r3LwJ4996W3PT1r49GjCZQEEVIKhRKhwMBAzJw5E3PnzkVkZCQA4OnTp/Dy8kKzZs2k23CQKiolCnhzTVI2dQEs3TgNhxAiq2ZNI2zd2hNCoQCbNnni7FkfWFvrcx0WIRWa3P0au3btwpgxY2BqaoqkpCT89ttvWLduHaZMmQJvb288fvwYLi4uqoyVcE1mkPQwgDZiJIRTMTFp0NPTgqFhwRpA33zTAG3a1IStrRGHkRFSecjdIrRx40asXLkSCQkJOHr0KBISEvDrr7/i0aNH2LZtGyVBVR1jst1iLrSlBiFcOnXqKRo23IapU88VuY+SIELkJ3ciFBERgYEDBwIA+vfvDw0NDaxevRo1atC+NGoh7g6Q9HEGSo32gGEtbuMhRE1lZORg/PjT8PI6goSED9i79wGOHw/hOixCKi25u8YyMzOhq6sLQLI/jVAolE6jJ2ogZH9B2XUYd3EQosaCg9/Cx8cf4eHvpXVeXnXRvr0dd0ERUskpNPf5t99+g76+ZOBdXl4e/Pz8YG5uLnMMbbpaBYlygaeHJWWBEKgzgNt4CFEzIpEYa9b8ix9/vIS8PMmkFF1dTWzc6IlRo5qAR+P1CCkzHmOMyXOgnZ3dZz9sPB5POptMXlu2bMHq1asRGxuLRo0aYfPmzWjevHmJxycnJ2PevHnw9/dHYmIiatWqhQ0bNqBHjx5yPV5qaiqMjIyQkpICQ0NDhWJVW5FngBMfl0ZwGgj0PsptPISokejoFAwbdgJXrryU1rm72+DQoQFwcjLjMDJCypeqvr/lbhGKiopS2oPmO3LkCKZPn45t27ahRYsW2LBhA7p3746wsDBYWloWOT4nJwddu3aFpaUl/vjjD1SvXh0vX76EsbGx0mMjhVC3GCGcCA9/jxYtfkNychYAyUTN2bPbYNGiDtDSEnAcHSFVg9wtQqrQokULNGvWDL/88gsAQCwWw9bWFlOmTMHs2bOLHL9t2zasXr0aT58+haamZpkek1qEFJSdCmyzAvKyAG0zYPxbQKDFdVSEqAWxmKFHj4MIDIyAra0h9u/vR+OBiNpS1fe30laWVlROTg6Cg4PRpUuXgmD4fHTp0gVBQUHFnhMQEIBWrVph0qRJsLKyQv369bFs2TKIRKLyClv9PDsuSYIAoO5gSoIIKUd8Pg979vTF2LFuePBgPCVBhKgAZxtFJSQkQCQSwcrKSqbeysoKT58+LfacyMhI/PPPPxgyZAjOnj2L58+fY+LEicjNzcXChQuLPSc7OxvZ2dnS26mpqcp7EuqAusUIKRd5eWIsXXoVbdvWQqdO9tJ6GxsDbN/em8PICKnaKtWOmWKxGJaWltixYwcEAgHc3d3x5s0brF69usREaPny5Vi8eHE5R1pFpEYD0ZclZZM6gHXJg9gJIWUXGZmEoUP9ERT0GtWrG+DhwwkwNdXhOixC1AJnXWPm5uYQCASIi4uTqY+Li4O1tXWx59jY2MDJyQkCQcEgQRcXF8TGxiInJ6fYc+bMmYOUlBTpT3R0tPKeRFX39BCAj0PIXIbSlhqEKBljDPv2PUDjxtsQFPQaABAbm45Ll15wHBkh6qNMiVBERAR+/PFHfPPNN3j37h0A4Ny5c3jy5Inc19DS0oK7uzsuXrworROLxbh48SJatWpV7DmtW7fG8+fPZTZ3DQ8Ph42NDbS0ih+7IhQKYWhoKPND5MCYbLeYC+00T4gyJSVlYvDg4/D1PYm0NMkfcg4OJrh+/VsMGODKcXSEqA+FE6ErV66gQYMGuHnzJvz9/ZGeng4AePDgQYndUyWZPn06du7cib179yI0NBQTJkxARkYGRo4cCQAYPnw45syZIz1+woQJSExMxHfffYfw8HCcOXMGy5Ytw6RJkxR9GuRz4h8A7z8mttU8AGMHbuMhpAq5fDkKDRtuw9GjBX88jhjRGPfvj0PLlrRtESHlSeExQrNnz8bPP/+M6dOnw8DAQFrfqVMn6TR4eXl7eyM+Ph4LFixAbGwsGjdujPPnz0sHUL969Qp8fkGuZmtri8DAQEybNg0NGzZE9erV8d133+GHH35Q9GmQz6FB0oQoXU6OCAsXXsLKlTeQv3CJsbE2duzohYED63EbHCFqSuF1hPT19fHo0SPY29vDwMAADx48gIODA6KiolC3bl1kZWWpKlaloHWE5CDOA3bYAhmxAF8TGB8L6JhyHRUhlV5kZBIaNtyKjIxcAECHDnbYt8+LdosnRA4VZh0hY2NjxMTEFKm/d+8eqlevrpSgCMde/SNJggDAoSclQYQoiYODCTZu9ISmJh+rVnXBxYvDKQkihGMKd40NHjwYP/zwA44dOwYejwexWIwbN25g5syZGD58uCpiJOWNusUIUYqEhA/Q1dWErm7BSvjfftsE7dvboXZt+gODkIpA4RahZcuWoW7durC1tUV6ejpcXV3Rrl07eHh44Mcff1RFjKQ85aQDz/wlZaExYN+T03AIqawCA5+jQYOtmDXrL5l6Ho9HSRAhFUiZ9xp79eoVHj9+jPT0dDRp0gR16tRRdmwqQWOEPiPkAHDuYytQw7FA1+3cxkNIJZOVlYc5cy5gw4ab0rrTp79Bz55OHEZFSOXH+e7z+a5fv442bdqgZs2aqFmzptICIRWEzNpB1C1GiCIePYrDkCH+ePTonbTO07M23N2rcRgVIaQ0CneNderUCfb29pg7dy5CQkJUERPhSnoM8OqCpGxoB1RvzWk4hFQWYjHDxo3/oVmzndIkSCgUYNMmT5w96wNra32OIySElEThROjt27eYMWMGrly5gvr166Nx48ZYvXo1Xr9+rYr4SHl6+jvAPq7a7UpbahAij5iYNPTocRDffx+I7GwRAKBBA0vcuTMWU6a0AI8+R4RUaAonQubm5pg8eTJu3LiBiIgIDBw4EHv37oWdnR06deqkihhJeaFuMUIUEhaWgIYNtyEwMEJaN21aS9y6NQb161tyGBkhRF5ftOmqvb09Zs+ejRUrVqBBgwa4cuWKsuIi5S3hMRB/X1K2bg6Y0sBOQj6ndm1TuLpaAABsbPQRGDgU69Z1h7a2wsMvCSEcKXMidOPGDUycOBE2Njbw8fFB/fr1cebMGWXGRspTyIGCMm2wSohcBAI+9u/vh2HDGuLhwwno1s2R65AIIQpS+M+WOXPm4PDhw3j79i26du2KjRs3om/fvtDV1VVFfKQ8MDEQelBS5msAdQdzGw8hFZBIJMaaNf+ibdta8PCwldbXrGmEffv6cRgZIeRLKJwIXb16FbNmzcKgQYNgbm6uiphIeYu+DKR/HOxu5wnoWnAZDSEVTnR0CoYNO4ErV17C3t4Y9++Ph6GhkOuwCCFKoHAidOPGDVXEQbhE3WKElOjo0ScYN+40kpMlG0pHRSXjr78i8PXXrhxHRghRBrkSoYCAAHz11VfQ1NREQEBAqcf26dNHKYGRcpL7AXj2h6SsZQg40vtHCACkpmZj6tRz2Lv3gbTO1tYQ+/f3Q/v2dtwFRghRKrkSIS8vL8TGxsLS0hJeXl4lHsfj8SASiZQVGykPEQFATpqk7PQ1oKnDbTyEVABBQdEYOvQEIiOTpHXe3vWwdWtPmJjQZ4SQqkSuREgsFhdbJlVAKHWLEZIvL0+MpUuvYsmSqxCJJNswGhhoYcuWHhg6tCEtjkhIFaTw9Pl9+/YhOzu7SH1OTg727dunlKBIOfnwDnhxXlI2sAVs23MbDyEci4hIxPLl16VJkIeHLR48GI9hwxpREkRIFaVwIjRy5EikpKQUqU9LS8PIkSOVEhQpJ08PA+xjV6bLEID3RetrElLpOTubY9WqrhAIeFi8uAOuXBkBe3sTrsMihKiQwrPGGGPF/mX0+vVrGBkZKSUoUk5kttSgbjGifpKSMqGrqwmhsOBX4ZQpzdGpkz1tkUGImpA7EWrSpAl4PB54PB46d+4MDY2CU0UiEV68eAFPT0+VBElU4P1TIO6OpGzZBDCvx208hJSzy5ejMGzYCQweXA+rV3eT1vN4PEqCCFEjcidC+bPF7t+/j+7du0NfX196n5aWFuzs7DBgwAClB0hUpPAgaVfaYJWoj5wcERYuvISVK2+AMWDNmiB4etZG584OXIdGCOGA3InQwoULAQB2dnbw9vaGtra2yoIiKsbEBYkQjw8405YaRD2EhSXAx8cfd+/GSOs6drSDszOtkk+IulJ4jJCvr68q4iDl6c0NIPWlpFyrK6Bvw208hKgYYww7dgRj2rRAZGbmAQA0NflYurQTZszwAJ9PM8IIUVdyJUKmpqYIDw+Hubk5TExMSp1GmpiYqLTgiIoUHiRN3WKkiouPz8Do0X8iICBMWufsbIZDhwbAzY3+CCBE3cmVCK1fvx4GBgbSMq2nUYnlZQHhRyVlTT2gthen4RCiSmFhCejQYS9iY9OldRMmNMWaNd2gq6vJYWSEkIpCrkSocHfYiBEjVBULKQ+RZ4Dsj+tA1ekvSYYIqaIcHExga2uI2Nh0mJvrYvfuPujd25nrsAghFYjCK+jdvXsXjx49kt4+deoUvLy8MHfuXOTk5Cg1OKICMmsHUbcYqdo0NQU4eLA/+vd3waNHEygJIoQUoXAiNG7cOISHhwMAIiMj4e3tDV1dXRw7dgz/+9//lB4gUaLM98CLs5Kyng1QsxO38RCiRGIxw6ZNN3HvXoxMfZ06Zjh+fBCsrfVLOJMQos4UToTCw8PRuHFjAMCxY8fQvn17HDp0CH5+fjh+/Liy4yPKFHYUEOdKynV9AL6A23gIUZKYmDT06HEQ3313Hj4+/vjwIZfrkAghlYTCiRBjTLoD/YULF9CjRw8AgK2tLRISEpQbHVEumi1GqqBTp56iYcNtCAyMAAA8fZqAc+eecRwVIaSyUHgdoaZNm+Lnn39Gly5dcOXKFWzduhUA8OLFC1hZWSk9QKIkSc+BmCBJ2bw+YNGQ23gI+UIZGTmYMeMvbN8eLK2zsdGHn58XunVz5DAyQkhlonAitGHDBgwZMgQnT57EvHnzULt2bQDAH3/8AQ8PD6UHSJQk9GBB2WUYQEsgkEosOPgtfHz8ER7+Xlrn5VUXO3f2hrm5LoeREUIqGx5jjCnjQllZWRAIBNDUrNhrc6SmpsLIyAgpKSkwNDTkOpzywRiwuw6QHAGAB4x9BRjU4DoqQhQmEomxevW/mD//EvLyJF30urqa2LChO0aPdqM1zgipwlT1/a1wi1C+4OBghIaGAgBcXV3h5uamtKCIksX89zEJgmSmGCVBpJJ6+jRBJglyd7fBoUMD4ORkxnFkhJDKSuFE6N27d/D29saVK1dgbGwMAEhOTkbHjh1x+PBhWFhYKDtG8qVCCu007zKUuzgI+UL16lliyZKOmDv3ImbPboNFizpAS4tmPxJCyk7hWWNTpkxBeno6njx5gsTERCQmJuLx48dITU3F1KlTVREj+RKiHCDssKSsoQM4DeA2HkIUkJaWLW39yTdrlgdu3RqDZcs6UxJECPliCidC58+fx6+//goXFxdpnaurK7Zs2YJz584pNTiiBC/OAVkfN8Kt7QVoGXAaDiHyCgqKRuPG2/Hzz1dl6gUCPpo2rcZRVISQqkbhREgsFhc7IFpTU1O6vhCpQEKpW4xULnl5YixefBlt2+5BZGQSliy5in//jeY6LEJIFaVwItSpUyd89913ePv2rbTuzZs3mDZtGjp37qzU4MgXykoGIv6UlHUtAbtunIZDyOdERiahXbs9WLToCkQiyYTWli1rwMaGtscghKiGwonQL7/8gtTUVNjZ2cHR0RGOjo6wt7dHamoqNm/erIoYSVmFHwNE2ZJy3W8AfpknCRKiUowx7Nv3AI0bb0NQ0GsAgEDAw+LFHXDlygjY25twGyAhpMpS+JvR1tYWd+/excWLF6XT511cXNClSxelB0e+EHWLkUogKSkTEyacwZEjT6R1Dg4mOHiwP1q2pKUeCCGqpVAidOTIEQQEBCAnJwedO3fGlClTVBUX+VIpUcDrj4NMTesCVu6chkNIccLCEtC1635ER6dK60aMaIxNmzxhYCDkMDJCiLqQOxHaunUrJk2ahDp16kBHRwf+/v6IiIjA6tWrVRkfKavCW2q40pYapGKqVcsYxsbaiI5OhYmJNrZv74WBA+txHRYhRI3IPUbol19+wcKFCxEWFob79+9j7969+PXXX1UZGykrxmS7xer6cBcLIaXQ1tbAoUMD0KNHHTx8OIGSIEJIuZN7rzEdHR2EhobCzs4OgGQavY6ODqKiomBjY6PKGJVKLfYai70DHGwmKddoB3hf4TYeQiAZEL1z5120aVMTrq60Aj0hRDGq+v6Wu0UoOzsbenp6BSfy+dDS0kJmZqbSgiFKErK/oOwyjLs4CPkoPj4DXl5HMG7cafj4HEd2dh7XIRFCCAAFB0vPnz8furq60ts5OTlYunQpjIyMpHXr1q1TXnREcaJc4OnvkrJACDh9zW08RO0FBj7HiBGnEBubDgB48CAOp0+HY8AAV44jI4QQBRKhdu3aISwsTKbOw8MDkZGR0ts8GpDLvZd/A5nxkrJjb0DbmNNwiPrKysrD7NkXsHHjTWmdubkudu/ug969nTmMjBBCCsidCF2+fFmFYRCloW4xUgE8ehQHHx9/PH78TlrXvbsj/Py8YG1Nq0QTQioOWmq4KslOBSJOSsraZoC9J6fhEPUjFjNs3nwTP/xwAdnZIgCAUCjAqlVdMXlyc/D51GpMCKlYKBGqSp75A3lZkrKzNyDQ4jYeonYePYrD9Ol/QSyWTEZt0MAShw4NQP36lhxHRgghxVN4rzFSgYUW6hZzpW4xUv4aNbLG3LltAADTprXErVtjKAkihFRo1CJUVaS9Bl5dkpSNawM2LbiNh6iFDx9yoa2tIdPltWBBe3Tr5oi2bWtxGBkhhMiHWoSqitBDAD6ujekylLbUICoXHPwWTZpsx9q1/8rUa2oKKAkihFQaZUqErl27hqFDh6JVq1Z48+YNAGD//v24fv26UoMjcmLsk24x2mmeqI5IJMbKldfRsuUuhIe/x7x5/+Du3RiuwyKEkDJROBE6fvw4unfvDh0dHdy7dw/Z2dkAgJSUFCxbtkzpARI5xD8EEh5LyjatAGNHbuMhVVZ0dAo6d96H2bMvIi9PDABo2NAK+vo0MJ8QUjkpnAj9/PPP2LZtG3bu3AlNTU1pfevWrXH37l2lBkfkFEKDpInqHT36BA0bbsOVKy8BSHpf58xpg3//HQUnJzOOoyOEkLJReLB0WFgY2rVrV6TeyMgIycnJyoiJKEIsAp4ekpT5moDzIG7jIVVOamo2pk49h717H0jrbG0NsX9/P7Rvb8ddYIQQogQKJ0LW1tZ4/vy5dBf6fNevX4eDg4Oy4iLyevUPkPFxfIZ9D0CH/jInyhMWloAePQ4hMjJJWuftXQ/btvWCsbE2h5ERQohyKNw1NmbMGHz33Xe4efMmeDwe3r59i4MHD2LmzJmYMGGCKmIkpaG1g4gK1ahhCA0Nya8JAwMt7Nvnhd9/H0BJECGkylA4EZo9ezZ8fHzQuXNnpKeno127dhg9ejTGjRuHKVOmlCmILVu2wM7ODtra2mjRogVu3bol13mHDx8Gj8eDl5dXmR630svNkKwmDQBCY8ChJ6fhkKpHT08Lhw71R4cOdnjwYDyGDWtEmysTQqoUHmOMleXEnJwcPH/+HOnp6XB1dYW+ftk2Ujxy5AiGDx+Obdu2oUWLFtiwYQOOHTuGsLAwWFqWvCJtVFQU2rRpAwcHB5iamuLkyZNyPV5qaiqMjIyQkpICQ0PDMsVcYYQeBM5+nCrfYAzQbQe38ZBKjTGG/fsfonVrWzg6mha5jxIgQgiXVPX9XeYFFbW0tODq6ormzZuXOQkCgHXr1mHMmDEYOXIkXF1dsW3bNujq6mL37t0lniMSiTBkyBAsXrxYvccl0WwxoiRJSZkYPPg4fH1PYsgQf+TmimTupySIEFJVKTxYumPHjqX+Uvznn3/kvlZOTg6Cg4MxZ84caR2fz0eXLl0QFBRU4nk//fQTLC0tMWrUKFy7dq3Ux8jOzpaudQRIMsoqIT0GePm3pGxoB1RvzWk4pPK6fDkKw4adwOvXks/GzZtvcPp0OPr1c+E4MkIIUT2FE6HGjRvL3M7NzcX9+/fx+PFj+Pr6KnSthIQEiEQiWFlZydRbWVnh6dOnxZ5z/fp17Nq1C/fv35frMZYvX47FixcrFFelEHYYYJIF7eAyBODRbilEMTk5IixYcAmrVt1Afge5iYk2duzoTUkQIURtKJwIrV+/vtj6RYsWIT09/YsDKk1aWhqGDRuGnTt3wtzcXK5z5syZg+nTp0tvp6amwtbWVlUhlh/qFiNfICwsAT4+/jJbY3TsaId9+/qhRo1KPnaOEEIUoLTd54cOHYrmzZtjzZo1cp9jbm4OgUCAuLg4mfq4uDhYW1sXOT4iIgJRUVHo3bu3tE4slrSKaGhoICwsDI6OsttLCIVCCIVCRZ5KxZfwBHh3T1K2bgaYOnMbD6k0GGPYsSMY06YFIjMzDwCgqcnH0qWdMGOGh8wu8oQQog6UlggFBQVBW1uxtUW0tLTg7u6OixcvSqfAi8ViXLx4EZMnTy5yfN26dfHo0SOZuh9//BFpaWnYuHFj1WjpkUfogYKyC22wSuR3714sxo8/I73t7GyGQ4cGwM3NhsOoCCGEOwonQv3795e5zRhDTEwM7ty5g/nz5yscwPTp0+Hr64umTZuiefPm2LBhAzIyMjBy5EgAwPDhw1G9enUsX74c2traqF+/vsz5xsbGAFCkvspiYsm0eQDgCYC6g7mNh1Qqbm42mD69Jdat+w8TJjTFmjXdoKur+fkTCSGkilI4ETIyMpK5zefz4ezsjJ9++gndunVTOABvb2/Ex8djwYIFiI2NRePGjXH+/HnpAOpXr16Bz6eBwFLRV4C0aEnZ3hPQLXmtJUKys/OgpSWQmem5bFlneHrWRteujqWcSQgh6kGhBRVFIhFu3LiBBg0awMTERJVxqUylX1AxcBTw+OMaSz1/pxYhUqJHj+Lg4+OPCROaYuLEZlyHQwghX6RCLKgoEAjQrVs32mWeK7mZQPgfkrKWAeDYl9t4SIUkFjNs3PgfmjXbiceP32HGjL8QEhLPdViEEFIhKdw1Vr9+fURGRsLe3l4V8ZDSRAQAOR8XhKzzNaCpw208pMKJiUnDyJGnEBgYIa2rU8e0lDMIIUS9KTz45ueff8bMmTNx+vRpxMTEIDU1VeaHqFDh2WKuNFuMyDp16ikaNtwmkwRNm9YSt26NgaurBYeREUJIxSV3i9BPP/2EGTNmoEePHgCAPn36yAzAzN+UUSQSlXQJ8iU+xANR5yVl/RqAbQdOwyEVR0ZGDmbM+AvbtwdL62xs9OHn54Vu3WhANCGElEbuRGjx4sUYP348Ll26pMp4SEmeHgbEkgXwaEsNki88/D169/4d4eHvpXVeXnWxc2dvmJvrchgZIYRUDnInQvmTy9q3b6+yYEgpqFuMFMPKSg85OZJWWF1dTWzc6IlRo5rQbvGEECInhZoV6JcrRxLDgNhbkrJFY8BcTRaPJJ9lZKSNAwf6oUWL6rh3bxxGj3ajzykhhChAoVljTk5On/0lm5iY+EUBkWLItAbRBqvq7NixJ2jZsgZsbQsWNm3duiaCgkZRAkQIIWWgUCK0ePHiIitLExVjDAj5mAjx+EDdb7iNh3AiNTUbU6eew969D9Chgx0uXBgGgaCgQZeSIEIIKRuFEqHBgwfD0pK2dChXb24AqVGScs0ugD5tjqlugoKiMXToCURGJgEALl+OwunT4ejbty7HkRFCSOUn9xgh+ouTI6H7C8rULaZW8vLEWLz4Mtq23SNNggwMtLBvnxf69HHmODpCCKkaFJ41RspRXjYQdlRS1tAFantxGg4pP5GRSRg61B9BQa+ldR4etjhwoB/s7SvnPn+EEFIRyZ0IicViVcZBivPiDJCdLCnX6Q9o6XMaDlE9xhj273+IyZPPIi0tBwAgEPCwYEF7zJ3bFhoatH4UIYQok8J7jZFyFELdYurmzp238PU9Kb3t4GCCgwf7o2XLGtwFRQghVRj9eVlRZSYCkWckZT1roGYnbuMh5aJZs+oYN84dADBiRGPcvz+OkiBCCFEhahGqqMKPAuJcSbmuD8Cnt6oqys0VQUODLzMZYe3abujRow4NiCaEkHJALUIVFXWLVXlhYQlo2XIX9u59IFOvp6dFSRAhhJQTSoQqouRI4O2/krJZPcCiEbfxEKVijGH79jto0mQ77t6NwZQp5/D8Oa3ITgghXKD+loro0y01aA2nKiM+PgOjR/+JgIAwaV316gbIzMzlMCpCCFFflAhVNIwV6hbjScYHkSohMPA5Row4hdjYdGnd+PHuWLu2O3R1NTmMjBBC1BclQhVN7C0g+bmkbNsBMLTlNBzy5bKy8jBnzgVs2HBTWmdurovdu/ugd28aC0QIIVyiRKiioUHSVcrz54no3/8IHj16J63z9KyNPXv6wtqaFsgkhBCuUSJUkYhygKeHJWUNbaDOAG7jIV/MxEQb799nAgCEQgFWr+6KyZOb0959hBBSQdCssYokKhDIei8pO/YFhIbcxkO+mJmZLvz8+qJRIyvcuTMWU6a0oCSIEEIqEGoRqkioW6zS+/PPMDRrVl2m26trV0cEB9tDIKC/OwghpKKh38wVRVYyEBEgKetYALW6cRoOUUxGRg7Gjz+NPn0O49tvT4ExJnM/JUGEEFIx0W/niuLZcUCULSnXHQwIaDp1ZREc/BZubjuwfXswAODcuec4fTqc46gIIYTIgxKhioK6xSodkUiMlSuvo2XLXQgPl4zt0tXVxM6dvdGrlxPH0RFCCJEHjRGqCFJfAq+vSMomzoBVU27jIZ8VHZ2CYcNO4MqVl9I6d3cbHDo0AE5OZhxGRgghRBGUCFUEoYcKyq5DaUuNCu7IkccYP/4MkpOzAEjertmz22DRog7Q0hJwHB0hhBBFUCLENZktNQC4DOUuFvJZ//33GoMHH5fetrU1xP79/dC+vR13QRFCCCkzGiPEtXd3gcRQSbl6W8DIjtNwSOlatqyBYcMaAgC8vevhwYPxlAQRQkglRi1CXAspvNM8tQZVNGIxA58v21X5yy890LNnHQwaVI8WRySEkEqOWoS4JM4Dnv4uKQu0AKeB3MZDZERGJqFNm904evSJTL2hoRDe3vUpCSKEkCqAWoS49PJv4EOcpOzQG9A24TYeAgBgjGH//oeYPPks0tJyEBp6Gq1a1YCtrRHXoRFCCFEyahHiUuFuMRokXSEkJWVi8ODj8PU9ibS0HACAqamOdONUQgghVQu1CHElJw14fkJS1jYFHHpwGw/B5ctRGDbsBF6/TpXWjRjRGJs2ecLAQMhhZIQQQlSFEiGuPPMH8j62Mjh7S8YIEU7k5IiwYMElrFp1A/lbhBkba2PHjl4YOLAet8ERQghRKUqEuELdYhVCZGQSBg48hrt3Y6R1HTrYYd8+LxoTRAghaoDGCHEh7Q3w6qKkbOwIVGvFbTxqTEdHA69epQAANDX5WLWqCy5eHE5JECGEqAlKhLjw9BCAj30wLrSlBpdsbAywa1cf1K1rjv/+G41Zs1oXWTeIEEJI1UVdY1yQ2VJjCHdxqKELFyLRpIk1zMx0pXV9+jjjq69qQ1OT9gkjhBB1Qy1C5S3+IZDwSFK2aQmY1OE2HjWRlZWHadPOo2vX/Rg37jRY/qjojygJIoQQ9USJUHkr3BrkOoy7ONTIo0dxaN58JzZsuAkAOH48FOfPP+c4KkIIIRUBJULlSSz6OD4IAF8DcBrEbTxVnFjMsHHjf2jWbCcePXoHABAKBdi0yROenrU5jo4QQkhFQGOEylP0JSD9raRs3wPQNec2niosJiYNI0eeQmBghLSuQQNLHDo0APXrW3IYGSGEkIqEEqHyRN1i5SIgIAyjRgUgIeGDtG7atJZYtqwztLXpvzwhhJAC9K1QXnIzgGfHJWWhEeDQi9t4qqgbN16hb9/D0tvW1vrYu9cL3bo5chgVIYSQiorGCJWX56ckyRAAOA0ENLS5jaeK8vCwRb9+dQEAffs649GjCZQEEUIIKRG1CJUX6hZTCcYYeIUWpOTxeNi5szf69HGGr28jmfsIIYSQT1GLUHnIiAVe/iUpG9QEqrfhNp4qIjo6BZ067cPp0+Ey9WZmuhgxojElQYQQQj6LWoTKw9PDABNLyq5DAR7ln1/q6NEnGDfuNJKTs/DkyTs8fDgB1tb6XIdFCCGkkqFv5PIgs6UG7TT/JVJTszFixEl4e/+B5OQsAIC2tgbevk3jODJCCCGVEbUIqdr7EODdXUnZyh0wc+E2nkosKCgaQ4b448WLZGmdt3c9bN3aEyYmOtwFRgghpNKiREjVQg4UlGmQdJnk5Ynx889X8fPPVyESSfYIMzDQwpYtPTB0aEMaC0QIIaTMKBFSJSYGQg9KyjwB4DyY23gqoaioZPj4HEdQ0GtpnYeHLQ4c6Ad7exMOIyOEEFIV0BghVXp9FUh7JSnbdQP0rLiNpxLi83kICYkHAAgEPCxe3AFXroygJIgQQohSUCKkSoW7xVyoW6wsatY0wrZtveDgYILr17/FggXtoaFB/20JIYQoB32jqEpuJhB+TFLW1Adq9+U2nkri2rWXSE3NlqkbPLg+njyZiJYta3AUFSGEkKqqQiRCW7ZsgZ2dHbS1tdGiRQvcunWrxGN37tyJtm3bwsTEBCYmJujSpUupx3Mm8k8gJ1VSdhoAaOpyG08Fl5MjwuzZF9C+vR+mTDlX5H7aLJUQQogqcJ4IHTlyBNOnT8fChQtx9+5dNGrUCN27d8e7d++KPf7y5cv45ptvcOnSJQQFBcHW1hbdunXDmzdvyjnyz6BuMbmFhSWgVatdWLnyBhgD9u17gL/+iuA6LEIIIWqAxxhjXAbQokULNGvWDL/88gsAQCwWw9bWFlOmTMHs2bM/e75IJIKJiQl++eUXDB8+/LPHp6amwsjICCkpKTA0NPzi+Iv1IR7YXg0Q5wH61YExLwG+QDWPVYkxxrBjRzCmTQtEZmYeAEBTk4+lSzthxgwP8Pk0LZ4QQoiEqr6/Oe1vyMnJQXBwMObMmSOt4/P56NKlC4KCguS6xocPH5CbmwtTU9Ni78/OzkZ2dsGYk9TU1C8LWh5hRyRJEADU9aEkqBjx8RkYPfpPBASESeucnc1w6NAAuLnZcBgZIYQQdcJp11hCQgJEIhGsrGSnlVtZWSE2Nlaua/zwww+oVq0aunTpUuz9y5cvh5GRkfTH1tb2i+P+rFBaRLE0gYHP0bDhNpkkaMKEprh7dxwlQYQQQsoV52OEvsSKFStw+PBhnDhxAtra2sUeM2fOHKSkpEh/oqOjVRtUYjgQc1NStmgEWDRQ7eNVMteuvYSn50HExqYDAMzNdREQMBi//toTurqaHEdHCCFE3XDaNWZubg6BQIC4uDiZ+ri4OFhbW5d67po1a7BixQpcuHABDRs2LPE4oVAIoVColHjlUrg1iDZYLaJNm5rw9KyN8+efw9OzNvbs6Uu7xhNCCOEMpy1CWlpacHd3x8WLF6V1YrEYFy9eRKtWrUo8b9WqVViyZAnOnz+Ppk2blkeo8mGsIBHi8QEXH27jqYB4PB727OmLX3/tgbNnfSgJIoQQwinOu8amT5+OnTt3Yu/evQgNDcWECROQkZGBkSNHAgCGDx8uM5h65cqVmD9/Pnbv3g07OzvExsYiNjYW6enpXD2FAm//BVJeSMo1OwP61biNh2Oxseno2fMQLl6MlKm3ttbHhAnNaLNUQgghnON8lTpvb2/Ex8djwYIFiI2NRePGjXH+/HnpAOpXr16Bzy/I17Zu3YqcnBx8/fXXMtdZuHAhFi1aVJ6hFxWyv6Cs5t1iAQFhGDUqAAkJH/DgQSwePBgPMzNaVJIQQkjFwvk6QuVNZesI5WUD222ArCRAQxeYEAdoqV+3T0ZGDmbM+AvbtwdL62xs9PHnn9/A3V29W8gIIYSUXZVcR6hKeXFWkgQBQJ1+apkEBQe/xZAh/ggLey+t8/Kqi507e8PcnFqDCCGEVDyUCCmLGneLiURirFnzL3788RLy8sQAAF1dTWzc6IlRo5rQWCBCCCEVFiVCypCZCLw4IynrWgG1il/csSp6/ToVw4adwOXLUdI6d3cbHDo0AE5OZtwFRgghhMiB81ljVUL4MUCUIym7+AB89ckvMzNzcfu2ZMNbHg+YM6cN/v13FCVBhBBCKgVKhJRBjbvF6tQxw6ZNX8HW1hCXLvli2bLO0NKivdUIIYRUDpQIfankSODtDUnZzBWwbMJtPCp269YbfPiQK1M3cmRjhIRMQvv2dtwERQghhJQRJUJfKvRgQdllmKR/qArKyxNj8eLL8PDYhZkz/5K5j8fjQV9fi6PICCGEkLKjROhLMAaEFu4Wq5pbakRGJqFduz1YtOgKRCKGrVvv4NKlF1yHRQghhHwx9RnVqwqxt4GkZ5KybQfAsCan4SgbYwz79z/E5MlnkZYmGQwuEPCwYEF7tG1bi+PoCCGEkC9HidCXkBkkPYy7OFQgKSkTEyacwZEjT6R1Dg4mOHiwP1q2rMFhZIQQQojyUCJUVqJcIOywpKyhDTgN4DYeJbpyJQrDhp1AdHSqtG7EiMbYtMkTBgZCDiMjhBBClIsSobKKCgQyEyRlhz6A0IjbeJTkypUodOy4F/k70JmYaGP79l4YOLAet4ERQgghKkCDpcuqcLeYa9XpFmvTpibatZOM/+nY0Q4PH06gJIgQQkiVRS1CZZGdAkSckpR1zAG77tzGo0QCAR/79/fDsWMh+P77luDzq+ZyAIQQQghALUJlE34cEGVLys6DAYEmt/GUUXx8BgYMOIobN17J1NvaGmH69FaUBBFCCKnyqEWoLEIrf7dYYOBzjBhxCrGx6bh7NwYPHoyHoSENhCaEEKJeqEVIUamvgOjLkrJJHcC6GZfRKCwrKw/ff38enp4HERubDgBIT89BePh7jiMjhBBCyh+1CCkq9FBBuZJtqfHoURx8fPzx+PE7aZ2nZ23s2dMX1tb6HEZGCCGEcIMSIUUU2VJjCHexKEAsZti8+SZ++OECsrNFAAChUIDVq7ti8uTm4FWiZI4QQghRJkqEFPHuHvA+RFKu1howduA2HjnExKRh5MhTCAyMkNY1aGCJQ4cGoH59Sw4jI4QQQrhHY4QUEXqgoFxJBkknJmbi8uUo6e1p01ri1q0xlAQRQgghoERIfuK8gvFBAi3AeRC38cipXj1LrF7dFdbW+ggMHIp167pDW5saAgkhhBCAEiH5vbwAfIiTlO17Atom3MZTggcPYpGdnSdTN3lyc4SETES3bo4cRUUIIYRUTJQIyauCd4uJRGKsXHkdTZvuxLx5/8jcx+PxYGKiw1FkhBBCSMVFiZA8ctKBZyckZW0TwL4Ht/F8Ijo6BZ0778Ps2ReRlyfG2rVBuH791edPJIQQQtQcDRaRxzN/IO+DpOw0CNCoOCswHz36BOPGnUZychYAybJGs2e3QfPm1TmOjBBCCKn4KBGSRwXsFktNzcbUqeewd+8DaZ2trSH27++H9u3tuAuMEEIIqUQoEfqc9LfAq4uSspE9UM2D23gABAVFY+jQE4iMTJLWeXvXw9atPWksECGEEKIASoQ+J/QQwMSSsstQzrfUuHw5Cl267INIxAAABgZa2LKlB4YObUgrRBNCCCEKosHSn1PBusVat7aFu3s1AICHhy0ePBiPYcMaURJECCGElAG1CJUm/hEQ/3EMjk0LyW7zHNPUFODgwf44cuQxfvihDTQ0KJclhBBCyooSodKEFN5gdWi5P3xSUiYmTz6H6dNbSluBAKB2bVPMm9eu3OMhpDgikQi5ublch0EIqQI0NTUhEAjK9TEpESqJWAQ8/bilBl8DcB5crg9/+XIUhg07gdevUxEc/BZ3746Drq5mucZAyOekp6fj9evXYIxxHQohpArg8XioUaMG9PX1y+0xKREqSfRlIP2NpGz3FaBrXi4Pm5MjwoIFl7Bq1Q3kf7e8e5eBJ0/eoVkzWhuIVBwikQivX7+Grq4uLCwsaJwaIeSLMMYQHx+P169fo06dOuXWMkSJUElCC3WLuZZPt1hYWAJ8fPxx926MtK5jRzvs29cPNWoYlksMhMgrNzcXjDFYWFhAR4eWbSCEfDkLCwtERUUhNzeXEiFO5X4Awo9LylqGgENvlT4cYww7dgRj2rRAZGZKNkzV1ORj6dJOmDHDA3w+/aVNKi5qCSKEKAsXv08oESrO81NAbrqk7DQQ0FTdX7vx8RkYPfpPBASESeucnc1w6NAAuLnZqOxxCSGEEELrCBWvHLvFoqNTcfbsM+ntCROa4u7dcZQEEUJkREVFgcfj4f79+yUec/nyZfB4PCQnJ5dbXOoiLCwM1tbWSEtL4zqUSuv8+fNo3LgxxGIx16HIoEToUxlxQNRfkrJBTaCGaqepu7nZ4OefO8LcXBcBAYPx6689aXYYISo0YsQI8Hi8Ij+enp5ch1Yh+Pn5SV8TPp8PGxsbeHt749WrV0WOffLkCQYNGgQLCwsIhUI4OTlhwYIF+PDhQ5Fj7927h4EDB8LKygra2tqoU6cOxowZg/Dw8M/G9Pr1a2hpaaF+/fpF7istQezQoQO+//57pcQxZ84cTJkyBQYGBkXuq1u3LoRCIWJjYz/7XCqCxMREDBkyBIaGhjA2NsaoUaOQnp5e6jmxsbEYNmwYrK2toaenBzc3Nxw/flzmGDs7uyKfqxUrVkjv9/T0hKamJg4ePKiS51VWlAh9KuwwwESSsssQgKfcl+jp0wTk5opk6mbO9MCTJxPRu7ezUh+LEFI8T09PxMTEyPz8/vvvXIdVYRgaGiImJgZv3rzB8ePHERYWhoEDB8oc899//6FFixbIycnBmTNnEB4ejqVLl8LPzw9du3ZFTk6O9NjTp0+jZcuWyM7OxsGDBxEaGooDBw7AyMgI8+fP/2w8fn5+GDRoEFJTU3Hz5s0yP6+yxvHq1SucPn0aI0aMKHLf9evXkZmZia+//hp79+4tc2zlaciQIXjy5An+/vtvnD59GlevXsXYsWNLPWf48OEICwtDQEAAHj16hP79+2PQoEG4d++ezHE//fSTzOdqypQpMvePGDECmzZtUvpz+iJMzaSkpDAALCUlpfgD9rsztgaSn4QnSntckUjMNmwIYkLhErZgwT9Kuy4hXMnMzGQhISEsMzOT61AU4uvry/r27VvqMQDYzp07mZeXF9PR0WG1a9dmp06dkt6fmJjIfHx8mLm5OdPW1ma1a9dmu3fvlt7/6tUrNnDgQGZkZMRMTExYnz592IsXL4rEsHTpUmZpacmMjIzY4sWLWW5uLps5cyYzMTFh1atXl7nmixcvGAD2+++/s1atWjGhUMjq1avHLl++LD3m0qVLDABLSkqS1l27do21adOGaWtrsxo1arApU6aw9PT0Ep/7nj17mJGRkUzdpk2bZH5visVi5urqypo2bcpEIpHMsffv32c8Ho+tWLGCMcZYRkYGMzc3Z15eXsU+XuFYiyMWi5mDgwM7f/48++GHH9iYMWNk7s9/Xe7du1fk3Pbt27Pvvvvui+NYvXo1a9q0abH3jRgxgs2ePZudO3eOOTk5SesDAwOZUCgsct2pU6eyjh07Sm/v2LGD1ahRg+no6DAvLy+2du3aIq+/MoWEhDAA7Pbt29K6c+fOMR6Px968eVPieXp6emzfvn0ydaampmznzp3S27Vq1WLr168v9fFfvnzJALDnz58Xe39pv1c++/1dRtQiVNj7UCAuWFK2dAPMXJVy2ZiYNPTocRDffx+I7GwRfv75Gm7deqOUaxNCVGPx4sUYNGgQHj58iB49emDIkCFITEwEAMyfPx8hISE4d+4cQkNDsXXrVpibS9Yay83NRffu3WFgYIBr167hxo0b0NfXh6enp0wryT///IO3b9/i6tWrWLduHRYuXIhevXrBxMQEN2/exPjx4zFu3Di8fv1aJq5Zs2ZhxowZuHfvHlq1aoXevXvj/fv3xT6HiIgIeHp6YsCAAXj48CGOHDmC69evY/LkyXK/Du/evcOJEycgEAik05nv37+PkJAQTJ8+HXy+7NdIo0aN0KVLF2kLW2BgIBISEvC///2v2OsbGxuX+viXLl3Chw8f0KVLFwwdOhSHDx9GRkaG3PHn+5I4rl27hqZNmxapT0tLw7FjxzB06FB07doVKSkpuHbtGgCgc+fOMDY2luk+EolEOHLkCIYMGQIAuHHjBsaPH4/vvvsO9+/fR9euXbF06dLPPpd69epBX1+/xJ+vvvqqxHODgoJgbGws83y6dOkCPp9famubh4cHjhw5gsTERIjFYhw+fBhZWVno0KGDzHErVqyAmZkZmjRpgtWrVyMvL0/m/po1a8LKykr6OlUENGusMBVssHrq1FOMHv0nEhIK+synTm2Ohg2tlHJ9QiqUA02BDA7GSehZA0PvyH346dOni6xcO3fuXMydO1d6e8SIEfjmm28AAMuWLcOmTZtw69YteHp64tWrV2jSpIn0y8TOzk563pEjRyAWi/Hbb79JpwLv2bMHxsbGuHz5Mrp16wYAMDU1xaZNm8Dn8+Hs7IxVq1bhw4cP0hjmzJmDFStW4Pr16xg8uGBl+8mTJ2PAgAEAgK1bt+L8+fPYtWtXsV/wy5cvx5AhQ6TjZOrUqYNNmzahffv22Lp1K7S1tYt9fVJSUqCvrw/GmHS8z9SpU6GnpwcA0vE0Li4uxZ7v4uKC69evAwCePZNMBqlbt26xx37Orl27MHjwYAgEAtSvXx8ODg44duxYsd1UpfmSOF6+fFlsInT48GHUqVMH9erVAwAMHjwYu3btQtu2bSEQCDB48GAcOnQIo0aNAgBcvHgRycnJ0vdv8+bN+OqrrzBz5kwAgJOTE/7991+cPn261HjOnj1b6rY2pa3rFRsbC0tLS5k6DQ0NmJqaljrG6ejRo/D29oaZmRk0NDSgq6uLEydOoHbt2tJjpk6dCjc3N5iamuLff//FnDlzEBMTg3Xr1slcq1q1anj58mWpz7E8USKUj4mBkI+JEI8P1P2yLTUyMnIwY8Zf2L49WFpnba2PvXu90K2b4xddm5AKKyO2YEX2Cqxjx47YunWrTJ2pqanM7YYNG0rLenp6MDQ0xLt37wAAEyZMwIABA3D37l1069YNXl5e8PDwAAA8ePAAz58/LzKoNisrCxEREdLb9erVk2lNsbKykhkMLBAIYGZmJn3MfK1atZKWNTQ00LRpU4SGhhb7PB88eICHDx/KDE5ljEEsFuPFixclJjIGBga4e/cucnNzce7cORw8eLDYlgomx9Yq8hwDSF6P/C/Htm3b4ty5c0hOToa/v780qQKAoUOHYteuXQonQvLGUZzMzMxik8bdu3dj6NCCmcVDhw5F+/btsXnzZhgYGGDIkCFo2bIl3r59i2rVquHgwYPo2bOntPUpLCwM/fr1k7lm8+bNP5sI1apVq8zPpazmz5+P5ORkXLhwAebm5jh58iQGDRqEa9euoUGDBgCA6dOnS49v2LAhtLS0MG7cOCxfvhxCoVB6n46OTrED6rlCiVC+N9eBtI+zImp1k/yFWUbBwW/h4+OP8PCC5uq+fZ3x2299YG6u+6WRElJxfcHnpjwfV09PT+Yv2eJoasrO3uTxeNJpv1999RVevnyJs2fP4u+//0bnzp0xadIkrFmzBunp6XB3dy92ZoyFhUWp1y/tMcsiPT0d48aNw9SpU4vcV7NmzRLP4/P50tfHxcUFERERmDBhAvbvlywt4uTkBAAIDQ1FkyZNipwfGhoqPSb/36dPn8okcZ8q3MqR36Jx6NAhZGVloUWLFtLj8hO58PBwODk5wdBQsup+SkpKkWsmJyfDyMhIoTiKY25ujqSkJJm6kJAQ/Pfff7h16xZ++OEHab1IJMLhw4cxZswYNGvWDI6Ojjh8+DAmTJiAEydOwM/PT6HHLk7hpLE4+YlkcaytrYsk13l5eUhMTIS1dfGfo4iICPzyyy94/PixtPWrUaNGuHbtGrZs2YJt27YVe16LFi2Ql5eHqKgoODsXTAZKTEyU+SxwjRKhfIV3mv+CbrF//nmB7t0PIC9P8stLV1cTGzZ0x+jRbrQCL6n6FOiequwsLCzg6+sLX19ftG3bFrNmzcKaNWvg5uaGI0eOwNLSUvolrUz//fcf2rWTLOuRl5eH4ODgEsf8uLm5ISQk5LNJ3+fMnj0bjo6OmDZtGtzc3NC4cWPUrVsX69evx+DBg2Vath48eIALFy5g+fLlAIBu3brB3Nwcq1atwokTJ4pcOzk5GcbGxsW2cuzatQszZswo0vozceJE7N69GytWrICpqSnMzc0RHByM9u3bS49JTU3F8+fPpQmQvHEUp0mTJggJCSkSW7t27bBlyxaZ+j179mDXrl0YM2YMAMkMrYMHD6JGjRrg8/no2bOn9FhnZ2fcvn1b5vxPbxfnS7rGWrVqheTkZAQHB8Pd3R2AZLyaWCyWSTgLy2+9+XQ8mEAgKDVRv3//Pvh8vkxXXH7LaHEJNGeUOvS6Eih21HluJmObjSQzxTbqMZZT8oyKz8nKymUNG25lwCLm7r6dhYUlfHnQhFRAlXnWmKenJ4uJiZH5iY+Plx4DgJ04cULmPCMjI7Znzx7GGGPz589nJ0+eZM+ePWOPHz9mvXr1Ys2bN2eMSWYn1alTh3Xo0IFdvXqVRUZGskuXLrEpU6aw6OhoaQyfzlwrPMMpX+FZOPmzo2rWrMn8/f1ZaGgoGzt2LNPX15fG/umssQcPHjAdHR02adIkdu/ePRYeHs5OnjzJJk2aVOLrU9ysMcYYGzRoEOvZs6f09o0bN5iuri7z8vJiN2/eZC9fvmRHjx5ltra2zMPDg2VlZUmPPXnyJNPU1GS9e/dmf//9N3vx4gW7ffs2mzVrFvP29i42jnv37jEALDQ0tMh9v/76K7O2tma5ubmMMcaWLVvGzMzM2IEDB9jz58/ZzZs3Wa9evZidnR378OHDF8XBGGMBAQHM0tKS5eXlMcYYy8nJYRYWFmzr1q1Fjs2flfX48WPGGGPPnj1jAFjDhg3ZqFGjZI69fv064/P5bO3atSw8PJxt27aNmZmZMWNj4xJjUQZPT0/WpEkTdvPmTXb9+nVWp04d9s0330jvf/36NXN2dmY3b95kjEmeb+3atVnbtm3ZzZs32fPnz9maNWsYj8djZ86cYYwx9u+//7L169ez+/fvs4iICHbgwAFmYWHBhg8fLvPYly5dYvr6+iwjI6PY2LiYNUaJEGOMhR0rmDJ/dnjJJ8vp8eM4Nm/eRZadnffF1yKkoqrMiRCAIj/Ozs7SYz6XCC1ZsoS5uLgwHR0dZmpqyvr27csiIyOlx8bExLDhw4czc3NzJhQKmYODAxszZoz0986XJEKHDh1izZs3Z1paWszV1ZX980/BchzFTZ+/desW69q1K9PX12d6enqsYcOGbOnSpSW+PiUlQkFBQQyA9MuRMcYePnzIBgwYwExNTZmmpiZzdHRkP/74Y7Ffcrdv32b9+/dnFhYWTCgUstq1a7OxY8eyZ8+eFRvH5MmTmaura7H3xcTEMD6fL13SIC8vj23atIk1aNCA6erqsho1ajBvb2+ZJQvKGgdjjOXm5rJq1aqx8+fPM8YY++OPPxifz2exsbHFHu/i4sKmTZsmvd28eXMGQOa9yrdjxw5WvXp16fT5n3/+mVlbW5cYizK8f/+effPNN0xfX58ZGhqykSNHsrS0NOn9+f/XLl26JK0LDw9n/fv3Z5aWlkxXV5c1bNhQZjp9cHAwa9GiBTMyMmLa2trMxcWFLVu2TCYhZoyxsWPHsnHjxpUYGxeJEI+xLxhBVgmlpqbCyMgIKSkpBc3WJ/sCEQGS8td/A7W6yHmtbMyYEYjvv2+JevUsP38CIVVIVlYWXrx4AXt7+xJnHxFSVWzZsgUBAQEIDAxU6eOMGTMGT58+rVDTy5UlISEBzs7OuHPnDuzt7Ys9prTfK8V+fysBjRH6kAC8OCsp61cDbDvKdVpQUDSGDj2ByMgk3Lr1FrdujYZQSC8nIYRURePGjUNycjLS0tKK3WajrNasWYOuXbtCT08P586dw969e/Hrr78q7foVSVRUFH799dcSkyCu0Dd3+FFA/HHBp7o+AF9Q6uF5eWIsXXoVS5ZchUgkaUx78SIJDx/GoVmz6qqOlhBCCAc0NDQwb948pV/31q1bWLVqFdLS0uDg4IBNmzZh9OjRSn+ciqBp06bFrsfENUqEFJgtFhmZhKFD/REUVLDSq4eHLQ4c6Ad7exNVRUgIIaSKOnr0KNchqD31ToSSngEx/0nK5g0Ai4bFHsYYw/79DzF58lmkpUmWyBcIeFiwoD3mzm0LDQ3aqYQQQgipjNQ7EQottOBZCa1BSUmZmDDhDI4ceSKtc3AwwcGD/dGyZQ1VR0gIIYQQFVLfRIixQnuL8STjg4oRGpqAY8cKFtIaMaIxNm3yhIGBsNjjCVE3ajbxlBCiQlz8PlHfPp2YW0Dyx31/anYCDIof6OzhYYt589rC2FgbR49+jT17+lISRAgg3Ym88I7qhBDyJfJ/n+T/fikP6tsiFHakoFyoW+zFiyTUrGkEgaAgR5w/vx3GjXNH9erKXy6fkMoqfwfq+Ph4aGpqFll+nxBCFCEWixEfHw9dXV1oaJRfeqK+idAzf4AHQEMHqNMfjDHs2BGMadMCsXBhe/zwQxvpoZqaAkqCCPkEj8eDjY0NXrx4UeoGkIQQIi8+n4+aNWuW696c6psIZScB2gBqeyE+hY/Ro48gICAMAPDjj5fQrZsjmjSx4TZGQio4LS0t1KlTh7rHCCFKoaWlVe6tyxUiEdqyZQtWr16N2NhYNGrUCJs3b0bz5s1LPP7YsWOYP38+oqKiUKdOHaxcuRI9evQo02MHJvTGiIbbEBubLq0bPboJnJ3Ny3Q9QtQNn8+nLTYIIZUW5536R44cwfTp07Fw4ULcvXsXjRo1Qvfu3fHu3btij//333/xzTffYNSoUbh37x68vLzg5eWFx48fK/S4WbkCfH+mHzxHhEuTIHNzXQQEDMbWrb2gq6v5xc+NEEIIIRUb55uutmjRAs2aNcMvv/wCQDJYytbWFlOmTMHs2bOLHO/t7Y2MjAycPn1aWteyZUs0btwY27Zt++zj5W/a5mI5CqHvbKX1np61sWdPX1hb6yvhWRFCCCFEmVS16SqnLUI5OTkIDg5Gly4Fu73z+Xx06dIFQUFBxZ4TFBQkczwAdO/evcTjSxL6zgIAIBQKsGmTJ86e9aEkiBBCCFEznI4RSkhIgEgkgpWVlUy9lZUVnj59Wuw5sbGxxR4fGxtb7PHZ2dnIzs6W3k5JScm/B66uFti1qy9cXS2QlpZW9idCCCGEEJVKTU0FoPxFFyvEYGlVWr58ORYvXlzMPesREgK0ajWj3GMihBBCSNm8f/8eRkZGSrsep4mQubk5BAIB4uLiZOrj4uJgbW1d7DnW1tYKHT9nzhxMnz5dejs5ORm1atXCq1evlPpCEsWlpqbC1tYW0dHRSu3vJWVD70fFQe9FxUHvRcWRkpKCmjVrwtTUVKnX5TQR0tLSgru7Oy5evAgvLy8AksHSFy9exOTJk4s9p1WrVrh48SK+//57ad3ff/+NVq1aFXu8UCiEUFh0SwwjIyP6T11BGBoa0ntRgdD7UXHQe1Fx0HtRcSh7nSHOu8amT58OX19fNG3aFM2bN8eGDRuQkZGBkSNHAgCGDx+O6tWrY/ny5QCA7777Du3bt8fatWvRs2dPHD58GHfu3MGOHTu4fBqEEEIIqYQ4T4S8vb0RHx+PBQsWIDY2Fo0bN8b58+elA6JfvXolk/15eHjg0KFD+PHHHzF37lzUqVMHJ0+eRP369bl6CoQQQgippDhPhABg8uTJJXaFXb58uUjdwIEDMXDgwDI9llAoxMKFC4vtLiPli96LioXej4qD3ouKg96LikNV7wXnCyoSQgghhHCF8y02CCGEEEK4QokQIYQQQtQWJUKEEEIIUVuUCBFCCCFEbVXJRGjLli2ws7ODtrY2WrRogVu3bpV6/LFjx1C3bl1oa2ujQYMGOHv2bDlFWvUp8l7s3LkTbdu2hYmJCUxMTNClS5fPvndEMYp+NvIdPnwYPB5PuvAp+XKKvhfJycmYNGkSbGxsIBQK4eTkRL+rlETR92LDhg1wdnaGjo4ObG1tMW3aNGRlZZVTtFXX1atX0bt3b1SrVg08Hg8nT5787DmXL1+Gm5sbhEIhateuDT8/P8UfmFUxhw8fZlpaWmz37t3syZMnbMyYMczY2JjFxcUVe/yNGzeYQCBgq1atYiEhIezHH39kmpqa7NGjR+UcedWj6Hvh4+PDtmzZwu7du8dCQ0PZiBEjmJGREXv9+nU5R141Kfp+5Hvx4gWrXr06a9u2Levbt2/5BFvFKfpeZGdns6ZNm7IePXqw69evsxcvXrDLly+z+/fvl3PkVY+i78XBgweZUChkBw8eZC9evGCBgYHMxsaGTZs2rZwjr3rOnj3L5s2bx/z9/RkAduLEiVKPj4yMZLq6umz69OksJCSEbd68mQkEAnb+/HmFHrfKJULNmzdnkyZNkt4WiUSsWrVqbPny5cUeP2jQINazZ0+ZuhYtWrBx48apNE51oOh78am8vDxmYGDA9u7dq6oQ1UpZ3o+8vDzm4eHBfvvtN+br60uJkJIo+l5s3bqVOTg4sJycnPIKUW0o+l5MmjSJderUSaZu+vTprHXr1iqNU93Ikwj973//Y/Xq1ZOp8/b2Zt27d1fosapU11hOTg6Cg4PRpUsXaR2fz0eXLl0QFBRU7DlBQUEyxwNA9+7dSzyeyKcs78WnPnz4gNzcXKVvsKeOyvp+/PTTT7C0tMSoUaPKI0y1UJb3IiAgAK1atcKkSZNgZWWF+vXrY9myZRCJROUVdpVUlvfCw8MDwcHB0u6zyMhInD17Fj169CiXmEkBZX1/V4iVpZUlISEBIpFIuj1HPisrKzx9+rTYc2JjY4s9PjY2VmVxqoOyvBef+uGHH1CtWrUi/9GJ4sryfly/fh27du3C/fv3yyFC9VGW9yIyMhL//PMPhgwZgrNnz+L58+eYOHEicnNzsXDhwvIIu0oqy3vh4+ODhIQEtGnTBowx5OXlYfz48Zg7d255hEwKKen7OzU1FZmZmdDR0ZHrOlWqRYhUHStWrMDhw4dx4sQJaGtrcx2O2klLS8OwYcOwc+dOmJubcx2O2hOLxbC0tMSOHTvg7u4Ob29vzJs3D9u2beM6NLVz+fJlLFu2DL/++ivu3r0Lf39/nDlzBkuWLOE6NFJGVapFyNzcHAKBAHFxcTL1cXFxsLa2LvYca2trhY4n8inLe5FvzZo1WLFiBS5cuICGDRuqMky1oej7ERERgaioKPTu3VtaJxaLAQAaGhoICwuDo6OjaoOuosry2bCxsYGmpiYEAoG0zsXFBbGxscjJyYGWlpZKY66qyvJezJ8/H8OGDcPo0aMBAA0aNEBGRgbGjh2LefPmyWwSTlSrpO9vQ0NDuVuDgCrWIqSlpQV3d3dcvHhRWicWi3Hx4kW0atWq2HNatWolczwA/P333yUeT+RTlvcCAFatWoUlS5bg/PnzaNq0aXmEqhYUfT/q1q2LR48e4f79+9KfPn36oGPHjrh//z5sbW3LM/wqpSyfjdatW+P58+fSZBQAwsPDYWNjQ0nQFyjLe/Hhw4ciyU5+gspo685ypbTvb8XGcVd8hw8fZkKhkPn5+bGQkBA2duxYZmxszGJjYxljjA0bNozNnj1bevyNGzeYhoYGW7NmDQsNDWULFy6k6fNKouh7sWLFCqalpcX++OMPFhMTI/1JS0vj6ilUKYq+H5+iWWPKo+h78erVK2ZgYMAmT57MwsLC2OnTp5mlpSX7+eefuXoKVYai78XChQuZgYEB+/3331lkZCT766+/mKOjIxs0aBBXT6HKSEtLY/fu3WP37t1jANi6devYvXv32MuXLxljjM2ePZsNGzZMenz+9PlZs2ax0NBQtmXLFpo+n2/z5s2sZs2aTEtLizVv3pz9999/0vvat2/PfH19ZY4/evQoc3JyYlpaWqxevXrszJkz5Rxx1aXIe1GrVi0GoMjPwoULyz/wKkrRz0ZhlAgpl6Lvxb///statGjBhEIhc3BwYEuXLmV5eXnlHHXVpMh7kZubyxYtWsQcHR2ZtrY2s7W1ZRMnTmRJSUnlH3gVc+nSpWK/A/Jff19fX9a+ffsi5zRu3JhpaWkxBwcHtmfPHoUfl8cYteURQgghRD1VqTFChBBCCCGKoESIEEIIIWqLEiFCCCGEqC1KhAghhBCitigRIoQQQojaokSIEEIIIWqLEiFCCCGEqC1KhAghMvz8/GBsbMx1GGXG4/Fw8uTJUo8ZMWIEvLy8yiUeQkjFRokQIVXQiBEjwOPxivw8f/6c69Dg5+cnjYfP56NGjRoYOXIk3r17p5Trx8TE4KuvvgIAREVFgcfj4f79+zLHbNy4EX5+fkp5vJIsWrRI+jwFAgFsbW0xduxYJCYmKnQdStoIUa0qtfs8IaSAp6cn9uzZI1NnYWHBUTSyDA0NERYWBrFYjAcPHmDkyJF4+/YtAgMDv/jaJe0aXpiRkdEXP4486tWrhwsXLkAkEiE0NBTffvstUlJScOTIkXJ5fELI51GLECFVlFAohLW1tcyPQCDAunXr0KBBA+jp6cHW1hYTJ05Eenp6idd58OABOnbsCAMDAxgaGsLd3R137tyR3n/9+nW0bdsWOjo6sLW1xdSpU5GRkVFqbDweD9bW1qhWrRq++uorTJ06FRcuXEBmZibEYjF++ukn1KhRA0KhEI0bN8b58+el5+bk5GDy5MmwsbGBtrY2atWqheXLl8tcO79rzN7eHgDQpEkT8Hg8dOjQAYBsK8uOHTtQrVo1mZ3dAaBv37749ttvpbdPnToFNzc3aGtrw8HBAYsXL0ZeXl6pz1NDQwPW1taoXr06unTpgoEDB+Lvv/+W3i8SiTBq1CjY29tDR0cHzs7O2Lhxo/T+RYsWYe/evTh16pS0deny5csAgOjoaAwaNAjGxsYwNTVF3759ERUVVWo8hJCiKBEiRM3w+Xxs2rQJT548wd69e/HPP//gf//7X4nHDxkyBDVq1MDt27cRHByM2bNnQ1NTEwAQEREBT09PDBgwAA8fPsSRI0dw/fp1TJ48WaGYdHR0IBaLkZeXh40bN2Lt2rVYs2YNHj58iO7du6NPnz549uwZAGDTpk0ICAjA0aNHERYWhoMHD8LOzq7Y6966dQsAcOHCBcTExMDf37/IMQMHDsT79+9x6dIlaV1iYiLOnz+PIUOGAACuXbuG4cOH47vvvkNISAi2b98OPz8/LF26VO7nGBUVhcDAQGhpaUnrxGIxatSogWPHjiEkJAQLFizA3LlzcfToUQDAzJkzMWjQIHh6eiImJgYxMTHw8PBAbm4uunfvDgMDA1y7dg03btyAvr4+PD09kZOTI3dMhBCgSu4+T4i68/X1ZQKBgOnp6Ul/vv7662KPPXbsGDMzM5Pe3rNnDzMyMpLeNjAwYH5+fsWeO2rUKDZ27FiZumvXrjE+n88yMzOLPefT64eHhzMnJyfWtGlTxhhj1apVY0uXLpU5p1mzZmzixImMMcamTJnCOnXqxMRicbHXB8BOnDjBGGPsxYsXDAC7d++ezDG+vr6sb9++0tt9+/Zl3377rfT29u3bWbVq1ZhIJGKMMda5c2e2bNkymWvs37+f2djYFBsDY4wtXLiQ8fl8pqenx7S1taU7aa9bt67EcxhjbNKkSWzAgAElxpr/2M7OzjKvQXZ2NtPR0WGBgYGlXp8QIovGCBFSRXXs2BFbt26V3tbT0wMgaR1Zvnw5nj59itTUVOTl5SErKwsfPnyArq5uketMnz4do0ePxv79+6XdO46OjgAk3WYPHz7EwYMHpcczxiAWi/HixQu4uLgUG1tKSgr09fUhFouRlZWFNm3a4LfffkNqairevn2L1q1byxzfunVrPHjwAICkW6tr165wdnaGp6cnevXqhW7dun3RazVkyBCMGTMGv/76K4RCIQ4ePIjBgweDz+dLn+eNGzdkWoBEIlGprxsAODs7IyAgAFlZWThw4ADu37+PKVOmyByzZcsW7N69G69evUJmZiZycnLQuHHjUuN98OABnj9/DgMDA5n6rKwsRERElOEVIER9USJESBWlp6eH2rVry9RFRUWhV69emDBhApYuXQpTU1Ncv34do0aNQk5OTrFf6IsWLYKPjw/OnDmDc+fOYeHChTh8+DD69euH9PR0jBs3DlOnTi1yXs2aNUuMzcDAAHfv3gWfz4eNjQ10dHQAAKmpqZ99Xm5ubnjx4gXOnTuHCxcuYNCgQejSpQv++OOPz55bkt69e4MxhjNnzqBZs2a4du0a1q9fL70/PT0dixcvRv/+/Yucq62tXeJ1tbS0pO/BihUr0LNnTyxevBhLliwBABw+fBgzZ87E2rVr0apVKxgYGGD16tW4efNmqfGmp6fD3d1dJgHNV1EGxBNSWVAiRIgaCQ4Ohlgsxtq1a6WtHfnjUUrj5OQEJycnTJs2Dd988w327NmDfv36wc3NDSEhIUUSrs/h8/nFnmNoaIhq1arhxo0baN++vbT+xo0baN68ucxx3t7e8Pb2xtdffw1PT08kJibC1NRU5nr543FEIlGp8Whra6N///44ePAgnj9/DmdnZ7i5uUnvd3NzQ1hYmMLP81M//vgjOnXqhAkTJkifp4eHByZOnCg95tMWHS0trSLxu7m54ciRI7C0tIShoeEXxUSIuqPB0oSokdq1ayM3NxebN29GZGQk9u/fj23btpV4fGZmJiZPnozLly/j5cuXuHHjBm7fvi3t8vrhhx/w77//YvLkybh//z6ePXuGU6dOKTxYurBZs2Zh5cqVOHLkCMLCwjB79mzcv38f3333HQBg3bp1+P333/H06VOEh4fj2LFjsLa2LnYRSEtLS+jo6OD8+fOIi4tDSkpKiY87ZMgQ/L9dO2ZJBQrDOP7ewEQUa3CxEEJo1SYhF4eIxlYhkBYHIZwdLGtp7AMoNLjYFwhzMmgrcRBEFEKIIIgg2pSQ505J5m0ILjSc/288hwPvOdMD57m8vLTz8/NpSfrD0dGRVatVOzk5sW63a71ezy4uLqxYLP7obpubmxaLxez09NTMzNbX163Valmj0bDBYGCHh4d2d3c3c2Ztbc06nY71+317eXmx9/d329vbs1AoZLu7u3Zzc2PD4dCur68tn8/b4+Pjj2YCnPfbJSUA/9+/CrYfzs7OFA6H5fP5tLOzo2q1KjPT6+urpNky83g8VjqdViQS0eLiolZWVnRwcDBThL69vdX29rYCgYD8fr9isdhc2fmzr2XpryaTiY6Pj7W6uiqPx6N4PK56vT7dL5fL2tjYkN/vVzAY1NbWltrt9nTfPpWlJalSqSgSiWhhYUGpVOrb95lMJgqHwzIz3d/fz811dXWlZDIpn8+nYDCoRCKhcrn87T1KpZLi8fjceq1Wk9fr1cPDg0ajkfb397W0tKTl5WXlcjkVCoWZc8/Pz9P3NTM1m01J0tPTkzKZjEKhkLxer6LRqLLZrN7e3r6dCcC8P5L0u1EMAADgd/A1BgAAnEUQAgAAziIIAQAAZxGEAACAswhCAADAWQQhAADgLIIQAABwFkEIAAA4iyAEAACcRRACAADOIggBAABnEYQAAICz/gJEPr+molzPRgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, ensemble_predictions)\n",
        "\n",
        "# Create a confusion matrix plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 14}, square=True, linewidths=0.5)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix', fontsize=16)\n",
        "plt.xticks([0.5, 1.5], ['Negative', 'Positive'])\n",
        "plt.yticks([0.5, 1.5], ['Negative', 'Positive'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "qGxKLgmFuwGi",
        "outputId": "5547d106-4a74-477f-db55-aeb876f396fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel(\"dataset.xlsx\")\n",
        "\n",
        "# Define preprocessing functions\n",
        "def preprocess_text(text):\n",
        "    # Removing punctuations, English letters, and digits\n",
        "    cleaned_text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)\n",
        "    # Lowercasing the text\n",
        "    cleaned_text = cleaned_text.lower()\n",
        "    # Removing multiple spaces\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
        "    return cleaned_text\n",
        "\n",
        "def tokenize_and_stem(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "    return stemmed_tokens\n",
        "\n",
        "# Apply preprocessing to each row\n",
        "data['headline_cleaned'] = data['headline'].apply(preprocess_text)\n",
        "\n",
        "def preprocess_content(text):\n",
        "    if isinstance(text, str):\n",
        "        return preprocess_text(text)\n",
        "    return ''\n",
        "\n",
        "data['content_cleaned'] = data['content'].apply(preprocess_content)\n",
        "\n",
        "# Tokenize and stem the cleaned text\n",
        "data['headline_processed'] = data['headline_cleaned'].apply(tokenize_and_stem)\n",
        "\n",
        "def tokenize_and_stem_content(text):\n",
        "    if isinstance(text, str):\n",
        "        tokens = word_tokenize(text)\n",
        "        stemmer = PorterStemmer()\n",
        "        stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "        return stemmed_tokens\n",
        "    return []\n",
        "\n",
        "data['content_processed'] = data['content_cleaned'].apply(tokenize_and_stem_content)\n",
        "\n",
        "# Remove Bangla stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words(\"bengali\"))\n",
        "data['headline_final'] = data['headline_processed'].apply(lambda tokens: [token for token in tokens if token not in stop_words])\n",
        "data['content_final'] = data['content_processed'].apply(lambda tokens: [token for token in tokens if token not in stop_words])\n",
        "\n",
        "# Combine headline and content tokens for input features\n",
        "data['combined_tokens'] = data.apply(lambda row: row['headline_final'] + row['content_final'], axis=1)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['combined_tokens'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert tokenized text to string for TF-IDF vectorization\n",
        "X_train_strings = X_train.apply(lambda tokens: ' '.join(tokens))\n",
        "X_test_strings = X_test.apply(lambda tokens: ' '.join(tokens))\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_strings)\n",
        "X_test_tfidf = vectorizer.transform(X_test_strings)\n",
        "\n",
        "# Train a fake news detection model (Naive Bayes classifier)\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fqeirxJu6gD",
        "outputId": "1a958e48-014c-40af-8bda-c442ca45f4d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[693 495]\n",
            " [231 949]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.58      0.66      1188\n",
            "           1       0.66      0.80      0.72      1180\n",
            "\n",
            "    accuracy                           0.69      2368\n",
            "   macro avg       0.70      0.69      0.69      2368\n",
            "weighted avg       0.70      0.69      0.69      2368\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ... (Preprocessing and model training code)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3ruObl8xc60",
        "outputId": "b9021efc-e41c-4492-dfe8-ebf5619cde96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel(\"dataset.xlsx\")  # Replace with your dataset file\n",
        "\n",
        "# Preprocessing: Sentencepiece Tokenization\n",
        "from bnlp import SentencepieceTokenizer\n",
        "bsp = SentencepieceTokenizer()\n",
        "\n",
        "# Replace missing values in 'content' column with an empty string\n",
        "data['content'].fillna('', inplace=True)\n",
        "\n",
        "data['headline_tokens'] = data['headline'].apply(bsp.tokenize)\n",
        "data['content_tokens'] = data['content'].apply(bsp.tokenize)\n",
        "\n",
        "# Preprocessing: Basic Tokenization\n",
        "from bnlp import BasicTokenizer\n",
        "tokenizer = BasicTokenizer()\n",
        "data['headline_basic_tokens'] = data['headline'].apply(tokenizer.tokenize)\n",
        "data['content_basic_tokens'] = data['content'].apply(tokenizer.tokenize)\n",
        "\n",
        "# Preprocessing: NLTK Tokenization\n",
        "from bnlp import NLTKTokenizer\n",
        "bnltk = NLTKTokenizer()\n",
        "data['headline_word_tokens'] = data['headline'].apply(bnltk.word_tokenize)\n",
        "data['content_sentence_tokens'] = data['content'].apply(bnltk.sentence_tokenize)\n",
        "\n",
        "\n",
        "\n",
        "# ... (Other preprocessing steps you've provided)\n",
        "\n",
        "# Combine cleaned headline and content tokens for input features\n",
        "# Combine cleaned headline and content tokens for input features\n",
        "data['combined_tokens1'] = data.apply(lambda row: ' '.join(row['headline_tokens'] + row['content_tokens']), axis=1)\n",
        "data['combined_tokens2'] = data.apply(lambda row: ' '.join(row['headline_basic_tokens'] + row['content_basic_tokens']), axis=1)\n",
        "data['combined_tokens3'] = data.apply(lambda row: ' '.join(row['headline_word_tokens'] + row['content_sentence_tokens']), axis=1)\n",
        "\n",
        "\n",
        "# Rest of the code remains unchanged\n",
        "\n"
      ],
      "metadata": {
        "id": "6QPyKF9-yqAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['combined_tokens1'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a fake news detection model (Naive Bayes classifier)\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp04b2DM8BiQ",
        "outputId": "99be6d2a-6110-4fb6-eed7-75cdbf109060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.73\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.63      0.70      1188\n",
            "           1       0.69      0.83      0.76      1180\n",
            "\n",
            "    accuracy                           0.73      2368\n",
            "   macro avg       0.74      0.73      0.73      2368\n",
            "weighted avg       0.74      0.73      0.73      2368\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['combined_tokens2'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a fake news detection model (Naive Bayes classifier)\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDblmdua9G05",
        "outputId": "90d61bc0-2a6f-48af-97bd-8ff34167b60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.73\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.63      0.70      1188\n",
            "           1       0.69      0.82      0.75      1180\n",
            "\n",
            "    accuracy                           0.73      2368\n",
            "   macro avg       0.73      0.73      0.72      2368\n",
            "weighted avg       0.73      0.73      0.72      2368\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['combined_tokens3'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a fake news detection model (Naive Bayes classifier)\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-YBKeZB9Hs4",
        "outputId": "1f91a26b-11d0-4d08-9623-53fc26fc0ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.73\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.63      0.70      1188\n",
            "           1       0.69      0.82      0.75      1180\n",
            "\n",
            "    accuracy                           0.73      2368\n",
            "   macro avg       0.73      0.73      0.72      2368\n",
            "weighted avg       0.73      0.73      0.72      2368\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from bnlp import SentencepieceTokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Download stopwords list if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load your dataset (replace with your dataset file)\n",
        "data = pd.read_excel(\"dataset.xlsx\")\n",
        "\n",
        "# Preprocessing: Sentencepiece Tokenization\n",
        "bsp = SentencepieceTokenizer()\n",
        "data['content'].fillna('', inplace=True)\n",
        "\n",
        "data['headline_tokens'] = data['headline'].apply(bsp.tokenize)\n",
        "data['content_tokens'] = data['content'].apply(bsp.tokenize)\n",
        "\n",
        "# Remove stopwords using NLTK\n",
        "stop_words = set(stopwords.words(\"bengali\"))\n",
        "data['headline_tokens'] = data['headline_tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
        "data['content_tokens'] = data['content_tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
        "\n",
        "# Combine cleaned headline and content tokens for input features\n",
        "data['combined_tokens'] = data.apply(lambda row: row['headline_tokens'] + row['content_tokens'], axis=1)\n",
        "\n",
        "# Prepare features and labels\n",
        "X = data['combined_tokens']\n",
        "y = data['label']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train.apply(lambda tokens: ' '.join(tokens)))\n",
        "X_test_tfidf = vectorizer.transform(X_test.apply(lambda tokens: ' '.join(tokens)))\n",
        "\n",
        "# Train a fake news detection model (Naive Bayes classifier)\n",
        "model = SVC()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeDnsmJx-KXZ",
        "outputId": "6ed3ab9d-9265-4eb3-f3df-856782b6deb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.80\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.76      0.79      1188\n",
            "           1       0.77      0.84      0.81      1180\n",
            "\n",
            "    accuracy                           0.80      2368\n",
            "   macro avg       0.80      0.80      0.80      2368\n",
            "weighted avg       0.80      0.80      0.80      2368\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from bnlp import SentencepieceTokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier\n",
        "\n",
        "\n",
        "# Download stopwords list if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load your dataset (replace with your dataset file)\n",
        "data = pd.read_excel(\"dataset.xlsx\")\n",
        "\n",
        "# Preprocessing: Sentencepiece Tokenization\n",
        "bsp = SentencepieceTokenizer()\n",
        "data['content'].fillna('', inplace=True)\n",
        "\n",
        "data['headline_tokens'] = data['headline'].apply(bsp.tokenize)\n",
        "data['content_tokens'] = data['content'].apply(bsp.tokenize)\n",
        "\n",
        "# Remove stopwords using NLTK\n",
        "stop_words = set(stopwords.words(\"bengali\"))\n",
        "data['headline_tokens'] = data['headline_tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
        "data['content_tokens'] = data['content_tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
        "\n",
        "# Combine cleaned headline and content tokens for input features\n",
        "data['combined_tokens'] = data.apply(lambda row: row['headline_tokens'] + row['content_tokens'], axis=1)\n",
        "\n",
        "# Prepare features and labels\n",
        "X = data['combined_tokens']\n",
        "y = data['label']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train.apply(lambda tokens: ' '.join(tokens)))\n",
        "X_test_tfidf = vectorizer.transform(X_test.apply(lambda tokens: ' '.join(tokens)))\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "ada_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "extra_model = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Create a VotingClassifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[('random_forest', rf_model), ('gradient_boosting', gb_model),\n",
        "                ('ada_boost', ada_model), ('extra_trees', extra_model)],\n",
        "    voting='soft'  # You can choose 'hard' or 'soft' voting\n",
        ")\n",
        "\n",
        "# Fit the VotingClassifier\n",
        "voting_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = voting_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovY91k5bAbOa",
        "outputId": "ec51fa23-d94c-4ce2-c641-95da1a252ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.80      1188\n",
            "           1       0.78      0.86      0.82      1180\n",
            "\n",
            "    accuracy                           0.81      2368\n",
            "   macro avg       0.82      0.81      0.81      2368\n",
            "weighted avg       0.82      0.81      0.81      2368\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTZ8DQ4TB0P-",
        "outputId": "eff6e3b8-3505-46b4-8cad-e58efd0b705c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten\n",
        "from sklearn.metrics import accuracy_score\n",
        "from bnlp import SentencepieceTokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Download stopwords list if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load your dataset (replace with your dataset file)\n",
        "data = pd.read_excel(\"dataset.xlsx\")\n",
        "\n",
        "# Preprocessing: Sentencepiece Tokenization\n",
        "bsp = SentencepieceTokenizer()\n",
        "data['content'].fillna('', inplace=True)\n",
        "\n",
        "data['headline_tokens'] = data['headline'].apply(bsp.tokenize)\n",
        "data['content_tokens'] = data['content'].apply(bsp.tokenize)\n",
        "\n",
        "# Remove stopwords using NLTK\n",
        "stop_words = set(stopwords.words(\"bengali\"))\n",
        "data['headline_tokens'] = data['headline_tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
        "data['content_tokens'] = data['content_tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
        "\n",
        "# Combine cleaned headline and content tokens for input features\n",
        "data['combined_tokens'] = data.apply(lambda row: row['headline_tokens'] + row['content_tokens'], axis=1)\n",
        "\n",
        "# Prepare features and labels\n",
        "X = data['combined_tokens']\n",
        "y = data['label']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "max_length = 200  # Adjust as needed\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_length))\n",
        "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train CNN-LSTM model\n",
        "history = model.fit(X_train_padded, y_train, epochs=20, batch_size=64,\n",
        "                    validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate model\n",
        "y_pred_prob = model.predict(X_test_padded)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDnKhuvlFRxv",
        "outputId": "7030be36-156f-446e-cb9b-7f1ade0c3aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 200, 128)          640000    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 196, 64)           41024     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 98, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_22 (LSTM)              (None, 128)               98816     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 788,161\n",
            "Trainable params: 788,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "119/119 [==============================] - 87s 642ms/step - loss: 0.6125 - accuracy: 0.6349 - val_loss: 0.5704 - val_accuracy: 0.6707\n",
            "Epoch 2/20\n",
            "119/119 [==============================] - 70s 579ms/step - loss: 0.4428 - accuracy: 0.7955 - val_loss: 0.5060 - val_accuracy: 0.7546\n",
            "Epoch 3/20\n",
            "119/119 [==============================] - 63s 531ms/step - loss: 0.3090 - accuracy: 0.8732 - val_loss: 0.4874 - val_accuracy: 0.7894\n",
            "Epoch 4/20\n",
            "119/119 [==============================] - 64s 541ms/step - loss: 0.2182 - accuracy: 0.9179 - val_loss: 0.5359 - val_accuracy: 0.7726\n",
            "Epoch 5/20\n",
            "119/119 [==============================] - 58s 488ms/step - loss: 0.1678 - accuracy: 0.9427 - val_loss: 0.7630 - val_accuracy: 0.7842\n",
            "Epoch 6/20\n",
            "119/119 [==============================] - 58s 485ms/step - loss: 0.1327 - accuracy: 0.9551 - val_loss: 0.8025 - val_accuracy: 0.7799\n",
            "74/74 [==============================] - 3s 35ms/step\n",
            "Accuracy: 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "from bnlp import SentencepieceTokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Download stopwords list if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load your dataset (replace with your dataset file)\n",
        "data = pd.read_excel(\"dataset.xlsx\")\n",
        "\n",
        "# Preprocessing: Sentencepiece Tokenization\n",
        "bsp = SentencepieceTokenizer()\n",
        "data['content'].fillna('', inplace=True)\n",
        "\n",
        "data['headline_tokens'] = data['headline'].apply(bsp.tokenize)\n",
        "data['content_tokens'] = data['content'].apply(bsp.tokenize)\n",
        "\n",
        "# Remove stopwords using NLTK\n",
        "stop_words = set(stopwords.words(\"bengali\"))\n",
        "data['headline_tokens'] = data['headline_tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
        "data['content_tokens'] = data['content_tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
        "\n",
        "# Combine cleaned headline and content tokens for input features\n",
        "data['combined_tokens'] = data.apply(lambda row: row['headline_tokens'] + row['content_tokens'], axis=1)\n",
        "\n",
        "# Prepare features and labels\n",
        "X = data['combined_tokens']\n",
        "y = data['label']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "max_length = 200  # Adjust as needed\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_length))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train CNN-LSTM model\n",
        "history = model.fit(X_train_padded, y_train, epochs=20, batch_size=64,\n",
        "                    validation_split=0.2) #, callbacks=[early_stopping]\n",
        "\n",
        "# Evaluate model\n",
        "y_pred_prob = model.predict(X_test_padded)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcIhF_1LNI0k",
        "outputId": "3a5de91a-9e83-4335-cde8-8a63acf12c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 200, 128)          640000    \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 198, 128)          49280     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 99, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " lstm_23 (LSTM)              (None, 99, 128)           131584    \n",
            "                                                                 \n",
            " lstm_24 (LSTM)              (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 874,497\n",
            "Trainable params: 874,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "119/119 [==============================] - 136s 1s/step - loss: 0.6302 - accuracy: 0.6284 - val_loss: 0.5357 - val_accuracy: 0.7314\n",
            "Epoch 2/20\n",
            "119/119 [==============================] - 122s 1s/step - loss: 0.4353 - accuracy: 0.8058 - val_loss: 0.4506 - val_accuracy: 0.7884\n",
            "Epoch 3/20\n",
            "119/119 [==============================] - 123s 1s/step - loss: 0.3023 - accuracy: 0.8784 - val_loss: 0.4692 - val_accuracy: 0.7799\n",
            "Epoch 4/20\n",
            "119/119 [==============================] - 115s 968ms/step - loss: 0.2313 - accuracy: 0.9158 - val_loss: 0.5024 - val_accuracy: 0.7889\n",
            "Epoch 5/20\n",
            "119/119 [==============================] - 115s 959ms/step - loss: 0.1704 - accuracy: 0.9411 - val_loss: 0.5520 - val_accuracy: 0.7900\n",
            "Epoch 6/20\n",
            "119/119 [==============================] - 111s 934ms/step - loss: 0.1415 - accuracy: 0.9546 - val_loss: 0.5961 - val_accuracy: 0.7810\n",
            "Epoch 7/20\n",
            "119/119 [==============================] - 110s 929ms/step - loss: 0.1263 - accuracy: 0.9578 - val_loss: 0.6849 - val_accuracy: 0.7794\n",
            "Epoch 8/20\n",
            "119/119 [==============================] - 108s 905ms/step - loss: 0.0899 - accuracy: 0.9694 - val_loss: 0.9399 - val_accuracy: 0.7757\n",
            "Epoch 9/20\n",
            "119/119 [==============================] - 110s 927ms/step - loss: 0.0746 - accuracy: 0.9735 - val_loss: 0.8318 - val_accuracy: 0.7604\n",
            "Epoch 10/20\n",
            "119/119 [==============================] - 111s 935ms/step - loss: 0.0651 - accuracy: 0.9757 - val_loss: 1.0564 - val_accuracy: 0.7694\n",
            "Epoch 11/20\n",
            "119/119 [==============================] - 109s 914ms/step - loss: 0.0593 - accuracy: 0.9786 - val_loss: 0.8889 - val_accuracy: 0.7747\n",
            "Epoch 12/20\n",
            "119/119 [==============================] - 110s 920ms/step - loss: 0.0648 - accuracy: 0.9756 - val_loss: 1.0837 - val_accuracy: 0.7789\n",
            "Epoch 13/20\n",
            "119/119 [==============================] - 110s 915ms/step - loss: 0.0549 - accuracy: 0.9776 - val_loss: 1.0377 - val_accuracy: 0.7747\n",
            "Epoch 14/20\n",
            "119/119 [==============================] - 110s 923ms/step - loss: 0.0699 - accuracy: 0.9708 - val_loss: 1.0804 - val_accuracy: 0.7763\n",
            "Epoch 15/20\n",
            "119/119 [==============================] - 111s 933ms/step - loss: 0.0532 - accuracy: 0.9793 - val_loss: 0.8816 - val_accuracy: 0.7609\n",
            "Epoch 16/20\n",
            "119/119 [==============================] - 112s 947ms/step - loss: 0.0591 - accuracy: 0.9773 - val_loss: 1.0676 - val_accuracy: 0.7673\n",
            "Epoch 17/20\n",
            "119/119 [==============================] - 113s 952ms/step - loss: 0.0382 - accuracy: 0.9823 - val_loss: 1.2329 - val_accuracy: 0.7726\n",
            "Epoch 18/20\n",
            "119/119 [==============================] - 113s 951ms/step - loss: 0.0329 - accuracy: 0.9838 - val_loss: 1.4100 - val_accuracy: 0.7789\n",
            "Epoch 19/20\n",
            "119/119 [==============================] - 113s 946ms/step - loss: 0.0390 - accuracy: 0.9814 - val_loss: 1.2597 - val_accuracy: 0.7757\n",
            "Epoch 20/20\n",
            "119/119 [==============================] - 111s 938ms/step - loss: 0.0485 - accuracy: 0.9795 - val_loss: 1.1772 - val_accuracy: 0.7731\n",
            "74/74 [==============================] - 5s 56ms/step\n",
            "Accuracy: 0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebw6mbjKOuf-",
        "outputId": "9a5e9a37-2989-4b74-d813-3640f6ee55d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.78      0.78      1188\n",
            "           1       0.78      0.78      0.78      1180\n",
            "\n",
            "    accuracy                           0.78      2368\n",
            "   macro avg       0.78      0.78      0.78      2368\n",
            "weighted avg       0.78      0.78      0.78      2368\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "from bnlp import SentencepieceTokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Download stopwords list if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load your dataset (replace with your dataset file)\n",
        "data = pd.read_excel(\"dataset.xlsx\")\n",
        "\n",
        "# Preprocessing: Sentencepiece Tokenization\n",
        "bsp = SentencepieceTokenizer()\n",
        "data['content'].fillna('', inplace=True)\n",
        "\n",
        "data['headline_tokens'] = data['headline'].apply(bsp.tokenize)\n",
        "data['content_tokens'] = data['content'].apply(bsp.tokenize)\n",
        "\n",
        "# Combine headline and content for more context\n",
        "data['combined_text'] = data['headline_tokens'] + data['content_tokens']\n",
        "\n",
        "# Combine tokens into sentences\n",
        "data['sentences'] = data['combined_text'].apply(lambda tokens: ' '.join(tokens))\n",
        "\n",
        "# Remove stopwords using NLTK\n",
        "stop_words = set(stopwords.words(\"bengali\"))\n",
        "data['cleaned_sentences'] = data['sentences'].apply(lambda sentence: ' '.join([word for word in sentence.split() if word not in stop_words]))\n",
        "\n",
        "# Prepare features and labels\n",
        "X = data['cleaned_sentences']\n",
        "y = data['label']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "max_length = 200  # Adjust as needed\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
        "\n",
        "# Create an ensemble of three models\n",
        "num_models = 3\n",
        "models = []\n",
        "for i in range(num_models):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_length))\n",
        "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "    models.append(model)\n",
        "\n",
        "# Train each model\n",
        "for model in models:\n",
        "    model.fit(X_train_padded, y_train, epochs=20, batch_size=64,\n",
        "              validation_split=0.2) #, callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
        "\n",
        "# Make predictions using each model\n",
        "predictions = []\n",
        "for model in models:\n",
        "    y_pred_prob = model.predict(X_test_padded)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "    predictions.append(y_pred)\n",
        "\n",
        "# Combine predictions using majority voting\n",
        "ensemble_predictions = np.mean(predictions, axis=0)\n",
        "ensemble_predictions = (ensemble_predictions > 0.5).astype(int)\n",
        "\n",
        "# Calculate ensemble accuracy\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
        "print(f\"Ensemble Accuracy: {ensemble_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9XachEIXeF4",
        "outputId": "41dab4c2-1d46-4730-f03b-4d289b384631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "119/119 [==============================] - 151s 1s/step - loss: 0.6357 - accuracy: 0.6097 - val_loss: 0.5405 - val_accuracy: 0.7087\n",
            "Epoch 2/20\n",
            "119/119 [==============================] - 123s 1s/step - loss: 0.4246 - accuracy: 0.8094 - val_loss: 0.4917 - val_accuracy: 0.7699\n",
            "Epoch 3/20\n",
            "119/119 [==============================] - 117s 985ms/step - loss: 0.2947 - accuracy: 0.8819 - val_loss: 0.5502 - val_accuracy: 0.7673\n",
            "Epoch 4/20\n",
            "119/119 [==============================] - 117s 984ms/step - loss: 0.1926 - accuracy: 0.9308 - val_loss: 0.6204 - val_accuracy: 0.7747\n",
            "Epoch 5/20\n",
            "119/119 [==============================] - 116s 973ms/step - loss: 0.1517 - accuracy: 0.9506 - val_loss: 0.6784 - val_accuracy: 0.7747\n",
            "Epoch 1/20\n",
            "119/119 [==============================] - 132s 1s/step - loss: 0.6279 - accuracy: 0.6275 - val_loss: 0.5289 - val_accuracy: 0.7177\n",
            "Epoch 2/20\n",
            "119/119 [==============================] - 120s 1s/step - loss: 0.4146 - accuracy: 0.8130 - val_loss: 0.4940 - val_accuracy: 0.7335\n",
            "Epoch 3/20\n",
            "119/119 [==============================] - 116s 973ms/step - loss: 0.2762 - accuracy: 0.8933 - val_loss: 0.5345 - val_accuracy: 0.7715\n",
            "Epoch 4/20\n",
            "119/119 [==============================] - 115s 957ms/step - loss: 0.1907 - accuracy: 0.9351 - val_loss: 0.5627 - val_accuracy: 0.7704\n",
            "Epoch 5/20\n",
            "119/119 [==============================] - 114s 962ms/step - loss: 0.1384 - accuracy: 0.9554 - val_loss: 0.6918 - val_accuracy: 0.7668\n",
            "Epoch 1/20\n",
            "119/119 [==============================] - 130s 1s/step - loss: 0.6264 - accuracy: 0.6181 - val_loss: 0.5366 - val_accuracy: 0.7245\n",
            "Epoch 2/20\n",
            "119/119 [==============================] - 119s 998ms/step - loss: 0.4382 - accuracy: 0.8011 - val_loss: 0.5050 - val_accuracy: 0.7493\n",
            "Epoch 3/20\n",
            "119/119 [==============================] - 116s 962ms/step - loss: 0.2883 - accuracy: 0.8922 - val_loss: 0.5326 - val_accuracy: 0.7799\n",
            "Epoch 4/20\n",
            "119/119 [==============================] - 112s 945ms/step - loss: 0.1850 - accuracy: 0.9365 - val_loss: 0.6300 - val_accuracy: 0.7604\n",
            "Epoch 5/20\n",
            "119/119 [==============================] - 112s 940ms/step - loss: 0.1460 - accuracy: 0.9550 - val_loss: 0.6513 - val_accuracy: 0.7588\n",
            "74/74 [==============================] - 5s 57ms/step\n",
            "74/74 [==============================] - 5s 57ms/step\n",
            "74/74 [==============================] - 5s 57ms/step\n",
            "Ensemble Accuracy: 0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Calculate ensemble predictions\n",
        "ensemble_predictions = np.mean(predictions, axis=0)\n",
        "ensemble_predictions = (ensemble_predictions > 0.5).astype(int)\n",
        "\n",
        "# Print classification report\n",
        "classification_rep = classification_report(y_test, ensemble_predictions, target_names=['Real', 'Fake'])\n",
        "print(\"Ensemble Classification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be5zfsm-Xqfc",
        "outputId": "6530247c-da41-41c1-cd47-c2167b762467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.84      0.70      0.77      1188\n",
            "        Fake       0.74      0.87      0.80      1180\n",
            "\n",
            "    accuracy                           0.79      2368\n",
            "   macro avg       0.79      0.79      0.78      2368\n",
            "weighted avg       0.79      0.79      0.78      2368\n",
            "\n"
          ]
        }
      ]
    }
  ]
}